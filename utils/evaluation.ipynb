{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/utils/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# è¯„ä¼°å‡½æ•°å°è£…\n",
        "ğŸš€ NYIT 880 | ğŸ§‘ğŸ»â€ğŸ’» funway\n",
        "\n",
        "- **è¯¥æ–‡ä»¶åªå®šä¹‰ å‡½æ•° æˆ– ç±»** â€¼ï¸\n",
        "- åœ¨å…¶ä»– ipynb æ–‡ä»¶ä¸­è¿è¡Œ `%run full_path/file_name.ipynb` å³å¯å¯¼å…¥è¯¥æ–‡ä»¶ä¸­çš„å‡½æ•°ä¸ç±»\n",
        "- ç”±äº Google Drive çš„å†™å…¥ç¼“å­˜, æ‰€ä»¥ä¿®æ”¹è¯¥æ–‡ä»¶å, å¯èƒ½éœ€è¦ç­‰å¾…ä¸€å®šæ—¶é—´(å‡ åç§’), åœ¨å¼•ç”¨å¤„æ‰ä¼šç”Ÿæ•ˆ"
      ],
      "metadata": {
        "id": "i9wDSITkLv3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'now' not in globals() or not callable(globals()['now']):\n",
        "    def now() -> str:\n",
        "        \"\"\"è·å–å½“å‰æ—¶é—´\"\"\"\n",
        "        from datetime import datetime\n",
        "        from zoneinfo import ZoneInfo\n",
        "        return datetime.now(tz=ZoneInfo('America/Vancouver')).strftime('%x %X %Z')\n",
        "# else:\n",
        "#     print(f\"[{now()}] âš ï¸ Function 'now' is already defined\")"
      ],
      "metadata": {
        "id": "i2dvIzQy66nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def generate_evaluation_report(y_true, y_predict,\n",
        "                               label_mapping: dict,\n",
        "                               figure_output: str,\n",
        "                               figure_show: bool = True):\n",
        "    \"\"\"\n",
        "    ç”ŸæˆæŠ¥å‘Šï¼ŒåŒ…æ‹¬æ··æ·†çŸ©é˜µã€å¤šåˆ†ç±»æŠ¥å‘Šã€äºŒåˆ†ç±»æŠ¥å‘Šã€‚\n",
        "    \"\"\"\n",
        "\n",
        "    ### æ··æ·†çŸ©é˜µ ###\n",
        "    report_text_cm = f\"[{now()}] ================= ğŸ“Š Confusion Matrix =================\\n\"\n",
        "\n",
        "    ## è®¡ç®—æ··æ·†çŸ©é˜µ ##\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    ## å½’ä¸€åŒ–æ··æ·†çŸ©é˜µ(è®¡ç®—ä¸ºç™¾åˆ†æ¯”) ##\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    labels = [f\"({k}) {v}\" for k, v in sorted(label_mapping.items(), key=lambda x: x[1])]\n",
        "    # print(f\"[{now()}] ğŸ·ï¸ Label mapping: {label_mapping}\")\n",
        "    # print(f\"[{now()}] ğŸ·ï¸ labels: {labels}\")\n",
        "\n",
        "    ## ç»˜åˆ¶æ··æ·†çŸ©é˜µå›¾åƒ ##\n",
        "    np.set_printoptions(precision=2, suppress=True)  # è®¾ç½®æ‰“å°æ—¶ä¿ç•™å°æ•°ç‚¹å2ä½, ç¦ç”¨ç§‘å­¦è®¡æ•°æ³•\n",
        "    plt.figure(figsize=(10, 8), dpi=150)\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f\"Confusion Matrix (Multiclass)\\n{figure_output.stem}\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    # ä¿å­˜å›¾åƒ\n",
        "    plt.savefig(figure_output, bbox_inches='tight')\n",
        "    # æ˜¾ç¤ºå›¾åƒ (show å®Œä¼šè‡ªåŠ¨æ¸…ç©ºå½“å‰å›¾åƒ, æ‰€ä»¥å¾—å…ˆ save å† show!)\n",
        "    if figure_show:\n",
        "        plt.show()\n",
        "\n",
        "    ## è¾“å‡ºæ··æ·†çŸ©é˜µæ–‡æœ¬ ##\n",
        "    # ä¿è¯å®½åº¦å¯¹é½\n",
        "    col_width = 7\n",
        "    report_text_cm += \" \" * 24 + \"\".join([name[name.index(\")\")+2:].ljust(col_width) for name in labels]) + \"\\n\"\n",
        "    for i, row in enumerate(cm_normalized):\n",
        "        row_name = labels[i][:20].ljust(24)\n",
        "        row_vals = \"\".join([\n",
        "            (\"-----\".ljust(col_width) if val < 1e-4 else f\"{val:.3f}\".ljust(col_width))\n",
        "            for val in row])\n",
        "        report_text_cm += row_name + row_vals + \"\\n\"\n",
        "\n",
        "\n",
        "    ### å¤šåˆ†ç±»æŠ¥å‘Š ###\n",
        "    report_multiclass = classification_report(y_true, y_pred, target_names=labels, zero_division=0, digits=6)\n",
        "    # zero_division æ˜¯é˜²æ­¢é™¤é›¶å‘Šè­¦, å¦‚æœæœ‰æŸä¸ªç±»åˆ«å®Œå…¨æ²¡æœ‰åˆ¤æ–­æ­£ç¡®çš„æ ·æœ¬ï¼Œå°±ä¼šå‡ºç°é™¤é›¶å‘Šè­¦\n",
        "\n",
        "    # Macro å¹³å‡ (ä¸è€ƒè™‘ä¸åŒç±»åˆ«çš„æ ·æœ¬æ•°é‡å·®å¼‚)\n",
        "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    rec_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    # Weighted å¹³å‡ (è€ƒè™‘ä¸åŒç±»åˆ«çš„æ ·æœ¬æ•°é‡å·®å¼‚)\n",
        "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    rec_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "\n",
        "    report_text_multiclass =  (\n",
        "        f\"[{now()}] ================= ğŸ“ Multiclass Report =================\\n\"\n",
        "        + report_multiclass + \"\\n\"\n",
        "        + f\"ğŸ“Š Macro average\\n\"\n",
        "        + f\"    Precision: {precision_macro:.6f}\\n\"\n",
        "        + f\"    Recall:    {rec_macro:.6f}\\n\"\n",
        "        + f\"    F1 Score:  {f1_macro:.6f}\\n\\n\"\n",
        "        + f\"ğŸ“Š Weighted average\\n\"\n",
        "        + f\"    Precision: {precision_weighted:.6f}\\n\"\n",
        "        + f\"    Recall:    {rec_weighted:.6f}\\n\"\n",
        "        + f\"    F1 Score:  {f1_weighted:.6f}\\n\\n\"\n",
        "        + f\"ğŸ¯ Accuracy: {acc:.6f}\\n\"\n",
        "        + f\"ğŸ¯ Balanced Accuracy: {balanced_acc:.6f}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "    ### äºŒåˆ†ç±»æŠ¥å‘Š ###\n",
        "    # å°†å¤šåˆ†ç±»æ ‡ç­¾æ˜ å°„ä¸ºäºŒåˆ†ç±»\n",
        "    # benign æ ‡ç­¾ä¸º 0 åˆ†ç±»ï¼Œæ‰€æœ‰æ”»å‡»æ ‡ç­¾ä½œä¸º 1 åˆ†ç±»\n",
        "    normal_class_label = 0\n",
        "    y_true_bin = np.where(y_true == normal_class_label, 0, 1)  # åŸ label ä¸º 0 çš„ä½œä¸ºäºŒåˆ†ç±»çš„ 0 ç±»åˆ«ï¼Œå…¶ä»–çš„ä½œä¸ºäºŒåˆ†ç±»çš„ 1 ç±»åˆ«\n",
        "    y_pred_bin = np.where(y_pred == normal_class_label, 0, 1)\n",
        "\n",
        "    report_binary = classification_report(y_true_bin, y_pred_bin, zero_division=0, digits=6)\n",
        "\n",
        "    # è®¡ç®—å¸¸ç”¨äºŒåˆ†ç±»æŒ‡æ ‡\n",
        "    acc_bin = accuracy_score(y_true_bin, y_pred_bin)  # 0,1 åˆ†ç±»çš„å‡†ç¡®ç‡\n",
        "    pre_bin = precision_score(y_true_bin, y_pred_bin)  # 1 åˆ†ç±»(æ”»å‡»ç±»åˆ«)çš„ç²¾ç¡®åº¦(é¢„æµ‹æ”»å‡»ç±»åˆ«æœ‰å¤šå‡†)\n",
        "    rec_bin = recall_score(y_true_bin, y_pred_bin) # æ”»å‡»ç±»åˆ«çš„å¬å›ç‡ (æœ‰å¤šå°‘çœŸå®çš„æ”»å‡»ç±»åˆ«è¢«é¢„æµ‹å‡ºæ¥äº†)\n",
        "    f1_bin = f1_score(y_true_bin, y_pred_bin)  # æ”»å‡»ç±»åˆ«çš„\n",
        "\n",
        "    # ğŸ§® è®¡ç®— FPRï¼ˆè¯¯æŠ¥ç‡ï¼‰ = FP / (FP + TN)\n",
        "    cm_bin = confusion_matrix(y_true_bin, y_pred_bin)\n",
        "    if cm_bin.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm_bin.ravel()\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    else:\n",
        "        print(f\"[{now()}] âš ï¸ confusion matrix shape is not (2, 2)\")\n",
        "        raise Exception(\"confusion matrix shape is not (2, 2)\")\n",
        "\n",
        "    report_text_binary = (\n",
        "        f\"[{now()}] ================= ğŸ“ Binary Report (Normal vs Attack) =================\\n\"\n",
        "        + report_binary + \"\\n\"\n",
        "        + f\"ğŸ¯ Accuracy       : {acc_bin:.6f}\\n\"\n",
        "        + f\"âœ… Precision      : {pre_bin:.6f}\\n\"\n",
        "        + f\"ğŸ” Recall / DR    : {rec_bin:.6f}\\n\"\n",
        "        + f\"ğŸ¯ F1 Score       : {f1_bin:.6f}\\n\"\n",
        "        + f\"ğŸš¨ FPR (è¯¯æŠ¥ç‡)    : {fpr:.6f}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "    ### è¿”å›æŠ¥å‘Š ###\n",
        "    report_text = report_text_cm + '\\n' + report_text_multiclass + '\\n' + report_text_binary\n",
        "    return report_text"
      ],
      "metadata": {
        "id": "W3Llr9lbxBZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}