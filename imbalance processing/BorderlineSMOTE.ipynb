{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gqqi2ITUeOmB"
      ],
      "authorship_tag": "ABX9TyOL2fKa7xybUWNBoCr2rglx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/imbalance%20processing/BorderlineSMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用 **BorderlineSMOTE** 对训练集的少数样本进行过采样\n",
        "- 传统 SMOTE 对所有少数类样本都进行处理(随机挑选邻居进行插值生成新数据)\n",
        "- BorderlineSMOTE 只处理\"边界上\"的少数类样本\n"
      ],
      "metadata": {
        "id": "pv4skFSheBzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Env"
      ],
      "metadata": {
        "id": "gqqi2ITUeOmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzbTh_MiPCpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e984ad8-8fdd-465a-bb4f-f854ceec8118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules import & Globals setup"
      ],
      "metadata": {
        "id": "qR21AFUgeYXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Modules ###\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Globals ###\n",
        "\n",
        "## Label 特征的数值化编码\n",
        "label_mapping = {\n",
        "    \"Benign\": 0,\n",
        "    \"Bot\": 1,\n",
        "    \"Brute Force -Web\": 2,\n",
        "    \"Brute Force -XSS\": 3,\n",
        "    \"DDOS attack-HOIC\": 4,\n",
        "    \"DDOS attack-LOIC-UDP\": 5,\n",
        "    \"DDoS attacks-LOIC-HTTP\": 6,\n",
        "    \"DoS attacks-GoldenEye\": 7,\n",
        "    \"DoS attacks-Hulk\": 8,\n",
        "    \"DoS attacks-SlowHTTPTest\": 9,\n",
        "    \"DoS attacks-Slowloris\": 10,\n",
        "    \"FTP-BruteForce\": 11,\n",
        "    \"Infilteration\": 12,\n",
        "    \"SQL Injection\": 13,\n",
        "    \"SSH-Bruteforce\": 14\n",
        "}\n",
        "\n",
        "## 计划尝试三种样本分布模式\n",
        "resample_schemes = {\n",
        "    # 模式1. (标签0:非0标签总和) ≈ (160:157); 非0标签按大概比例增强\n",
        "    1: {\n",
        "        0: 1600000,  # 保持不变\n",
        "        1: 200000,   # ⤵️ 228953\n",
        "        2: 20000,    # ⤴️ 489\n",
        "        3: 20000,    # ⤴️ 184\n",
        "        4: 200000,   # ⤵️ 548809\n",
        "        5: 20000,    # ⤴️ 1384\n",
        "        6: 200000,   # ⤵️ 460953\n",
        "        7: 100000,   # ⤴️ 33206\n",
        "        8: 200000,   # ⤵️ 369530\n",
        "        9: 111912,   # ⤴️ 111912\n",
        "        10: 50000,   # ⤴️ 8792\n",
        "        11: 154683,  # ⤴️ 154683\n",
        "        12: 128511,  # ⤴️ 128511\n",
        "        13: 20000,   # ⤴️ 70\n",
        "        14: 150071   # ⤴️ 150071\n",
        "    },\n",
        "    # 模式2. (标签0:最多非0标签样本) ≈ (3:2)\n",
        "    2: {\n",
        "        0: 300000,   # ⤵️ 1600000\n",
        "        1: 200000,   # ⤵️ 228953\n",
        "        2: 20000,    # ⤴️ 489\n",
        "        3: 20000,    # ⤴️ 184\n",
        "        4: 200000,   # ⤵️ 548809\n",
        "        5: 20000,    # ⤴️ 1384\n",
        "        6: 200000,   # ⤵️ 460953\n",
        "        7: 100000,   # ⤴️ 33206\n",
        "        8: 200000,   # ⤵️ 369530\n",
        "        9: 111912,   # ⤴️ 111912\n",
        "        10: 50000,   # ⤴️ 8792\n",
        "        11: 154683,  # ⤴️ 154683\n",
        "        12: 128511,  # ⤴️ 128511\n",
        "        13: 20000,   # ⤴️ 70\n",
        "        14: 150071   # ⤴️ 150071\n",
        "    },\n",
        "    # 模式3. (标签0:非0标签总和) = (1:1); 每种非0标签都占 114300 个样本\n",
        "    3: {\n",
        "        0: 1600000,\n",
        "        **{k: 114300 for k in range(1, 15)}\n",
        "    },\n",
        "    # 模式4. 所有标签都 20万样本\n",
        "    4: {\n",
        "       **{k: 200000 for k in range(0, 15)}\n",
        "    },\n",
        "}\n",
        "\n",
        "## 数据目录\n",
        "datasets_folder = Path('/content/drive/MyDrive/NYIT/870/datasets')\n",
        "dataset = 'CSE-CIC-IDS2018'\n",
        "preprocessed_folder = datasets_folder / 'preprocessed' / dataset\n",
        "balanced_folder = datasets_folder / 'balanced' / dataset"
      ],
      "metadata": {
        "id": "NKNH9UjKeZmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaling_method = 'standard'\n",
        "# scaling_method = 'minmax'\n",
        "\n",
        "resample_scheme = 3\n",
        "resample_to = resample_schemes[resample_scheme]\n",
        "\n",
        "oversampling_method = 'ROS+BLSMOTE'\n",
        "\n",
        "# undersampling_method = 'NM'"
      ],
      "metadata": {
        "id": "QuRdhKfJ4RFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_file = preprocessed_folder / f'integrated/train_X_{scaling_method}.npy'\n",
        "y_file = preprocessed_folder / f'integrated/train_label_{scaling_method}.npy'\n",
        "\n",
        "# 加载训练集文件\n",
        "X = np.load(X_file)\n",
        "y = np.load(y_file)\n",
        "\n",
        "labels_counts = sorted(Counter(y).items())\n",
        "labels_counts = dict(labels_counts)\n",
        "\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] {X_file.name} shape: {X.shape}')\n",
        "print(f'Labels: { {int(k): v for k, v in labels_counts.items()} }\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXZ4E8wJlzLF",
        "outputId": "6c877dfb-80a4-428b-c0d4-da50d18be3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/21/25 00:17:51] train_X_standard.npy shape: (3797547, 70)\n",
            "Labels: {0: 1600000, 1: 228953, 2: 489, 3: 184, 4: 548809, 5: 1384, 6: 460953, 7: 33206, 8: 369530, 9: 111912, 10: 8792, 11: 154683, 12: 128511, 13: 70, 14: 150071}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 利用 ROS 提前补充极少数类样本\n",
        "- 先用 ROS 随机复制的方式，将极少数类样本扩展到可接受的程度后再进行 oversampling\n"
      ],
      "metadata": {
        "id": "fDAkD88lY-gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample_to = {}\n",
        "# 判断 oversampling_method 字符串开头是否为 ROS\n",
        "if oversampling_method.startswith('ROS'):\n",
        "    if oversampling_method.startswith('ROS+'):\n",
        "        oversample_to = {2: 1000, 3: 500, 13: 500}\n",
        "    elif oversampling_method.startswith('ROS1+'):\n",
        "        oversample_to = {2: 1000, 3: 1000, 13: 1000}\n",
        "\n",
        "    oversampler = RandomOverSampler(sampling_strategy=oversample_to, random_state=42)\n",
        "    X, y = oversampler.fit_resample(X, y)\n",
        "\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] After ROS oversampling:')\n",
        "    print(f'  X.shape: {X.shape}, y.shape: {y.shape}')\n",
        "    print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y).items())} }\\n')\n",
        "else:\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] No need to ROS oversampling.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfzi08QuZwQV",
        "outputId": "2c68111b-46af-42cf-a0b2-ea52bba36863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/21/25 00:17:54] After ROS oversampling:\n",
            "  X.shape: (3798804, 70), y.shape: (3798804,)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 1000, 3: 500, 4: 548809, 5: 1384, 6: 460953, 7: 33206, 8: 369530, 9: 111912, 10: 8792, 11: 154683, 12: 128511, 13: 500, 14: 150071}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BorderlineSMOTE\n",
        "\n",
        "*   又是一个巨耗时的算法\n",
        "*   ❓使用 BorderlineSMOTE 对 oversample_to 字典内的所有标签进行一次性过采样，不知道为什么会出现有的标签没有被处理的情况。\n"
      ],
      "metadata": {
        "id": "75awp9PSfBmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "\n",
        "### 分阶段过采样函数 #############################################################\n",
        "# 70 → 350 → 1750 → 8750 → 43750 这样\n",
        "def staged_oversample_blsmote(X, y, label, target, factor=5, random_state=42, k_neighbors=5, m_neighbors=10):\n",
        "    current_X, current_y = X, y\n",
        "    current_count = Counter(current_y)[label]\n",
        "\n",
        "    # 如果目标数量比当前数量小或相等，直接返回\n",
        "    if current_count >= target:\n",
        "        return X, y\n",
        "\n",
        "    while current_count < target:\n",
        "        next_target = min(current_count * factor, target)  # 下一个阶段的目标\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}]  当前数量: {current_count}, 下阶段目标: {next_target}\")\n",
        "\n",
        "        oversampler = BorderlineSMOTE(\n",
        "            sampling_strategy={label: next_target},\n",
        "            random_state=random_state,\n",
        "            k_neighbors=k_neighbors,\n",
        "            m_neighbors=m_neighbors\n",
        "        )\n",
        "        try:\n",
        "          current_X, current_y = oversampler.fit_resample(current_X, current_y)\n",
        "          if current_count == Counter(current_y)[label]:\n",
        "              raise Exception('无法新增样本! (标签的样本分布不适合使用该过采样方法)')\n",
        "          current_count = Counter(current_y)[label]\n",
        "        except Exception as e:\n",
        "          print(f\"  ERROR: {e}\")\n",
        "          break\n",
        "\n",
        "        # 最后一次得到近似 target 值后就可以退出了。\n",
        "        if next_target == target:\n",
        "            break\n",
        "\n",
        "    return current_X, current_y\n",
        "### 分阶段过采样函数 #############################################################\n",
        "\n",
        "\n",
        "# 1. 指定需要过采样的标签与目标\n",
        "oversample_to = {}\n",
        "labels_counts = dict(sorted(Counter(y).items()))\n",
        "for label, target in resample_to.items():\n",
        "    if labels_counts[label] < resample_to[label]:\n",
        "        oversample_to[label] = target\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] oversample_to: {oversample_to}\\n')\n",
        "\n",
        "# 2. 执行过采样\n",
        "start_time = datetime.now()\n",
        "\n",
        "#############################################\n",
        "# 2-1. 一次性过采样\n",
        "# 可能出现某些标签没有被处理的情况。。。\n",
        "# oversampler = BorderlineSMOTE(sampling_strategy=oversample_to, random_state=42, k_neighbors=5, m_neighbors=10)\n",
        "# X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "#############################################\n",
        "# 2-2. 逐标签过采样\n",
        "# 先提取出不需要过采样的数据\n",
        "mask = ~np.isin(y, list(oversample_to.keys()))\n",
        "X_resampled = X[mask]\n",
        "y_resampled = y[mask]\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] X_resampled.shape(before): {X_resampled.shape}')\n",
        "print(f'  Labels(before): { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "\n",
        "for label, target in oversample_to.items():\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] Oversampling [{label}]: {labels_counts[label]} -> {oversample_to[label]} ...')\n",
        "    st = datetime.now()\n",
        "\n",
        "    # 2-2-1. 不分阶段过采样\n",
        "    sampler = BorderlineSMOTE(sampling_strategy={label: target}, random_state=42, k_neighbors=5, m_neighbors=10, kind='borderline-1')\n",
        "    X_, y_ = sampler.fit_resample(X, y)\n",
        "\n",
        "    # 2-2-2. 分阶段过采样\n",
        "    # X_, y_ = staged_oversample_blsmote(X, y, label, target, factor=5, random_state=42, k_neighbors=5, m_neighbors=10)\n",
        "\n",
        "    et = datetime.now()\n",
        "    print(f\"  Time elapsed: {et - st}. [{st.strftime('%Y%m%d %X')} -> {et.strftime('%Y%m%d %X')}]\")\n",
        "\n",
        "    # 从结果中提取出当前标签的样本（包括 原始样本 + 新增样本）\n",
        "    mask_current_label = (y_ == label)\n",
        "    X_current_label = X_[mask_current_label]\n",
        "    y_current_label = y_[mask_current_label]\n",
        "\n",
        "    # 拼接到最终结果\n",
        "    X_resampled = np.vstack((X_resampled, X_current_label))\n",
        "    y_resampled = np.hstack((y_resampled, y_current_label))\n",
        "\n",
        "    print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "    print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "#############################################\n",
        "\n",
        "# 3. 查看结果\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] After oversampling:')\n",
        "end_time = datetime.now()\n",
        "print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySil5tAjiOvy",
        "outputId": "1da5d340-f499-4fdb-8636-98133ab87d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/21/25 00:17:55] oversample_to: {2: 114300, 3: 114300, 5: 114300, 7: 114300, 9: 114300, 10: 114300, 13: 114300}\n",
            "\n",
            "[04/21/25 00:17:56] X_resampled.shape(before): (3641510, 70)\n",
            "  Labels(before): {0: 1600000, 1: 228953, 4: 548809, 6: 460953, 8: 369530, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 00:17:56] Oversampling [2]: 1000 -> 114300 ...\n",
            "  Time elapsed: 0:00:37.050501. [20250421 00:17:56 -> 20250421 00:18:33]\n",
            "  X_resampled.shape: (3755810, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 4: 548809, 6: 460953, 8: 369530, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 00:18:34] Oversampling [3]: 500 -> 114300 ...\n",
            "  Time elapsed: 0:00:18.538283. [20250421 00:18:34 -> 20250421 00:18:53]\n",
            "  X_resampled.shape: (3870110, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 6: 460953, 8: 369530, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 00:18:54] Oversampling [5]: 1384 -> 114300 ...\n",
            "  Time elapsed: 0:00:51.015972. [20250421 00:18:54 -> 20250421 00:19:45]\n",
            "  X_resampled.shape: (3984410, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 8: 369530, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 00:19:46] Oversampling [7]: 33206 -> 114300 ...\n",
            "  Time elapsed: 0:19:50.755433. [20250421 00:19:46 -> 20250421 00:39:37]\n",
            "  X_resampled.shape: (4098710, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 7: 114300, 8: 369530, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 00:39:39] Oversampling [9]: 111912 -> 114300 ...\n",
            "  Time elapsed: 1:06:06.090119. [20250421 00:39:39 -> 20250421 01:45:45]\n",
            "  X_resampled.shape: (4210622, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 7: 114300, 8: 369530, 9: 111912, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 01:45:47] Oversampling [10]: 8792 -> 114300 ...\n",
            "  Time elapsed: 0:05:09.048278. [20250421 01:45:47 -> 20250421 01:50:56]\n",
            "  X_resampled.shape: (4324922, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 7: 114300, 8: 369530, 9: 111912, 10: 114300, 11: 154683, 12: 128511, 14: 150071}\n",
            "\n",
            "[04/21/25 01:50:58] Oversampling [13]: 500 -> 114300 ...\n",
            "  Time elapsed: 0:00:20.089343. [20250421 01:50:58 -> 20250421 01:51:18]\n",
            "  X_resampled.shape: (4439222, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 7: 114300, 8: 369530, 9: 111912, 10: 114300, 11: 154683, 12: 128511, 13: 114300, 14: 150071}\n",
            "\n",
            "[04/21/25 01:51:19] After oversampling:\n",
            "  Time elapsed: 1:33:23.559038. [04/21/25 00:17:55 -> 04/21/25 01:51:19]\n",
            "  X_resampled.shape: (4439222, 70)\n",
            "  Labels: {0: 1600000, 1: 228953, 2: 114300, 3: 114300, 4: 548809, 5: 114300, 6: 460953, 7: 114300, 8: 369530, 9: 111912, 10: 114300, 11: 154683, 12: 128511, 13: 114300, 14: 150071}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存文件\n",
        "X_resampled_file = balanced_folder / f'{X_file.stem}_s{resample_scheme}_{oversampling_method}.npy'\n",
        "y_resampled_file = balanced_folder / f'{y_file.stem}_s{resample_scheme}_{oversampling_method}.npy'\n",
        "\n",
        "# 判断实际 oversample 之后的标签样本数，有没有达到目标数量 oversample_to 的 95%，没有的话，设置变量 incomplete 为 true\n",
        "incomplete = False\n",
        "incomplete_ratio = 0.95\n",
        "labels_counts = sorted(Counter(y_resampled).items())\n",
        "labels_counts = dict(labels_counts)\n",
        "for label, target in oversample_to.items():\n",
        "    if labels_counts[label] <= target * incomplete_ratio:\n",
        "        incomplete = True\n",
        "        # 文件名后面有个 + 号表示过采样不完全，需要使用额外的简单过采样进行数据补全\n",
        "        X_resampled_file = X_resampled_file.with_name(X_resampled_file.stem + '+.npy')\n",
        "        y_resampled_file = y_resampled_file.with_name(y_resampled_file.stem + '+.npy')\n",
        "        break\n",
        "\n",
        "np.save(X_resampled_file, X_resampled)\n",
        "np.save(y_resampled_file, y_resampled)\n",
        "\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] ✅ Saved to {X_resampled_file} & {y_resampled_file.name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XptFFRJh99TB",
        "outputId": "bb8820c5-1f8f-4892-c6b4-8b9c4c811f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/21/25 01:51:27] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/balanced/CSE-CIC-IDS2018/train_X_standard_s3_ROS+BLSMOTE.npy & train_label_standard_s3_ROS+BLSMOTE.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMOTE 补全数据\n",
        "\n",
        "因为基于 **邻居** 样本的过采样算法, 可能会因为找不到邻居而导致无法新增数据。<br/>\n",
        "所以在最后用 SMOTE 算法进行兜底, 补全不足 oversample_to 目标的样本。\n"
      ],
      "metadata": {
        "id": "tp6vxC9t_q25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "if not incomplete:\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] ✅ 无需补全数据')\n",
        "else:\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] ⚠️ 需要补全数据')\n",
        "\n",
        "    # 加载训练集文件\n",
        "    # X_resampled_file = balanced_folder / f'{X_file.stem}_s{resample_scheme}_BLSMOTE.npy'\n",
        "    # y_resampled_file = balanced_folder / f'{y_file.stem}_s{resample_scheme}_BLSMOTE.npy'\n",
        "\n",
        "    # X_resampled = np.load(X_resampled_file)\n",
        "    # y_resampled = np.load(y_resampled_file)\n",
        "\n",
        "    labels_counts = sorted(Counter(y_resampled).items())\n",
        "    labels_counts = dict(labels_counts)\n",
        "\n",
        "    print(f'X_resampled.shape: {X_resampled.shape}')\n",
        "    print(f'Labels: { {int(k): v for k, v in labels_counts.items()} }\\n')\n",
        "\n",
        "    # 指定需要补充过采样的标签与目标\n",
        "    oversample_to = {}\n",
        "    for label, target in resample_to.items():\n",
        "        if labels_counts[label] < resample_to[label]:\n",
        "            oversample_to[label] = target\n",
        "    print(f'oversample_to: {oversample_to}\\n')\n",
        "\n",
        "    # 使用 SMOTE 过采样\n",
        "    sampler = SMOTE(sampling_strategy=oversample_to, random_state=42)\n",
        "    X_completed, y_completed = sampler.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "    # 打印结果\n",
        "    print(f'  X_completed.shape: {X_completed.shape}')\n",
        "    print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_completed).items())} }\\n')\n",
        "\n",
        "    # 保存结果\n",
        "    X_completed_file = X_resampled_file.with_name(X_resampled_file.stem + 'SMOTE.npy')\n",
        "    y_completed_file = y_resampled_file.with_name(y_resampled_file.stem + 'SMOTE.npy')\n",
        "\n",
        "    np.save(X_completed_file, X_completed)\n",
        "    np.save(y_completed_file, y_completed)\n",
        "\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] ✅ Saved to {X_completed_file} & {y_completed_file.name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tAavlt9AcNo",
        "outputId": "4f5aa32c-e7a8-42cd-b848-edde9c56bd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/21/25 01:51:27] ✅ 无需补全数据\n"
          ]
        }
      ]
    }
  ]
}