{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/imbalance%20processing/UnderSampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv4skFSheBzA"
      },
      "source": [
        "# 使用几种 UnderSampling 算法对数据集进行欠采样\n",
        "\n",
        "- **RUS** (RandomUnderSampler)\n",
        "- **IHT** (InstanceHardnessThreshold)\n",
        "- **NM** (NearMiss, 丢弃！)\n",
        "- **FNM** (FAISS NearMiss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqqi2ITUeOmB"
      },
      "source": [
        "## Google Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzbTh_MiPCpH",
        "outputId": "23537adb-3efa-45c0-cd5d-9087822982a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR21AFUgeYXb"
      },
      "source": [
        "## Modules import & Globals setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKNH9UjKeZmU"
      },
      "outputs": [],
      "source": [
        "### Modules ###\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Globals ###\n",
        "\n",
        "## Label 特征的数值化编码\n",
        "label_mapping = {\n",
        "    \"Benign\": 0,\n",
        "    \"Bot\": 1,\n",
        "    \"Brute Force -Web\": 2,\n",
        "    \"Brute Force -XSS\": 3,\n",
        "    \"DDOS attack-HOIC\": 4,\n",
        "    \"DDOS attack-LOIC-UDP\": 5,\n",
        "    \"DDoS attacks-LOIC-HTTP\": 6,\n",
        "    \"DoS attacks-GoldenEye\": 7,\n",
        "    \"DoS attacks-Hulk\": 8,\n",
        "    \"DoS attacks-SlowHTTPTest\": 9,\n",
        "    \"DoS attacks-Slowloris\": 10,\n",
        "    \"FTP-BruteForce\": 11,\n",
        "    \"Infilteration\": 12,\n",
        "    \"SQL Injection\": 13,\n",
        "    \"SSH-Bruteforce\": 14\n",
        "}\n",
        "\n",
        "## 计划尝试三种样本分布模式\n",
        "resample_schemes = {\n",
        "    # 模式1. (标签0:非0标签总和) ≈ (160:157); 非0标签按大概比例增强\n",
        "    1: {\n",
        "        0: 1600000,  # 保持不变\n",
        "        1: 200000,   # ⤵️ 228953\n",
        "        2: 20000,    # ⤴️ 489\n",
        "        3: 20000,    # ⤴️ 184\n",
        "        4: 200000,   # ⤵️ 548809\n",
        "        5: 20000,    # ⤴️ 1384\n",
        "        6: 200000,   # ⤵️ 460953\n",
        "        7: 100000,   # ⤴️ 33206\n",
        "        8: 200000,   # ⤵️ 369530\n",
        "        9: 111912,   # ⤴️ 111912\n",
        "        10: 50000,   # ⤴️ 8792\n",
        "        11: 154683,  # ⤴️ 154683\n",
        "        12: 128511,  # ⤴️ 128511\n",
        "        13: 20000,   # ⤴️ 70\n",
        "        14: 150071   # ⤴️ 150071\n",
        "    },\n",
        "    # 模式2. (标签0:最多非0标签样本) ≈ (3:2)\n",
        "    2: {\n",
        "        0: 300000,   # ⤵️ 1600000\n",
        "        1: 200000,   # ⤵️ 228953\n",
        "        2: 20000,    # ⤴️ 489\n",
        "        3: 20000,    # ⤴️ 184\n",
        "        4: 200000,   # ⤵️ 548809\n",
        "        5: 20000,    # ⤴️ 1384\n",
        "        6: 200000,   # ⤵️ 460953\n",
        "        7: 100000,   # ⤴️ 33206\n",
        "        8: 200000,   # ⤵️ 369530\n",
        "        9: 111912,   # ⤴️ 111912\n",
        "        10: 50000,   # ⤴️ 8792\n",
        "        11: 154683,  # ⤴️ 154683\n",
        "        12: 128511,  # ⤴️ 128511\n",
        "        13: 20000,   # ⤴️ 70\n",
        "        14: 150071   # ⤴️ 150071\n",
        "    },\n",
        "    # 模式3. (标签0:非0标签总和) = (1:1); 每种非0标签都占 114300 个样本\n",
        "    3: {\n",
        "        0: 1600000,\n",
        "        **{k: 114300 for k in range(1, 15)}\n",
        "    },\n",
        "    # 模式4. 所有标签都 20万样本\n",
        "    4: {\n",
        "       **{k: 200000 for k in range(0, 15)}\n",
        "    },\n",
        "}\n",
        "\n",
        "## 数据目录\n",
        "datasets_folder = Path('/content/drive/MyDrive/NYIT/870/datasets')\n",
        "dataset = 'CSE-CIC-IDS2018'\n",
        "preprocessed_folder = datasets_folder / 'preprocessed' / dataset\n",
        "balanced_folder = datasets_folder / 'balanced' / dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnjufbHiJFDr"
      },
      "outputs": [],
      "source": [
        "scaling_method = 'standard'\n",
        "# scaling_method = 'minmax'\n",
        "\n",
        "resample_scheme = 2\n",
        "resample_to = resample_schemes[resample_scheme]\n",
        "\n",
        "oversampling_method = 'ROS1+cGAN'\n",
        "# oversampling_method = 'ADASYN'\n",
        "# oversampling_method = 'BLSMOTE+SMOTE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXZ4E8wJlzLF",
        "outputId": "c63941a3-88e9-41c6-f5c2-8a13a820b17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04/26/25 22:56:03\n",
            "train_X_standard_s2_ROS1+cGAN.shape: (3983422, 70)\n",
            "Labels: {0: 1600000, 1: 228953, 2: 20000, 3: 20000, 4: 548809, 5: 20000, 6: 460953, 7: 100000, 8: 369530, 9: 111912, 10: 50000, 11: 154683, 12: 128511, 13: 20000, 14: 150071}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_file = balanced_folder / f'train_X_{scaling_method}_s{resample_scheme}_{oversampling_method}.npy'\n",
        "y_file = balanced_folder / f'train_label_{scaling_method}_s{resample_scheme}_{oversampling_method}.npy'\n",
        "\n",
        "# 加载训练集文件\n",
        "X = np.load(X_file)\n",
        "y = np.load(y_file)\n",
        "\n",
        "labels_counts = sorted(Counter(y).items())\n",
        "labels_counts = dict(labels_counts)\n",
        "\n",
        "print(datetime.now().strftime('%x %X'))\n",
        "print(f'{X_file.stem}.shape: {X.shape}')\n",
        "print(f'Labels: { {int(k): v for k, v in labels_counts.items()} }\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo1ayoAkLEDm",
        "outputId": "31476a8c-ce41-4457-8eae-e99c06eecb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "undersample_to: {0: 300000, 1: 200000, 4: 200000, 6: 200000, 8: 200000}\n"
          ]
        }
      ],
      "source": [
        "# 指定需要欠采样的标签与目标\n",
        "undersample_to = {}\n",
        "for label, target in resample_to.items():\n",
        "    if labels_counts[label] > resample_to[label]:\n",
        "        undersample_to[label] = target\n",
        "print(f'undersample_to: {undersample_to}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNwpu2TO0080"
      },
      "source": [
        "## **RUS** (RandomUnderSampler)\n",
        "随机从多数类样本中删除样本，直到达到目标数量。\n",
        "* 速度快到令人感动 (ಥ﹏ಥ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvMefGPD0483",
        "outputId": "0c490b6f-e981-415c-c130-362ae6caf258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After RUS undersampling:\n",
            "  Time elapsed: 0:00:00.579592. [04/26/25 22:56:03 -> 04/26/25 22:56:04]\n",
            "  X_resampled.shape: (1875177, 70)\n",
            "  Labels: {0: 300000, 1: 200000, 2: 20000, 3: 20000, 4: 200000, 5: 20000, 6: 200000, 7: 100000, 8: 200000, 9: 111912, 10: 50000, 11: 154683, 12: 128511, 13: 20000, 14: 150071}\n",
            "\n",
            "[04/26/25 22:56:08] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/balanced/CSE-CIC-IDS2018/train_X_standard_s2_ROS1+cGAN_RUS.npy & train_label_standard_s2_ROS1+cGAN_RUS.npy\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "undersampling_method = 'RUS'\n",
        "start_time = datetime.now()\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy=undersample_to, random_state=42)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f'After {undersampling_method} undersampling:')\n",
        "end_time = datetime.now()\n",
        "print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "\n",
        "# 保存文件\n",
        "X_resampled_file = X_file.with_name(f'{X_file.stem}_{undersampling_method}.npy')\n",
        "y_resampled_file = y_file.with_name(f'{y_file.stem}_{undersampling_method}.npy')\n",
        "np.save(X_resampled_file, X_resampled)\n",
        "np.save(y_resampled_file, y_resampled)\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {X_resampled_file} & {y_resampled_file.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 补充: 使用 TomekLink 清洗边界\n",
        "# from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# print(f\"[{datetime.now().strftime('%x %X')}] ⏰ TomekLinks cleaning...\")\n",
        "# start_time = datetime.now()\n",
        "\n",
        "# undersampler = TomekLinks(n_jobs=-1)\n",
        "# X_resampled_tl, y_resampled_tl = undersampler.fit_resample(X_resampled, y_resampled)\n",
        "\n",
        "# end_time = datetime.now()\n",
        "# print(f'After TomekLinks undersampling:')\n",
        "# print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "# print(f'  X_resampled.shape: {X_resampled_tl.shape}')\n",
        "# print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled_tl).items())} }\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqLpdIrubFQs",
        "outputId": "061cd5f3-210e-4841-eada-60b86cb1b47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[04/21/25 17:40:26] ⏰ TomekLinks cleaning...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75awp9PSfBmN"
      },
      "source": [
        "## **IHT** (InstanceHardnessThreshold)\n",
        "首先用一个分类器(默认为 LogisticRegression)对每个样本预测概率，计算这个样本被正确分类的难度，然后根据这个\"难度\"排序，删除哪些最难分类的样本。\n",
        "\n",
        "- 耗时\n",
        "- 内存消耗大\n",
        "- 大数据时需要减少 `cv` 参数, 不然可能耗尽内存并报错 ` TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.`\n",
        "- 无法保存欠采样到指定数量\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySil5tAjiOvy",
        "outputId": "76d11db8-1ace-4306-e3cb-bf0452dbf375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/19/25 23:17:12] Start IHT undersampling...\n",
            "original X shape: (4439222, 70)\n",
            "undersample_to: {1: 114300, 4: 114300, 6: 114300, 8: 114300, 11: 114300, 12: 114300, 14: 114300}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TerminatedWorkerError",
          "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-58f104dc9e9b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mundersampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstanceHardnessThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mundersample_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mundersampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{datetime.now().strftime('%x %X')}] After {undersampling_method} undersampling:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/under_sampling/_prototype_selection/_instance_hardness_threshold.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[0;32m--> 166\u001b[0;31m         probabilities = cross_val_predict(\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m   1248\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m   1249\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import InstanceHardnessThreshold\n",
        "\n",
        "undersampling_method = 'IHT'\n",
        "start_time = datetime.now()\n",
        "print(f\"[{start_time.strftime('%x %X')}] Start {undersampling_method} undersampling...\")\n",
        "print(f'original X shape: {X.shape}')\n",
        "print(f'undersample_to: {undersample_to}')\n",
        "\n",
        "undersampler = InstanceHardnessThreshold(sampling_strategy=undersample_to, random_state=42, cv=3, n_jobs=-1)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] After {undersampling_method} undersampling:\")\n",
        "end_time = datetime.now()\n",
        "print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "\n",
        "# 保存文件\n",
        "X_resampled_file = X_file.with_name(f'{X_file.stem}_{undersampling_method}.npy')\n",
        "y_resampled_file = y_file.with_name(f'{y_file.stem}_{undersampling_method}.npy')\n",
        "np.save(X_resampled_file, X_resampled)\n",
        "np.save(y_resampled_file, y_resampled)\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {X_resampled_file} & {y_resampled_file.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VAnxs4dMJy7"
      },
      "source": [
        "## **NM** (NearMiss) 放弃！！\n",
        "根据样本与少数类样本之间的\"距离\"来选择要保留的多数类样本。<br/>\n",
        "**内存开销超级大！**<br/>\n",
        "NearMiss 有三种版本:\n",
        "* **version 1** 对每个(多数类)样本，计算它到 k 个最近邻居的平均距离，保留平均距离最小的。\n",
        "  * 更容易导致某些偏远的少数类样本没有多数类\"邻居\", 不利于后续对少数类样本进行过采样。\n",
        "* **version 2** 对每个(多数类)样本，计算它到 k 个最远邻居的平均距离，保留平均距离最小的。\n",
        "  * 相比于 version 1, 3 更加保守一点。\n",
        "* **version 3** 从少数类样本出发，选择它最近的 k 个多数类样本进行保留。\n",
        "  * 对于极度 imbalance 的数据，会导致大部分多数类样本被删除(无法根据指定数量进行保留)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxtnsxeOO3S-",
        "outputId": "a9a1fa19-a836-4cd8-9584-e4443edc79fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "undersample to: {1: 200000, 2: 20000, 3: 20000, 4: 200000, 6: 200000, 7: 100000, 8: 200000, 13: 20000}\n"
          ]
        }
      ],
      "source": [
        "# from imblearn.under_sampling import NearMiss\n",
        "# print(f'undersample to: {undersample_to}')\n",
        "# undersampling_method = 'NM'\n",
        "# start_time = datetime.now()\n",
        "\n",
        "# undersampler = NearMiss(sampling_strategy=undersample_to, version=2, n_neighbors=3, n_jobs=-1)\n",
        "# X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "# print(f'After {undersampling_method} undersampling:')\n",
        "# end_time = datetime.now()\n",
        "# print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "# print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "# print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "\n",
        "# # 保存文件\n",
        "# X_resampled_file = X_file.with_name(f'{X_file.stem}_{undersampling_method}.npy')\n",
        "# y_resampled_file = y_file.with_name(f'{y_file.stem}_{undersampling_method}.npy')\n",
        "# np.save(X_resampled_file, X_resampled)\n",
        "# np.save(y_resampled_file, y_resampled)\n",
        "# print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {X_resampled_file} & {y_resampled_file.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzsdGKr6BmH8"
      },
      "source": [
        "## **FNM** (FAISS-NearMiss)\n",
        "- 由于 imblearn 的 NM 在计算 KNN 近邻的时候需要大量内存，对于百万级别的数据就是灾难。\n",
        "\n",
        "- 所以改成使用 FAISS 库的 IndexHNSWFlat 算法计算近邻。。。速度快很多(但它不是完全精度，是近似值)\n",
        "\n",
        "- FAISS 还能利用 GPU 加速，但是看起来 colab 好像不支持\n",
        "\n",
        "- 代码是利用 chatGPT 老师跟 NearMiss 源码修改的，不保证正确性\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuPD2e-Dqqf7",
        "outputId": "9ce2efb7-689a-4c44-8b0e-2e1ae28ea29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: faiss-gpu\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: faiss-gpu-cu11==1.8.0.1 in /usr/local/lib/python3.11/dist-packages (1.8.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu11==1.8.0.1) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu11==1.8.0.1) (24.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11>=11.8.89 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu11==1.8.0.1) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cublas-cu11>=11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu11==1.8.0.1) (11.11.3.6)\n",
            "[04/07/25 03:38:34] Start FNM undersampling...\n",
            "[04/07/25 05:25:20] Caculating nearest neighbors by FAISS...\n",
            "[04/07/25 05:27:40]   Nearest neighbors shape: (3983422, 4)\n",
            "[04/07/25 05:27:40]   distances shape: (3983422, 4)\n",
            "[04/07/25 05:27:41] processing target class 0...\n",
            "[04/07/25 05:27:41] processing target class 1...\n",
            "[04/07/25 05:27:41] processing target class 2...\n",
            "[04/07/25 05:27:41] processing target class 3...\n",
            "[04/07/25 05:27:41] processing target class 4...\n",
            "[04/07/25 05:27:42] processing target class 5...\n",
            "[04/07/25 05:27:42] processing target class 6...\n",
            "[04/07/25 05:27:42] processing target class 7...\n",
            "[04/07/25 05:27:42] processing target class 8...\n",
            "[04/07/25 05:27:43] processing target class 9...\n",
            "[04/07/25 05:27:43] processing target class 10...\n",
            "[04/07/25 05:27:43] processing target class 11...\n",
            "[04/07/25 05:27:43] processing target class 12...\n",
            "[04/07/25 05:27:43] processing target class 13...\n",
            "[04/07/25 05:27:43] processing target class 14...\n",
            "After FNM undersampling:\n",
            "  Time elapsed: 1:49:10.625347. [04/07/25 03:38:34 -> 04/07/25 05:27:45]\n",
            "  X_resampled.shape: (3175177, 70)\n",
            "  Labels: {0: 1600000, 1: 200000, 2: 20000, 3: 20000, 4: 200000, 5: 20000, 6: 200000, 7: 100000, 8: 200000, 9: 111912, 10: 50000, 11: 154683, 12: 128511, 13: 20000, 14: 150071}\n",
            "\n",
            "[04/07/25 05:27:55] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/balanced/CSE-CIC-IDS2018/train_X_standard_s1_cGAN_FNM.npy & train_label_standard_s1_cGAN_FNM.npy\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "## 修改为使用 faiss 进行近邻搜索\n",
        "############################################\n",
        "# 打印是否安装 faiss-gpu 库\n",
        "!pip show faiss-gpu|grep Version:\n",
        "!echo -e \"\\033[0m\"  # 重置终端文字颜色\n",
        "\n",
        "# 安装 faiss-gpu 库\n",
        "!apt install libomp-dev\n",
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu-cu11==1.8.0.1\n",
        "\n",
        "\n",
        "import faiss\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.utils import _safe_indexing\n",
        "\n",
        "class FAISSNearMiss(NearMiss):\n",
        "    def _fit_resample(self, X, y):\n",
        "        # 创建 FAISS 索引 (FlatL2, 速度太慢！)\n",
        "        # index = faiss.IndexFlatL2(X.shape[1])\n",
        "        # index.add(X.astype(np.float32))  # FAISS 需要数据类型为 float32\n",
        "\n",
        "        # 创建 FAISS 索引 (HNSW)\n",
        "        M = 32  # 每个节点的最大邻居数，越大越准确，但速度越慢\n",
        "        efConstruction = 1024  # 索引构建时的候选邻居数，越大越准确，但速度越慢\n",
        "        index = faiss.IndexHNSWFlat(X.shape[1], M)\n",
        "        index.hnsw.efConstruction = efConstruction  # 设置 HNSW 索引的参数\n",
        "\n",
        "        # FAISS 需要数据类型为 float32\n",
        "        index.add(X.astype(np.float32))\n",
        "        # 执行 FAISS 的最近邻搜索，找到每个样本的邻居\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}] Caculating nearest neighbors by FAISS...\")\n",
        "        distances, nearest_neighbors = index.search(X, k=self.n_neighbors+1)\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}]   Nearest neighbors shape: {nearest_neighbors.shape}\")\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}]   distances shape: {distances.shape}\")\n",
        "\n",
        "        # 这个虽然没啥用了，但 NM 后续还会引用 self.nn_.n_neighbors 属性(为什么不直接用 sefl.n_neighbors ... )\n",
        "        self.nn_ = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
        "        self.nn_.set_params(**{\"n_jobs\": self.n_jobs})\n",
        "\n",
        "        ########################################################################\n",
        "        # 下面是从 NearMiss 源码修改的\n",
        "\n",
        "        idx_under = np.empty((0,), dtype=int)\n",
        "\n",
        "        target_stats = Counter(y)\n",
        "        class_minority = min(target_stats, key=target_stats.get)\n",
        "        # print(f\"[{datetime.now().strftime('%x %X')}] class_minority: {class_minority}\")\n",
        "        minority_class_indices = np.flatnonzero(y == class_minority)\n",
        "\n",
        "        for target_class in np.unique(y):\n",
        "            print(f\"[{datetime.now().strftime('%x %X')}] processing target class {target_class}...\")\n",
        "            if target_class in self.sampling_strategy_.keys():\n",
        "                n_samples = self.sampling_strategy_[target_class]\n",
        "                target_class_indices = np.flatnonzero(y == target_class)\n",
        "                X_class = _safe_indexing(X, target_class_indices)\n",
        "                y_class = _safe_indexing(y, target_class_indices)\n",
        "\n",
        "                if self.version == 1:\n",
        "                    dist_vec = distances[target_class_indices]\n",
        "                    idx_vec = nearest_neighbors[target_class_indices]\n",
        "                    index_target_class = self._selection_dist_based(\n",
        "                        X,\n",
        "                        y,\n",
        "                        dist_vec,\n",
        "                        n_samples,\n",
        "                        target_class,\n",
        "                        sel_strategy=\"nearest\",\n",
        "                    )\n",
        "                else:\n",
        "                    raise NotImplementedError('Only version 1 is implemented for FAISSNearMiss')\n",
        "            else:\n",
        "                index_target_class = slice(None)\n",
        "\n",
        "            idx_under = np.concatenate(\n",
        "                (\n",
        "                    idx_under,\n",
        "                    np.flatnonzero(y == target_class)[index_target_class],\n",
        "                ),\n",
        "                axis=0,\n",
        "            )\n",
        "\n",
        "        self.sample_indices_ = idx_under\n",
        "\n",
        "        return _safe_indexing(X, idx_under), _safe_indexing(y, idx_under)\n",
        "\n",
        "undersampling_method = 'FNM'\n",
        "start_time = datetime.now()\n",
        "print(f\"[{start_time.strftime('%x %X')}] Start {undersampling_method} undersampling...\")\n",
        "\n",
        "undersampler = FAISSNearMiss(sampling_strategy=undersample_to)\n",
        "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f'After {undersampling_method} undersampling:')\n",
        "end_time = datetime.now()\n",
        "print(f\"  Time elapsed: {end_time - start_time}. [{start_time.strftime('%x %X')} -> {end_time.strftime('%x %X')}]\")\n",
        "print(f'  X_resampled.shape: {X_resampled.shape}')\n",
        "print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y_resampled).items())} }\\n')\n",
        "\n",
        "# 保存文件\n",
        "X_resampled_file = X_file.with_name(f'{X_file.stem}_{undersampling_method}.npy')\n",
        "y_resampled_file = y_file.with_name(f'{y_file.stem}_{undersampling_method}.npy')\n",
        "np.save(X_resampled_file, X_resampled)\n",
        "np.save(y_resampled_file, y_resampled)\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {X_resampled_file} & {y_resampled_file.name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gqqi2ITUeOmB",
        "-VAnxs4dMJy7",
        "AzsdGKr6BmH8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}