{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/imbalance%20processing/CGAN_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv4skFSheBzA"
      },
      "source": [
        "# 使用 ROS+CGAN 对训练集进行过采样\n",
        "🚀 NYIT 880 | 🧑🏻‍💻 funway\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR21AFUgeYXb"
      },
      "source": [
        "## Modules import & Globals setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKNH9UjKeZmU",
        "outputId": "b735f6b0-4194-4a6f-99cd-41d1ccfe9b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[06/25/25 06:14:22] 🏷️ Label mapping: {'Benign': 0, 'Bot': 1, 'Brute Force -Web': 2, 'Brute Force -XSS': 3, 'DDOS attack-HOIC': 4, 'DDOS attack-LOIC-UDP': 5, 'DDoS attacks-LOIC-HTTP': 6, 'DoS attacks-GoldenEye': 7, 'DoS attacks-Hulk': 8, 'DoS attacks-SlowHTTPTest': 9, 'DoS attacks-Slowloris': 10, 'FTP-BruteForce': 11, 'Infilteration': 12, 'SQL Injection': 13, 'SSH-Bruteforce': 14}\n",
            "导入 utility.ipynb 模块. version 1.0.1\n"
          ]
        }
      ],
      "source": [
        "### Modules ###\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "## mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "### Globals ###\n",
        "## 数据文件目录\n",
        "dataset = 'cse-cic-ids2018'\n",
        "project_folder = Path('/content/drive/MyDrive/NYIT/880')\n",
        "preprocessed_folder = project_folder / 'data/preprocessed'\n",
        "scaled_folder = preprocessed_folder / 'scaled'\n",
        "splits_folder = preprocessed_folder / 'splits'\n",
        "balanced_folder = project_folder / 'data/balanced'\n",
        "\n",
        "## Label 列的所有可能值(有序)\n",
        "unique_labels = ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] 🏷️ Label mapping: {label_mapping}\")\n",
        "\n",
        "# 定义极少数类. [13, 3, 2] 属于极少数, [5, 10, 7] 属于少数\n",
        "minority_labels = [13, 3, 2, 5, 10, 7]\n",
        "\n",
        "### 全局随机数种子 ###\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "op_seed = 42\n",
        "\n",
        "### Utilities ###\n",
        "# 导入 utility.ipynb 模块\n",
        "%run /content/drive/MyDrive/NYIT/880/code/utils/utility.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4DGprZsKWAz"
      },
      "source": [
        "## 可调参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K-SqflxGQ5rK"
      },
      "outputs": [],
      "source": [
        "# 是否强制重新训练 CGAN\n",
        "retrain = False\n",
        "\n",
        "# 选择 scaling 方法. 可选[standard, minmax, robust, l1pminmax]\n",
        "scaling_method = 'minmax'\n",
        "\n",
        "# 过采样方法. 可以选[cgan-a, cgan-m, cgan-b, ros1+cgan-a, ros2+cgan-b, ...]\n",
        "oversampling_method = 'cgan-m'\n",
        "\n",
        "## CGAN 参数 ##\n",
        "noise_dim = 128     # 噪声维度(给生成器的)\n",
        "epochs = 500        # 多少轮训练\n",
        "batch_size = 512    # 每轮训练中划分 batch 的大小\n",
        "buffer_size = 200_000  # tf.data 随机切片数据时的缓存大小\n",
        "\n",
        "gen_embed_dim = 128                # 生成器嵌入层维度\n",
        "gen_hidden_dims = [128, 256, 512] # 生成器隐藏层\n",
        "gen_learning_rate = 3e-4          # 生成器学习率\n",
        "\n",
        "disc_embed_dim = 64           # 判别器嵌入层维度\n",
        "disc_hidden_dims = [256, 128] # 判别器隐藏层\n",
        "disc_learning_rate = 1e-4     # 判别器学习率\n",
        "\n",
        "# 生成过采样文件 (空数组就表示不生成 过采样文件)\n",
        "resample_outputs = []\n",
        "\n",
        "# 在生成过采样文件之前, 是否先用 CGAN 判别器删除质量差的样本\n",
        "# cgan_filter_strategy = 0 表示不使用 CGAN 进行删除\n",
        "cgan_filter_strategy = 0 # 去 utility 里的 filter_schemes 取值\n",
        "if cgan_filter_strategy and 'cgan-m' in oversampling_method:\n",
        "    raise Exception('不要使用 cgan-m 对多数类进行欠采样！因为 cgan-m 是仅针对 minority 进行训练的。')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM7RomoyKpSt"
      },
      "source": [
        "## 加载训练集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DXZ4E8wJlzLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cf6781-7f4a-4fac-8317-fbf56674c594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/24/25 23:14:38 PDT] train_X_minmax.npy shape: (3797547, 70), train_y.npy shape: (3797547,)\n",
            "Labels: {0: 1600000, 1: 228953, 2: 489, 3: 184, 4: 548809, 5: 1384, 6: 460953, 7: 33206, 8: 369530, 9: 111912, 10: 8792, 11: 154683, 12: 128511, 13: 70, 14: 150071}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_file = splits_folder / f'train_X_{scaling_method}.npy'\n",
        "y_file = splits_folder / f'train_y.npy'\n",
        "\n",
        "# 加载训练集文件\n",
        "X = np.load(X_file)\n",
        "y = np.load(y_file)\n",
        "\n",
        "print(f'[{now()}] {X_file.name} shape: {X.shape}, {y_file.name} shape: {y.shape}')\n",
        "print(f'Labels: { {int(k): v for k, v in sorted(Counter(y).items())} }\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75awp9PSfBmN"
      },
      "source": [
        "## CGAN 定义\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhavXS3_0bpG"
      },
      "source": [
        "### 定义辅助函数与类"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B9-UoZzDQhsB"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def select_cgan_subset(X, y, mode, rus_target=100_000):\n",
        "    \"\"\"\n",
        "    Selects a subset of the data for cGAN training based on the specified mode.\n",
        "    \"\"\"\n",
        "    if mode == 'a':\n",
        "        # 返回全量数据\n",
        "        return X, y\n",
        "\n",
        "    elif mode == 'm':\n",
        "        # 返回极少数类数据\n",
        "        mask = np.isin(y, minority_labels)\n",
        "        return X[mask], y[mask]\n",
        "\n",
        "    elif mode == 'f':\n",
        "        mask = np.isin(y, minority_labels + [9, 12])\n",
        "        return X[mask], y[mask]\n",
        "\n",
        "    elif mode == 'b':\n",
        "        # 返回平衡后的训练数据 (将多数类都下采样到 100_000)\n",
        "        strategy = {label: rus_target for label in np.unique(y) if label not in minority_labels}\n",
        "        rus = RandomUnderSampler(sampling_strategy=strategy, random_state=op_seed)\n",
        "        return rus.fit_resample(X, y)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid mode: {mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OFGJh4Zq1QLh"
      },
      "outputs": [],
      "source": [
        "# Callback: adjust learning rates based on delta_loss\n",
        "class MyReduceLR(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    如果 delta_loss 连续 {patience} 次大于 {delta_threshold} 或者小于 -{delta_threshold}，则调整学习率。\n",
        "    \"\"\"\n",
        "    def __init__(self, delta_threshold=1.0, patience=5, factor=0.5, min_lr=1e-8):\n",
        "        super().__init__()\n",
        "        self.delta_threshold = delta_threshold\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.min_lr = min_lr\n",
        "\n",
        "        self.d_bad = 0\n",
        "        self.g_bad = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        delta = logs.get('delta_loss')\n",
        "        if delta is None:\n",
        "            return\n",
        "\n",
        "        # 如果 d_loss 比 g_loss 小，并且相差大于 delta_threshold\n",
        "        if delta <= -self.delta_threshold:\n",
        "            self.d_bad += 1\n",
        "        else:\n",
        "            self.d_bad = 0\n",
        "\n",
        "        # 如果 d_loss 比 g_loss 大，并且相差大于 delta_threshold\n",
        "        if delta >= self.delta_threshold:\n",
        "            self.g_bad += 1\n",
        "        else:\n",
        "            self.g_bad = 0\n",
        "\n",
        "        # Apply LR adjustments\n",
        "        if self.d_bad >= self.patience:\n",
        "            old_lr = float(self.model.d_optimizer.learning_rate)\n",
        "            new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "            if new_lr < old_lr:\n",
        "              self.model.d_optimizer.learning_rate.assign(new_lr)\n",
        "              self.d_bad = 0\n",
        "              print(f\"\\n[{now()}] Adjust discriminator\\'s learning rate to {new_lr}\")\n",
        "        if self.g_bad >= self.patience:\n",
        "            old_lr = float(self.model.g_optimizer.learning_rate)\n",
        "            new_lr = max(old_lr * self.factor, self.min_lr)\n",
        "            if new_lr < old_lr:\n",
        "              self.model.g_optimizer.learning_rate.assign(new_lr)\n",
        "              self.g_bad = 0\n",
        "              print(f\"\\n[{now()}] Adjust generator\\'s learning rate to {new_lr}\")\n",
        "\n",
        "\n",
        "# Callback: early stopping when balanced\n",
        "class MyEarlyStopping(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    如果 CGAN 的 |delta_loss| 连续 {patience} 次在 {balance_tolerance} 之间，表示 CGAN 已经收敛，停止训练。\n",
        "    \"\"\"\n",
        "    def __init__(self, balance_tolerance=0.1, patience=10):\n",
        "        super().__init__()\n",
        "        self.balance_tolerance = balance_tolerance\n",
        "        self.patience = patience\n",
        "        self.balance = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        delta = logs.get('delta_loss')\n",
        "        # print(f\"[{datetime.now().strftime('%x %X')}] {logs}\", file=sys.stderr)\n",
        "        # d = self.model.disc_loss_metric.result().numpy()\n",
        "        # g = self.model.gen_loss_metric.result().numpy()\n",
        "        # dl = self.model.delta_loss_metric.result().numpy()\n",
        "        # print(f\"[{datetime.now().strftime('%x %X')}] {d, g, dl}\", file=sys.stderr)\n",
        "\n",
        "        if delta is None:\n",
        "            return\n",
        "\n",
        "        # Check balance condition\n",
        "        if abs(delta) <= self.balance_tolerance:\n",
        "            self.balance += 1\n",
        "        else:\n",
        "            self.balance = 0\n",
        "\n",
        "        if self.balance >= self.patience:\n",
        "            self.model.stop_training = True\n",
        "            print(f\"\\n[{datetime.now().strftime('%x %X')}] Early stopping triggered. CGAN is balanced.\")\n",
        "\n",
        "\n",
        "class BalanceCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, delta_threshold=0.8, extra_steps=2):\n",
        "        super().__init__()\n",
        "        self.delta_threshold = delta_threshold\n",
        "        self.extra_steps = extra_steps\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        logs = logs or {}\n",
        "        d_loss = logs.get('discriminator_loss')\n",
        "        g_loss = logs.get('generator_loss')\n",
        "\n",
        "        if d_loss is not None and g_loss is not None:\n",
        "            delta_loss = d_loss - g_loss\n",
        "\n",
        "            if delta_loss < -self.delta_threshold:\n",
        "                # D-loss 太低，需要暂停\n",
        "                self.model.pause_D = True\n",
        "                self.model.extra_steps_G = self.extra_steps\n",
        "                # tf.print('暂停 D')\n",
        "            elif delta_loss > self.delta_threshold:\n",
        "                # G-loss 太低，需要暂停\n",
        "                self.model.pause_G = True\n",
        "                self.model.extra_steps_D = self.extra_steps\n",
        "                # tf.print('暂停 G')\n",
        "            else:\n",
        "                self.model.pause_D = False\n",
        "                self.model.pause_G = False\n",
        "                self.model.extra_steps_D = 0\n",
        "                self.model.extra_steps_G = 0\n",
        "\n",
        "class SaveOnInterval(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    每 Interval 轮的时候，保存一次模型\n",
        "    \"\"\"\n",
        "    def __init__(self, interval, dest_gen_file, dest_dis_file):\n",
        "        super().__init__()\n",
        "        self.interval = interval\n",
        "        self.dest_gen_file = dest_gen_file\n",
        "        self.dest_dis_file = dest_dis_file\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # epoch 从 0 开始算，故 +1\n",
        "        epoch_num = epoch + 1\n",
        "        max_epochs = self.params['epochs']\n",
        "\n",
        "        if epoch_num % self.interval == 0 and epoch_num < max_epochs:\n",
        "            gen_file = self.dest_gen_file.with_name(self.dest_gen_file.name.replace(f'e{max_epochs},', f'e{epoch_num},'))\n",
        "            dis_file = self.dest_dis_file.with_name(self.dest_dis_file.name.replace(f'e{max_epochs},', f'e{epoch_num},'))\n",
        "\n",
        "            self.model.generator.save(gen_file)\n",
        "            self.model.discriminator.save(dis_file)\n",
        "\n",
        "            print(f'\\n[{now()}] 💾 Saved model at epoch {epoch_num} to: {gen_file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUwtAak0tyuJ"
      },
      "source": [
        "### 定义 cGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ySil5tAjiOvy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# ---------------- Generator Definition ----------------\n",
        "def build_generator(num_classes: int,\n",
        "                    feature_dim: int,\n",
        "                    noise_dim: int = 128,\n",
        "                    embed_dim: int = 64,\n",
        "                    hidden_dims: list = [128, 256, 512]\n",
        "                    ) -> Model:\n",
        "\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] Building generator with: num_classes={num_classes}, feature_dim={feature_dim}, noise_dim={noise_dim}, embed_dim={embed_dim}, hidden_dims={hidden_dims}\")\n",
        "\n",
        "    # 定义输入层\n",
        "    noise_input = layers.Input(shape=(noise_dim,), name='noise_input')         # 噪声输入，输入一个 noise_dim 维的向量作为噪声\n",
        "    label_input = layers.Input(shape=(1,), dtype='int32', name='label_input')  # 类别输入, 输入一个整数作为类别标签\n",
        "\n",
        "    # 类别嵌入层\n",
        "    label_embedding = layers.Embedding(input_dim=num_classes, output_dim=embed_dim)(label_input)  # 将类别标签映射为嵌入向量(embed_dim 维)\n",
        "    label_embedding = layers.Flatten()(label_embedding)  # 将嵌入向量展平, (1, embed_dim) -> (embed_dim,)\n",
        "\n",
        "    # 合并 噪声向量 和 类别嵌入向量\n",
        "    # 合并后的向量维度为 (noise_dim + embed_dim,)\n",
        "    x = layers.Concatenate()([noise_input, label_embedding])\n",
        "\n",
        "    # 隐藏层 (激活函数为 relu)\n",
        "    for dim in hidden_dims:\n",
        "        x = layers.Dense(dim, activation='relu')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # 输出层的激活函数要跟数据预处理的 scaling 方法适配\n",
        "    activation = 'sigmoid' if scaling_method in ['minmax', 'l1pminmax'] else 'linear'\n",
        "\n",
        "    # 输出层 (输出 feature_dim 维的特征向量)\n",
        "    output = layers.Dense(feature_dim, activation=activation, name='generated_data')(x)\n",
        "\n",
        "    # 返回生成器模型\n",
        "    # 该模型接受两个输入，一个是噪声向量，一个是类别标签. 输出生成的特征向量\n",
        "    return Model([noise_input, label_input], output, name=\"Generator\")\n",
        "\n",
        "\n",
        "# ---------------- Discriminator Definition ----------------\n",
        "def build_discriminator(num_classes: int, feature_dim: int,\n",
        "                        embed_dim: int = 64,\n",
        "                        hidden_dims: list = [256, 128]\n",
        "                        ) -> Model:\n",
        "\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] Building discriminator with: num_classes={num_classes}, feature_dim={feature_dim}, embed_dim={embed_dim}, hidden_dims={hidden_dims}\")\n",
        "\n",
        "    # 定义输入层\n",
        "    data_input = layers.Input(shape=(feature_dim,), name='data_input')  # 输入一个特征向量 (feature_dim 维)\n",
        "    label_input = layers.Input(shape=(1,), dtype='int32', name='label_input')  # 输入一个类别标签 (整数)\n",
        "\n",
        "    # 类别嵌入层\n",
        "    label_embedding = layers.Embedding(input_dim=num_classes, output_dim=embed_dim)(label_input) # 将类别标签映射为嵌入向量(embed_dim 维)\n",
        "    label_embedding = layers.Flatten()(label_embedding)  # 将嵌入向量展平, (1, embed_dim) -> (embed_dim,)\n",
        "\n",
        "    # 合并 特征向量 和 类别嵌入向量\n",
        "    # 合并后的向量维度为 (feature_dim + embed_dim,)\n",
        "    x = layers.Concatenate()([data_input, label_embedding])\n",
        "\n",
        "    # 判别器网络结构\n",
        "    for dim in hidden_dims:\n",
        "        x = layers.Dense(dim)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    # 输出层 (sigmoid 激活函数. 输出为 [0, 1] 区间, 接近0: 判断为假数据, 接近1: 判断为真实数据)\n",
        "    output = layers.Dense(1, activation='sigmoid', name='validity')(x)\n",
        "\n",
        "    # 返回判别器模型\n",
        "    # 该模型接受两个输入，一个是特征向量，一个是类别标签. 输出判别结果(真/假 的概率)\n",
        "    return Model([data_input, label_input], output, name=\"Discriminator\")\n",
        "\n",
        "\n",
        "# ---------------- CGAN Model with Custom train_step ----------------\n",
        "class ConditionalGAN(Model):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 discriminator,\n",
        "                 seen_labels: list = [],\n",
        "                 **kwargs):\n",
        "        super(ConditionalGAN, self).__init__(**kwargs)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.seen_labels = tf.constant(seen_labels, dtype=tf.int32)\n",
        "\n",
        "        self.noise_dim = generator.input_shape[0][1]\n",
        "\n",
        "        self.pause_D = False\n",
        "        self.pause_G = False\n",
        "        self.extra_steps_D = 0\n",
        "        self.extra_steps_G = 0\n",
        "\n",
        "        self.gen_loss_metric = tf.keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_metric = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "        self.delta_loss_metric = tf.keras.metrics.Mean(name=\"delta_loss\")\n",
        "        pass\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.disc_loss_metric,\n",
        "                self.gen_loss_metric,\n",
        "                self.delta_loss_metric,\n",
        "                ]\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def _train_D(self, real_x, real_y):\n",
        "        real_size = tf.shape(real_x)[0]\n",
        "\n",
        "        ## 训练判别器 ##\n",
        "        # 生成一组 (real_size,1) 的假标签\n",
        "        # 方法1: 从 seen_labels 中随机取值 (优点是完全随机，对少数类别友好。缺点是更难收敛)\n",
        "        idx = tf.random.uniform((real_size,), maxval=tf.shape(self.seen_labels)[0], dtype=tf.int32)\n",
        "        fake_y = tf.expand_dims(tf.gather(self.seen_labels, idx), axis=1)  # shape (real_size,1)\n",
        "        # 方法2: 由 real_y 打乱顺序获得 (优点是简单，保持原类别比例，有助于收敛)\n",
        "        # fake_y = tf.random.shuffle(real_y)\n",
        "\n",
        "        with tf.GradientTape() as tape_d:\n",
        "            self.discriminator.trainable = True\n",
        "            fake_x = self.generator([tf.random.normal((real_size, self.noise_dim)), fake_y], training=False)\n",
        "\n",
        "            real_validity = self.discriminator([real_x, real_y], training=True)\n",
        "            fake_validity = self.discriminator([fake_x, fake_y], training=True)\n",
        "\n",
        "            d_loss_real = self.loss_fn(tf.ones_like(real_validity), real_validity)  # 对真实样本的损失\n",
        "            d_loss_fake = self.loss_fn(tf.zeros_like(fake_validity), fake_validity)  # 对生成样本的损失\n",
        "            d_loss = 0.5 * (d_loss_real + d_loss_fake)  # 平均损失\n",
        "\n",
        "        # 计算梯度，更新判别器参数\n",
        "        grads_d = tape_d.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients( zip(grads_d, self.discriminator.trainable_weights) )\n",
        "\n",
        "        self.disc_loss_metric.update_state(d_loss)\n",
        "        pass\n",
        "\n",
        "    def _train_G(self, real_x, real_y):\n",
        "        real_size = tf.shape(real_x)[0]\n",
        "\n",
        "        ## 训练生成器 ##\n",
        "        idx = tf.random.uniform((real_size,), maxval=tf.shape(self.seen_labels)[0], dtype=tf.int32)\n",
        "        fake_y = tf.expand_dims(tf.gather(self.seen_labels, idx), axis=1)  # shape (real_size,1)\n",
        "        # fake_y = tf.random.shuffle(real_y)\n",
        "\n",
        "        with tf.GradientTape() as tape_g:\n",
        "            self.discriminator.trainable = False\n",
        "            # 要在生成器的 tap 内部调用生成器\n",
        "            fake_x = self.generator([tf.random.normal((real_size, self.noise_dim)), fake_y], training=True)\n",
        "\n",
        "            fake_validity = self.discriminator([fake_x, fake_y], training=False)\n",
        "            g_loss = self.loss_fn(tf.ones_like(fake_validity), fake_validity)\n",
        "\n",
        "        # 计算梯度，更新生成器参数\n",
        "        grads_g = tape_g.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients( zip(grads_g, self.generator.trainable_weights) )\n",
        "        self.discriminator.trainable = True\n",
        "\n",
        "        self.gen_loss_metric.update_state(g_loss)\n",
        "        pass\n",
        "\n",
        "\n",
        "    # fit 方法会自动调用 train_step, 每次传递 batch_size 的 data 给它\n",
        "    def train_step(self, data):\n",
        "        real_x, real_y = data\n",
        "\n",
        "        if not self.pause_D:\n",
        "            for _ in range(1 + self.extra_steps_D):\n",
        "                self._train_D(real_x, real_y)\n",
        "\n",
        "        if not self.pause_G:\n",
        "            for _ in range(1 + self.extra_steps_G):\n",
        "                self._train_G(real_x, real_y)\n",
        "\n",
        "        batch_delta = self.disc_loss_metric.result() - self.gen_loss_metric.result()\n",
        "        self.delta_loss_metric.update_state(batch_delta)\n",
        "\n",
        "        return {\n",
        "            \"discriminator_loss\": self.disc_loss_metric.result(),\n",
        "            \"generator_loss\": self.gen_loss_metric.result(),\n",
        "            \"delta_loss\": self.delta_loss_metric.result(),\n",
        "            # 'g_loss': g_loss,\n",
        "            # 'd_loss': d_loss,\n",
        "            # 'd_loss_real': d_loss_real,\n",
        "            # 'd_loss_fake': d_loss_fake,\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDAkD88lY-gE"
      },
      "source": [
        "## 1️⃣ 利用 ROS 提前补充极少数类样本\n",
        "- 先用 ROS 随机复制的方式，将极少数类样本扩展到可接受的程度后再进行 oversampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vfzi08QuZwQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d00cb7-2e58-457b-985c-8eb0a0aadcd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/24/25 23:14:40 PDT] No need to apply ROS oversampling.\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample_to = {}\n",
        "# 判断 oversampling_method 字符串开头是否为 ros\n",
        "if oversampling_method.startswith('ros'):\n",
        "    ros_scheme = int(oversampling_method[3])\n",
        "    oversample_to = ros_schemes[ros_scheme]\n",
        "    print(f'[{now()}] Applying ROS oversampling to: {oversample_to}')\n",
        "\n",
        "    oversampler = RandomOverSampler(sampling_strategy=oversample_to, random_state=op_seed)\n",
        "    X, y = oversampler.fit_resample(X, y)\n",
        "\n",
        "    print(f'[{now()}] After ROS oversampling:')\n",
        "    print(f'  X.shape: {X.shape}, y.shape: {y.shape}')\n",
        "    print(f'  Labels: { {int(k): v for k, v in sorted(Counter(y).items())} }\\n')\n",
        "else:\n",
        "    print(f'[{now()}] No need to apply ROS oversampling.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG0WobNKt5iS"
      },
      "source": [
        "## 2️⃣ 初始化 并 训练 cGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TAUxg7ZEtcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe61f78d-3918-4af7-8f81-08d3aef9a21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/24/25 23:14:42 PDT] 🚀 Training cGAN [cgan-m(n128,f70,c15,e500,b512,gen[128,[128, 256, 512],0.0003],dis[64,[256, 128],0.0001])_generator]...\n",
            "[06/24/25 23:14:42 PDT] Selected X.shape: (44125, 70), y.shape: (44125,)\n",
            "[06/24/25 23:14:42 PDT] Selected labels: {2: 489, 3: 184, 5: 1384, 7: 33206, 10: 8792, 13: 70}\n",
            "[06/25/25 06:14:44] Building generator with: num_classes=15, feature_dim=70, noise_dim=128, embed_dim=128, hidden_dims=[128, 256, 512]\n",
            "[06/25/25 06:14:45] Building discriminator with: num_classes=15, feature_dim=70, embed_dim=64, hidden_dims=[256, 128]\n",
            "Epoch 1/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 71ms/step - delta_loss: -0.4150 - discriminator_loss: 0.5059 - generator_loss: 1.1715\n",
            "Epoch 2/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.1886 - discriminator_loss: 0.1846 - generator_loss: 2.6399\n",
            "Epoch 3/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -3.1044 - discriminator_loss: 0.2432 - generator_loss: 3.2759\n",
            "Epoch 4/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.6856 - discriminator_loss: 0.3416 - generator_loss: 2.9608\n",
            "Epoch 5/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.4278 - discriminator_loss: 0.2977 - generator_loss: 2.6871\n",
            "Epoch 6/500\n",
            "\u001b[1m77/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.2389 - discriminator_loss: 0.3285 - generator_loss: 2.5532\n",
            "[06/24/25 23:15:16 PDT] Adjust discriminator's learning rate to 4.999999873689376e-05\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.2369 - discriminator_loss: 0.3304 - generator_loss: 2.5510\n",
            "Epoch 7/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.1433 - discriminator_loss: 0.3709 - generator_loss: 2.5182\n",
            "Epoch 8/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.1656 - discriminator_loss: 0.3968 - generator_loss: 2.5696\n",
            "Epoch 9/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0961 - discriminator_loss: 0.3884 - generator_loss: 2.4809\n",
            "Epoch 10/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0573 - discriminator_loss: 0.3964 - generator_loss: 2.4320\n",
            "Epoch 11/500\n",
            "\u001b[1m86/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9507 - discriminator_loss: 0.4038 - generator_loss: 2.3604\n",
            "[06/24/25 23:15:17 PDT] Adjust discriminator's learning rate to 2.499999936844688e-05\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9508 - discriminator_loss: 0.4039 - generator_loss: 2.3607\n",
            "Epoch 12/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9993 - discriminator_loss: 0.4134 - generator_loss: 2.4136\n",
            "Epoch 13/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0222 - discriminator_loss: 0.4185 - generator_loss: 2.4405\n",
            "Epoch 14/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9741 - discriminator_loss: 0.4228 - generator_loss: 2.4111\n",
            "Epoch 15/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0466 - discriminator_loss: 0.4209 - generator_loss: 2.4463\n",
            "Epoch 16/500\n",
            "\u001b[1m73/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8873 - discriminator_loss: 0.4071 - generator_loss: 2.2783\n",
            "[06/24/25 23:15:19 PDT] Adjust discriminator's learning rate to 1.249999968422344e-05\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8846 - discriminator_loss: 0.4072 - generator_loss: 2.2792\n",
            "Epoch 17/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9248 - discriminator_loss: 0.4208 - generator_loss: 2.3432\n",
            "Epoch 18/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9509 - discriminator_loss: 0.4219 - generator_loss: 2.3645\n",
            "Epoch 19/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9221 - discriminator_loss: 0.4189 - generator_loss: 2.3344\n",
            "Epoch 20/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9367 - discriminator_loss: 0.4101 - generator_loss: 2.3367\n",
            "Epoch 21/500\n",
            "\u001b[1m73/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8301 - discriminator_loss: 0.4070 - generator_loss: 2.2559\n",
            "[06/24/25 23:15:21 PDT] Adjust discriminator's learning rate to 6.24999984211172e-06\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8341 - discriminator_loss: 0.4077 - generator_loss: 2.2658\n",
            "Epoch 22/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0347 - discriminator_loss: 0.4174 - generator_loss: 2.4447\n",
            "Epoch 23/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0734 - discriminator_loss: 0.4245 - generator_loss: 2.4874\n",
            "Epoch 24/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0654 - discriminator_loss: 0.4240 - generator_loss: 2.4839\n",
            "Epoch 25/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0596 - discriminator_loss: 0.4267 - generator_loss: 2.4878\n",
            "Epoch 26/500\n",
            "\u001b[1m75/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0658 - discriminator_loss: 0.4266 - generator_loss: 2.5201\n",
            "[06/24/25 23:15:22 PDT] Adjust discriminator's learning rate to 3.12499992105586e-06\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0701 - discriminator_loss: 0.4264 - generator_loss: 2.5221\n",
            "Epoch 27/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.1088 - discriminator_loss: 0.4308 - generator_loss: 2.5390\n",
            "Epoch 28/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0298 - discriminator_loss: 0.4279 - generator_loss: 2.4446\n",
            "Epoch 29/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9459 - discriminator_loss: 0.4306 - generator_loss: 2.3854\n",
            "Epoch 30/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9422 - discriminator_loss: 0.4306 - generator_loss: 2.3805\n",
            "Epoch 31/500\n",
            "\u001b[1m86/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0240 - discriminator_loss: 0.4285 - generator_loss: 2.4275\n",
            "[06/24/25 23:15:24 PDT] Adjust discriminator's learning rate to 1.56249996052793e-06\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0234 - discriminator_loss: 0.4285 - generator_loss: 2.4271\n",
            "Epoch 32/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9603 - discriminator_loss: 0.4203 - generator_loss: 2.3839\n",
            "Epoch 33/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9580 - discriminator_loss: 0.4276 - generator_loss: 2.3844\n",
            "Epoch 34/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9763 - discriminator_loss: 0.4269 - generator_loss: 2.4080\n",
            "Epoch 35/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9897 - discriminator_loss: 0.4267 - generator_loss: 2.4066\n",
            "Epoch 36/500\n",
            "\u001b[1m85/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9835 - discriminator_loss: 0.4204 - generator_loss: 2.3968\n",
            "[06/24/25 23:15:26 PDT] Adjust discriminator's learning rate to 7.81249980263965e-07\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9832 - discriminator_loss: 0.4205 - generator_loss: 2.3970\n",
            "Epoch 37/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9581 - discriminator_loss: 0.4252 - generator_loss: 2.3855\n",
            "Epoch 38/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9588 - discriminator_loss: 0.4260 - generator_loss: 2.3900\n",
            "Epoch 39/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9487 - discriminator_loss: 0.4265 - generator_loss: 2.3752\n",
            "Epoch 40/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9601 - discriminator_loss: 0.4274 - generator_loss: 2.3785\n",
            "Epoch 41/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9426 - discriminator_loss: 0.4270 - generator_loss: 2.3869\n",
            "[06/24/25 23:15:27 PDT] Adjust discriminator's learning rate to 3.906249901319825e-07\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9428 - discriminator_loss: 0.4271 - generator_loss: 2.3870\n",
            "Epoch 42/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9488 - discriminator_loss: 0.4240 - generator_loss: 2.3800\n",
            "Epoch 43/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9598 - discriminator_loss: 0.4339 - generator_loss: 2.3787\n",
            "Epoch 44/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8936 - discriminator_loss: 0.4456 - generator_loss: 2.3523\n",
            "Epoch 45/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9366 - discriminator_loss: 0.4442 - generator_loss: 2.3744\n",
            "Epoch 46/500\n",
            "\u001b[1m71/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9365 - discriminator_loss: 0.4435 - generator_loss: 2.3801\n",
            "[06/24/25 23:15:29 PDT] Adjust discriminator's learning rate to 1.9531249506599124e-07\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9366 - discriminator_loss: 0.4437 - generator_loss: 2.3809\n",
            "Epoch 47/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9810 - discriminator_loss: 0.4422 - generator_loss: 2.4016\n",
            "Epoch 48/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9715 - discriminator_loss: 0.4415 - generator_loss: 2.3965\n",
            "Epoch 49/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9432 - discriminator_loss: 0.4454 - generator_loss: 2.3915\n",
            "Epoch 50/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9606 - discriminator_loss: 0.4430 - generator_loss: 2.4021\n",
            "Epoch 51/500\n",
            "\u001b[1m74/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9266 - discriminator_loss: 0.4400 - generator_loss: 2.3818\n",
            "[06/24/25 23:15:30 PDT] Adjust discriminator's learning rate to 9.765624753299562e-08\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9292 - discriminator_loss: 0.4402 - generator_loss: 2.3842\n",
            "Epoch 52/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9513 - discriminator_loss: 0.4417 - generator_loss: 2.3896\n",
            "Epoch 53/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9102 - discriminator_loss: 0.4409 - generator_loss: 2.3704\n",
            "Epoch 54/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -2.0116 - discriminator_loss: 0.4380 - generator_loss: 2.4182\n",
            "Epoch 55/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9278 - discriminator_loss: 0.4444 - generator_loss: 2.3878\n",
            "Epoch 56/500\n",
            "\u001b[1m74/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9714 - discriminator_loss: 0.4451 - generator_loss: 2.4052\n",
            "[06/24/25 23:15:32 PDT] Adjust discriminator's learning rate to 4.882812376649781e-08\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9695 - discriminator_loss: 0.4448 - generator_loss: 2.4043\n",
            "Epoch 57/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9363 - discriminator_loss: 0.4396 - generator_loss: 2.3884\n",
            "Epoch 58/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9257 - discriminator_loss: 0.4410 - generator_loss: 2.3736\n",
            "Epoch 59/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9572 - discriminator_loss: 0.4463 - generator_loss: 2.4011\n",
            "Epoch 60/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9111 - discriminator_loss: 0.4453 - generator_loss: 2.3677\n",
            "Epoch 61/500\n",
            "\u001b[1m85/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9808 - discriminator_loss: 0.4410 - generator_loss: 2.4123\n",
            "[06/24/25 23:15:34 PDT] Adjust discriminator's learning rate to 2.4414061883248905e-08\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9805 - discriminator_loss: 0.4410 - generator_loss: 2.4120\n",
            "Epoch 62/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9293 - discriminator_loss: 0.4429 - generator_loss: 2.3749\n",
            "Epoch 63/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9846 - discriminator_loss: 0.4423 - generator_loss: 2.4158\n",
            "Epoch 64/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9569 - discriminator_loss: 0.4411 - generator_loss: 2.3996\n",
            "Epoch 65/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9522 - discriminator_loss: 0.4462 - generator_loss: 2.3895\n",
            "Epoch 66/500\n",
            "\u001b[1m73/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9477 - discriminator_loss: 0.4433 - generator_loss: 2.3853\n",
            "[06/24/25 23:15:35 PDT] Adjust discriminator's learning rate to 1.2207030941624453e-08\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9467 - discriminator_loss: 0.4435 - generator_loss: 2.3859\n",
            "Epoch 67/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9381 - discriminator_loss: 0.4458 - generator_loss: 2.3923\n",
            "Epoch 68/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9522 - discriminator_loss: 0.4410 - generator_loss: 2.3964\n",
            "Epoch 69/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8922 - discriminator_loss: 0.4441 - generator_loss: 2.3629\n",
            "Epoch 70/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9561 - discriminator_loss: 0.4426 - generator_loss: 2.3968\n",
            "Epoch 71/500\n",
            "\u001b[1m85/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9043 - discriminator_loss: 0.4438 - generator_loss: 2.3695\n",
            "[06/24/25 23:15:37 PDT] Adjust discriminator's learning rate to 1e-08\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9050 - discriminator_loss: 0.4439 - generator_loss: 2.3700\n",
            "Epoch 72/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9308 - discriminator_loss: 0.4444 - generator_loss: 2.3815\n",
            "Epoch 73/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9499 - discriminator_loss: 0.4457 - generator_loss: 2.3977\n",
            "Epoch 74/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9610 - discriminator_loss: 0.4377 - generator_loss: 2.3881\n",
            "Epoch 75/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9476 - discriminator_loss: 0.4440 - generator_loss: 2.3844\n",
            "Epoch 76/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9588 - discriminator_loss: 0.4428 - generator_loss: 2.3961\n",
            "Epoch 77/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9607 - discriminator_loss: 0.4385 - generator_loss: 2.3910\n",
            "Epoch 78/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9404 - discriminator_loss: 0.4435 - generator_loss: 2.3912\n",
            "Epoch 79/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9654 - discriminator_loss: 0.4346 - generator_loss: 2.3953\n",
            "Epoch 80/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9440 - discriminator_loss: 0.4405 - generator_loss: 2.3937\n",
            "Epoch 81/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9855 - discriminator_loss: 0.4433 - generator_loss: 2.4127\n",
            "Epoch 82/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9447 - discriminator_loss: 0.4427 - generator_loss: 2.3818\n",
            "Epoch 83/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9401 - discriminator_loss: 0.4403 - generator_loss: 2.3868\n",
            "Epoch 84/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9371 - discriminator_loss: 0.4444 - generator_loss: 2.3864\n",
            "Epoch 85/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9374 - discriminator_loss: 0.4415 - generator_loss: 2.3861\n",
            "Epoch 86/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9724 - discriminator_loss: 0.4340 - generator_loss: 2.3952\n",
            "Epoch 87/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9384 - discriminator_loss: 0.4465 - generator_loss: 2.3905\n",
            "Epoch 88/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9305 - discriminator_loss: 0.4419 - generator_loss: 2.3904\n",
            "Epoch 89/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9486 - discriminator_loss: 0.4424 - generator_loss: 2.3982\n",
            "Epoch 90/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9424 - discriminator_loss: 0.4427 - generator_loss: 2.3806\n",
            "Epoch 91/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9704 - discriminator_loss: 0.4443 - generator_loss: 2.3951\n",
            "Epoch 92/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8935 - discriminator_loss: 0.4430 - generator_loss: 2.3581\n",
            "Epoch 93/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9649 - discriminator_loss: 0.4390 - generator_loss: 2.3966\n",
            "Epoch 94/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9386 - discriminator_loss: 0.4420 - generator_loss: 2.3828\n",
            "Epoch 95/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9273 - discriminator_loss: 0.4470 - generator_loss: 2.3794\n",
            "Epoch 96/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9398 - discriminator_loss: 0.4430 - generator_loss: 2.3845\n",
            "Epoch 97/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9572 - discriminator_loss: 0.4418 - generator_loss: 2.3872\n",
            "Epoch 98/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9138 - discriminator_loss: 0.4426 - generator_loss: 2.3634\n",
            "Epoch 99/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9631 - discriminator_loss: 0.4446 - generator_loss: 2.4099\n",
            "Epoch 100/500\n",
            "\u001b[1m71/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9569 - discriminator_loss: 0.4435 - generator_loss: 2.3883\n",
            "[06/24/25 23:15:47 PDT] 💾 Saved model at epoch 100 to: /content/drive/MyDrive/NYIT/880/data/balanced/models/minmax/cgan-m(n128,f70,c15,e100,b512,gen[128,[128, 256, 512],0.0003],dis[64,[256, 128],0.0001])_generator.keras\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - delta_loss: -1.9547 - discriminator_loss: 0.4436 - generator_loss: 2.3894\n",
            "Epoch 101/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9120 - discriminator_loss: 0.4425 - generator_loss: 2.3696\n",
            "Epoch 102/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9433 - discriminator_loss: 0.4420 - generator_loss: 2.3806\n",
            "Epoch 103/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9452 - discriminator_loss: 0.4459 - generator_loss: 2.3915\n",
            "Epoch 104/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9438 - discriminator_loss: 0.4389 - generator_loss: 2.3746\n",
            "Epoch 105/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9456 - discriminator_loss: 0.4475 - generator_loss: 2.3883\n",
            "Epoch 106/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9555 - discriminator_loss: 0.4449 - generator_loss: 2.3859\n",
            "Epoch 107/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9720 - discriminator_loss: 0.4415 - generator_loss: 2.4034\n",
            "Epoch 108/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9508 - discriminator_loss: 0.4419 - generator_loss: 2.3881\n",
            "Epoch 109/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9328 - discriminator_loss: 0.4479 - generator_loss: 2.3871\n",
            "Epoch 110/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9455 - discriminator_loss: 0.4439 - generator_loss: 2.3811\n",
            "Epoch 111/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9497 - discriminator_loss: 0.4425 - generator_loss: 2.3829\n",
            "Epoch 112/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9528 - discriminator_loss: 0.4424 - generator_loss: 2.3945\n",
            "Epoch 113/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9588 - discriminator_loss: 0.4426 - generator_loss: 2.3960\n",
            "Epoch 114/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9483 - discriminator_loss: 0.4423 - generator_loss: 2.3767\n",
            "Epoch 115/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9437 - discriminator_loss: 0.4479 - generator_loss: 2.3871\n",
            "Epoch 116/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9325 - discriminator_loss: 0.4416 - generator_loss: 2.3951\n",
            "Epoch 117/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9348 - discriminator_loss: 0.4433 - generator_loss: 2.3841\n",
            "Epoch 118/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9475 - discriminator_loss: 0.4434 - generator_loss: 2.3901\n",
            "Epoch 119/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9491 - discriminator_loss: 0.4403 - generator_loss: 2.3897\n",
            "Epoch 120/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9629 - discriminator_loss: 0.4465 - generator_loss: 2.4011\n",
            "Epoch 121/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9156 - discriminator_loss: 0.4452 - generator_loss: 2.3676\n",
            "Epoch 122/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9449 - discriminator_loss: 0.4487 - generator_loss: 2.3923\n",
            "Epoch 123/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9194 - discriminator_loss: 0.4464 - generator_loss: 2.3830\n",
            "Epoch 124/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9424 - discriminator_loss: 0.4456 - generator_loss: 2.3871\n",
            "Epoch 125/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9461 - discriminator_loss: 0.4374 - generator_loss: 2.3852\n",
            "Epoch 126/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9467 - discriminator_loss: 0.4435 - generator_loss: 2.3901\n",
            "Epoch 127/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9418 - discriminator_loss: 0.4423 - generator_loss: 2.3847\n",
            "Epoch 128/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9043 - discriminator_loss: 0.4453 - generator_loss: 2.3667\n",
            "Epoch 129/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9493 - discriminator_loss: 0.4416 - generator_loss: 2.3931\n",
            "Epoch 130/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9169 - discriminator_loss: 0.4416 - generator_loss: 2.3643\n",
            "Epoch 131/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9220 - discriminator_loss: 0.4412 - generator_loss: 2.3797\n",
            "Epoch 132/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9461 - discriminator_loss: 0.4451 - generator_loss: 2.3933\n",
            "Epoch 133/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9316 - discriminator_loss: 0.4432 - generator_loss: 2.3902\n",
            "Epoch 134/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9445 - discriminator_loss: 0.4391 - generator_loss: 2.3905\n",
            "Epoch 135/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9352 - discriminator_loss: 0.4441 - generator_loss: 2.3958\n",
            "Epoch 136/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9510 - discriminator_loss: 0.4403 - generator_loss: 2.3955\n",
            "Epoch 137/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9584 - discriminator_loss: 0.4397 - generator_loss: 2.3890\n",
            "Epoch 138/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8982 - discriminator_loss: 0.4456 - generator_loss: 2.3646\n",
            "Epoch 139/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9711 - discriminator_loss: 0.4409 - generator_loss: 2.3941\n",
            "Epoch 140/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9545 - discriminator_loss: 0.4454 - generator_loss: 2.3939\n",
            "Epoch 141/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9322 - discriminator_loss: 0.4410 - generator_loss: 2.3752\n",
            "Epoch 142/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9720 - discriminator_loss: 0.4478 - generator_loss: 2.4033\n",
            "Epoch 143/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9248 - discriminator_loss: 0.4459 - generator_loss: 2.3830\n",
            "Epoch 144/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9488 - discriminator_loss: 0.4400 - generator_loss: 2.3953\n",
            "Epoch 145/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9302 - discriminator_loss: 0.4455 - generator_loss: 2.3761\n",
            "Epoch 146/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9297 - discriminator_loss: 0.4452 - generator_loss: 2.3888\n",
            "Epoch 147/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9513 - discriminator_loss: 0.4445 - generator_loss: 2.4075\n",
            "Epoch 148/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9315 - discriminator_loss: 0.4412 - generator_loss: 2.3798\n",
            "Epoch 149/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9463 - discriminator_loss: 0.4451 - generator_loss: 2.3914\n",
            "Epoch 150/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9423 - discriminator_loss: 0.4443 - generator_loss: 2.3842\n",
            "Epoch 151/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9523 - discriminator_loss: 0.4413 - generator_loss: 2.3928\n",
            "Epoch 152/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9539 - discriminator_loss: 0.4445 - generator_loss: 2.3923\n",
            "Epoch 153/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9423 - discriminator_loss: 0.4422 - generator_loss: 2.3891\n",
            "Epoch 154/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9543 - discriminator_loss: 0.4429 - generator_loss: 2.3999\n",
            "Epoch 155/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9326 - discriminator_loss: 0.4417 - generator_loss: 2.3759\n",
            "Epoch 156/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9344 - discriminator_loss: 0.4449 - generator_loss: 2.3779\n",
            "Epoch 157/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9269 - discriminator_loss: 0.4421 - generator_loss: 2.3852\n",
            "Epoch 158/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9530 - discriminator_loss: 0.4422 - generator_loss: 2.3954\n",
            "Epoch 159/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9417 - discriminator_loss: 0.4416 - generator_loss: 2.3831\n",
            "Epoch 160/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9655 - discriminator_loss: 0.4414 - generator_loss: 2.4033\n",
            "Epoch 161/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9541 - discriminator_loss: 0.4483 - generator_loss: 2.3961\n",
            "Epoch 162/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9910 - discriminator_loss: 0.4349 - generator_loss: 2.4056\n",
            "Epoch 163/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9301 - discriminator_loss: 0.4397 - generator_loss: 2.3803\n",
            "Epoch 164/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9202 - discriminator_loss: 0.4449 - generator_loss: 2.3743\n",
            "Epoch 165/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9617 - discriminator_loss: 0.4401 - generator_loss: 2.4010\n",
            "Epoch 166/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9733 - discriminator_loss: 0.4461 - generator_loss: 2.4119\n",
            "Epoch 167/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9202 - discriminator_loss: 0.4428 - generator_loss: 2.3779\n",
            "Epoch 168/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9949 - discriminator_loss: 0.4395 - generator_loss: 2.4169\n",
            "Epoch 169/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9487 - discriminator_loss: 0.4388 - generator_loss: 2.3924\n",
            "Epoch 170/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9617 - discriminator_loss: 0.4418 - generator_loss: 2.3987\n",
            "Epoch 171/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9102 - discriminator_loss: 0.4413 - generator_loss: 2.3653\n",
            "Epoch 172/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9473 - discriminator_loss: 0.4436 - generator_loss: 2.3858\n",
            "Epoch 173/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9316 - discriminator_loss: 0.4433 - generator_loss: 2.3857\n",
            "Epoch 174/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9437 - discriminator_loss: 0.4429 - generator_loss: 2.3835\n",
            "Epoch 175/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9497 - discriminator_loss: 0.4414 - generator_loss: 2.3925\n",
            "Epoch 176/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9485 - discriminator_loss: 0.4376 - generator_loss: 2.3913\n",
            "Epoch 177/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9608 - discriminator_loss: 0.4414 - generator_loss: 2.4029\n",
            "Epoch 178/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9515 - discriminator_loss: 0.4422 - generator_loss: 2.3987\n",
            "Epoch 179/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9299 - discriminator_loss: 0.4398 - generator_loss: 2.3728\n",
            "Epoch 180/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9603 - discriminator_loss: 0.4425 - generator_loss: 2.3973\n",
            "Epoch 181/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9939 - discriminator_loss: 0.4427 - generator_loss: 2.4123\n",
            "Epoch 182/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9543 - discriminator_loss: 0.4429 - generator_loss: 2.4066\n",
            "Epoch 183/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9384 - discriminator_loss: 0.4459 - generator_loss: 2.3894\n",
            "Epoch 184/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9636 - discriminator_loss: 0.4416 - generator_loss: 2.3895\n",
            "Epoch 185/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9304 - discriminator_loss: 0.4470 - generator_loss: 2.3769\n",
            "Epoch 186/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9573 - discriminator_loss: 0.4442 - generator_loss: 2.4030\n",
            "Epoch 187/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9264 - discriminator_loss: 0.4440 - generator_loss: 2.3836\n",
            "Epoch 188/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9134 - discriminator_loss: 0.4478 - generator_loss: 2.3681\n",
            "Epoch 189/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9549 - discriminator_loss: 0.4402 - generator_loss: 2.3894\n",
            "Epoch 190/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9520 - discriminator_loss: 0.4415 - generator_loss: 2.4020\n",
            "Epoch 191/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9309 - discriminator_loss: 0.4432 - generator_loss: 2.3837\n",
            "Epoch 192/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9655 - discriminator_loss: 0.4456 - generator_loss: 2.4033\n",
            "Epoch 193/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9576 - discriminator_loss: 0.4457 - generator_loss: 2.3999\n",
            "Epoch 194/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9560 - discriminator_loss: 0.4406 - generator_loss: 2.4013\n",
            "Epoch 195/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9553 - discriminator_loss: 0.4443 - generator_loss: 2.3921\n",
            "Epoch 196/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9410 - discriminator_loss: 0.4365 - generator_loss: 2.3823\n",
            "Epoch 197/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9566 - discriminator_loss: 0.4415 - generator_loss: 2.3917\n",
            "Epoch 198/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9445 - discriminator_loss: 0.4464 - generator_loss: 2.3915\n",
            "Epoch 199/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9202 - discriminator_loss: 0.4412 - generator_loss: 2.3821\n",
            "Epoch 200/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9357 - discriminator_loss: 0.4378 - generator_loss: 2.3749\n",
            "[06/24/25 23:16:20 PDT] 💾 Saved model at epoch 200 to: /content/drive/MyDrive/NYIT/880/data/balanced/models/minmax/cgan-m(n128,f70,c15,e200,b512,gen[128,[128, 256, 512],0.0003],dis[64,[256, 128],0.0001])_generator.keras\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - delta_loss: -1.9358 - discriminator_loss: 0.4378 - generator_loss: 2.3750\n",
            "Epoch 201/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9524 - discriminator_loss: 0.4437 - generator_loss: 2.3988\n",
            "Epoch 202/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9087 - discriminator_loss: 0.4375 - generator_loss: 2.3595\n",
            "Epoch 203/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9253 - discriminator_loss: 0.4410 - generator_loss: 2.3801\n",
            "Epoch 204/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9275 - discriminator_loss: 0.4425 - generator_loss: 2.3810\n",
            "Epoch 205/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9220 - discriminator_loss: 0.4430 - generator_loss: 2.3740\n",
            "Epoch 206/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9607 - discriminator_loss: 0.4402 - generator_loss: 2.3865\n",
            "Epoch 207/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9558 - discriminator_loss: 0.4430 - generator_loss: 2.3961\n",
            "Epoch 208/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9313 - discriminator_loss: 0.4469 - generator_loss: 2.3865\n",
            "Epoch 209/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9539 - discriminator_loss: 0.4402 - generator_loss: 2.3964\n",
            "Epoch 210/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9480 - discriminator_loss: 0.4392 - generator_loss: 2.3842\n",
            "Epoch 211/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9605 - discriminator_loss: 0.4270 - generator_loss: 2.3844\n",
            "Epoch 212/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9308 - discriminator_loss: 0.4419 - generator_loss: 2.3828\n",
            "Epoch 213/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9371 - discriminator_loss: 0.4460 - generator_loss: 2.3937\n",
            "Epoch 214/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9546 - discriminator_loss: 0.4437 - generator_loss: 2.3918\n",
            "Epoch 215/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9718 - discriminator_loss: 0.4427 - generator_loss: 2.4174\n",
            "Epoch 216/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9218 - discriminator_loss: 0.4414 - generator_loss: 2.3737\n",
            "Epoch 217/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9570 - discriminator_loss: 0.4449 - generator_loss: 2.3968\n",
            "Epoch 218/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9632 - discriminator_loss: 0.4365 - generator_loss: 2.3972\n",
            "Epoch 219/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9418 - discriminator_loss: 0.4402 - generator_loss: 2.3805\n",
            "Epoch 220/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9323 - discriminator_loss: 0.4471 - generator_loss: 2.3836\n",
            "Epoch 221/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9107 - discriminator_loss: 0.4529 - generator_loss: 2.3789\n",
            "Epoch 222/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9416 - discriminator_loss: 0.4538 - generator_loss: 2.3912\n",
            "Epoch 223/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9265 - discriminator_loss: 0.4531 - generator_loss: 2.3908\n",
            "Epoch 224/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9342 - discriminator_loss: 0.4528 - generator_loss: 2.3891\n",
            "Epoch 225/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9052 - discriminator_loss: 0.4537 - generator_loss: 2.3685\n",
            "Epoch 226/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9506 - discriminator_loss: 0.4528 - generator_loss: 2.3876\n",
            "Epoch 227/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9449 - discriminator_loss: 0.4586 - generator_loss: 2.3933\n",
            "Epoch 228/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9426 - discriminator_loss: 0.4542 - generator_loss: 2.3976\n",
            "Epoch 229/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9475 - discriminator_loss: 0.4526 - generator_loss: 2.3877\n",
            "Epoch 230/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9715 - discriminator_loss: 0.4481 - generator_loss: 2.4040\n",
            "Epoch 231/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9420 - discriminator_loss: 0.4577 - generator_loss: 2.3950\n",
            "Epoch 232/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9329 - discriminator_loss: 0.4540 - generator_loss: 2.3920\n",
            "Epoch 233/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9261 - discriminator_loss: 0.4537 - generator_loss: 2.3863\n",
            "Epoch 234/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9581 - discriminator_loss: 0.4504 - generator_loss: 2.3958\n",
            "Epoch 235/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9448 - discriminator_loss: 0.4539 - generator_loss: 2.3969\n",
            "Epoch 236/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9495 - discriminator_loss: 0.4529 - generator_loss: 2.4007\n",
            "Epoch 237/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9453 - discriminator_loss: 0.4462 - generator_loss: 2.3916\n",
            "Epoch 238/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9367 - discriminator_loss: 0.4577 - generator_loss: 2.3827\n",
            "Epoch 239/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9433 - discriminator_loss: 0.4504 - generator_loss: 2.3895\n",
            "Epoch 240/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9476 - discriminator_loss: 0.4508 - generator_loss: 2.3888\n",
            "Epoch 241/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9485 - discriminator_loss: 0.4552 - generator_loss: 2.4072\n",
            "Epoch 242/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9655 - discriminator_loss: 0.4488 - generator_loss: 2.3903\n",
            "Epoch 243/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9359 - discriminator_loss: 0.4532 - generator_loss: 2.3864\n",
            "Epoch 244/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9159 - discriminator_loss: 0.4514 - generator_loss: 2.3745\n",
            "Epoch 245/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9164 - discriminator_loss: 0.4530 - generator_loss: 2.3887\n",
            "Epoch 246/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9457 - discriminator_loss: 0.4531 - generator_loss: 2.4038\n",
            "Epoch 247/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9468 - discriminator_loss: 0.4495 - generator_loss: 2.3824\n",
            "Epoch 248/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9755 - discriminator_loss: 0.4485 - generator_loss: 2.4127\n",
            "Epoch 249/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9765 - discriminator_loss: 0.4461 - generator_loss: 2.4102\n",
            "Epoch 250/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9277 - discriminator_loss: 0.4535 - generator_loss: 2.3823\n",
            "Epoch 251/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9547 - discriminator_loss: 0.4543 - generator_loss: 2.4076\n",
            "Epoch 252/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9081 - discriminator_loss: 0.4519 - generator_loss: 2.3805\n",
            "Epoch 253/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9334 - discriminator_loss: 0.4537 - generator_loss: 2.3949\n",
            "Epoch 254/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9445 - discriminator_loss: 0.4474 - generator_loss: 2.3882\n",
            "Epoch 255/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9363 - discriminator_loss: 0.4525 - generator_loss: 2.3897\n",
            "Epoch 256/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9291 - discriminator_loss: 0.4511 - generator_loss: 2.3898\n",
            "Epoch 257/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9096 - discriminator_loss: 0.4540 - generator_loss: 2.3792\n",
            "Epoch 258/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9494 - discriminator_loss: 0.4498 - generator_loss: 2.3818\n",
            "Epoch 259/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9270 - discriminator_loss: 0.4540 - generator_loss: 2.3851\n",
            "Epoch 260/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9362 - discriminator_loss: 0.4552 - generator_loss: 2.3944\n",
            "Epoch 261/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8923 - discriminator_loss: 0.4573 - generator_loss: 2.3768\n",
            "Epoch 262/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9530 - discriminator_loss: 0.4555 - generator_loss: 2.4154\n",
            "Epoch 263/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9407 - discriminator_loss: 0.4548 - generator_loss: 2.3959\n",
            "Epoch 264/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9440 - discriminator_loss: 0.4519 - generator_loss: 2.3952\n",
            "Epoch 265/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8893 - discriminator_loss: 0.4557 - generator_loss: 2.3697\n",
            "Epoch 266/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9641 - discriminator_loss: 0.4499 - generator_loss: 2.3979\n",
            "Epoch 267/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9591 - discriminator_loss: 0.4514 - generator_loss: 2.3927\n",
            "Epoch 268/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9769 - discriminator_loss: 0.4532 - generator_loss: 2.4074\n",
            "Epoch 269/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9581 - discriminator_loss: 0.4564 - generator_loss: 2.4138\n",
            "Epoch 270/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9585 - discriminator_loss: 0.4538 - generator_loss: 2.3961\n",
            "Epoch 271/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9711 - discriminator_loss: 0.4496 - generator_loss: 2.4109\n",
            "Epoch 272/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9712 - discriminator_loss: 0.4546 - generator_loss: 2.4149\n",
            "Epoch 273/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9578 - discriminator_loss: 0.4489 - generator_loss: 2.4002\n",
            "Epoch 274/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9486 - discriminator_loss: 0.4553 - generator_loss: 2.4041\n",
            "Epoch 275/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9309 - discriminator_loss: 0.4526 - generator_loss: 2.3848\n",
            "Epoch 276/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9507 - discriminator_loss: 0.4481 - generator_loss: 2.3901\n",
            "Epoch 277/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9398 - discriminator_loss: 0.4532 - generator_loss: 2.3848\n",
            "Epoch 278/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9450 - discriminator_loss: 0.4557 - generator_loss: 2.4020\n",
            "Epoch 279/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9406 - discriminator_loss: 0.4524 - generator_loss: 2.3942\n",
            "Epoch 280/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9568 - discriminator_loss: 0.4532 - generator_loss: 2.3922\n",
            "Epoch 281/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9323 - discriminator_loss: 0.4571 - generator_loss: 2.3912\n",
            "Epoch 282/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9469 - discriminator_loss: 0.4542 - generator_loss: 2.3909\n",
            "Epoch 283/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9428 - discriminator_loss: 0.4520 - generator_loss: 2.3941\n",
            "Epoch 284/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9304 - discriminator_loss: 0.4584 - generator_loss: 2.3835\n",
            "Epoch 285/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9338 - discriminator_loss: 0.4572 - generator_loss: 2.3844\n",
            "Epoch 286/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9450 - discriminator_loss: 0.4520 - generator_loss: 2.3872\n",
            "Epoch 287/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9539 - discriminator_loss: 0.4512 - generator_loss: 2.4086\n",
            "Epoch 288/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9321 - discriminator_loss: 0.4557 - generator_loss: 2.3787\n",
            "Epoch 289/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9334 - discriminator_loss: 0.4581 - generator_loss: 2.3928\n",
            "Epoch 290/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9329 - discriminator_loss: 0.4541 - generator_loss: 2.3856\n",
            "Epoch 291/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9452 - discriminator_loss: 0.4534 - generator_loss: 2.3964\n",
            "Epoch 292/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9225 - discriminator_loss: 0.4541 - generator_loss: 2.3879\n",
            "Epoch 293/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9398 - discriminator_loss: 0.4564 - generator_loss: 2.3938\n",
            "Epoch 294/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9515 - discriminator_loss: 0.4570 - generator_loss: 2.4050\n",
            "Epoch 295/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9471 - discriminator_loss: 0.4532 - generator_loss: 2.3987\n",
            "Epoch 296/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9712 - discriminator_loss: 0.4471 - generator_loss: 2.4019\n",
            "Epoch 297/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9424 - discriminator_loss: 0.4568 - generator_loss: 2.4044\n",
            "Epoch 298/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9553 - discriminator_loss: 0.4568 - generator_loss: 2.4039\n",
            "Epoch 299/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9173 - discriminator_loss: 0.4523 - generator_loss: 2.3714\n",
            "Epoch 300/500\n",
            "\u001b[1m74/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9468 - discriminator_loss: 0.4579 - generator_loss: 2.4063\n",
            "[06/24/25 23:16:54 PDT] 💾 Saved model at epoch 300 to: /content/drive/MyDrive/NYIT/880/data/balanced/models/minmax/cgan-m(n128,f70,c15,e300,b512,gen[128,[128, 256, 512],0.0003],dis[64,[256, 128],0.0001])_generator.keras\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - delta_loss: -1.9472 - discriminator_loss: 0.4576 - generator_loss: 2.4067\n",
            "Epoch 301/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9256 - discriminator_loss: 0.4543 - generator_loss: 2.3895\n",
            "Epoch 302/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9518 - discriminator_loss: 0.4558 - generator_loss: 2.4130\n",
            "Epoch 303/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9559 - discriminator_loss: 0.4576 - generator_loss: 2.4014\n",
            "Epoch 304/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9128 - discriminator_loss: 0.4573 - generator_loss: 2.3801\n",
            "Epoch 305/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9145 - discriminator_loss: 0.4552 - generator_loss: 2.3810\n",
            "Epoch 306/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9307 - discriminator_loss: 0.4533 - generator_loss: 2.3845\n",
            "Epoch 307/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9457 - discriminator_loss: 0.4514 - generator_loss: 2.3947\n",
            "Epoch 308/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9540 - discriminator_loss: 0.4495 - generator_loss: 2.3985\n",
            "Epoch 309/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9305 - discriminator_loss: 0.4556 - generator_loss: 2.3875\n",
            "Epoch 310/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9577 - discriminator_loss: 0.4564 - generator_loss: 2.4062\n",
            "Epoch 311/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9291 - discriminator_loss: 0.4568 - generator_loss: 2.4005\n",
            "Epoch 312/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9621 - discriminator_loss: 0.4519 - generator_loss: 2.4106\n",
            "Epoch 313/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9640 - discriminator_loss: 0.4533 - generator_loss: 2.4149\n",
            "Epoch 314/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9408 - discriminator_loss: 0.4557 - generator_loss: 2.4017\n",
            "Epoch 315/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9467 - discriminator_loss: 0.4525 - generator_loss: 2.3906\n",
            "Epoch 316/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9566 - discriminator_loss: 0.4565 - generator_loss: 2.4065\n",
            "Epoch 317/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.8907 - discriminator_loss: 0.4590 - generator_loss: 2.3675\n",
            "Epoch 318/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9161 - discriminator_loss: 0.4544 - generator_loss: 2.3742\n",
            "Epoch 319/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9261 - discriminator_loss: 0.4543 - generator_loss: 2.3847\n",
            "Epoch 320/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9451 - discriminator_loss: 0.4518 - generator_loss: 2.3998\n",
            "Epoch 321/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9761 - discriminator_loss: 0.4488 - generator_loss: 2.4123\n",
            "Epoch 322/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9297 - discriminator_loss: 0.4522 - generator_loss: 2.3991\n",
            "Epoch 323/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9701 - discriminator_loss: 0.4484 - generator_loss: 2.4152\n",
            "Epoch 324/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9417 - discriminator_loss: 0.4523 - generator_loss: 2.3868\n",
            "Epoch 325/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9711 - discriminator_loss: 0.4497 - generator_loss: 2.4185\n",
            "Epoch 326/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9520 - discriminator_loss: 0.4537 - generator_loss: 2.4001\n",
            "Epoch 327/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9443 - discriminator_loss: 0.4486 - generator_loss: 2.3956\n",
            "Epoch 328/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9377 - discriminator_loss: 0.4549 - generator_loss: 2.4008\n",
            "Epoch 329/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9212 - discriminator_loss: 0.4556 - generator_loss: 2.3820\n",
            "Epoch 330/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9360 - discriminator_loss: 0.4516 - generator_loss: 2.3921\n",
            "Epoch 331/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9342 - discriminator_loss: 0.4500 - generator_loss: 2.3941\n",
            "Epoch 332/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9355 - discriminator_loss: 0.4539 - generator_loss: 2.3912\n",
            "Epoch 333/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9587 - discriminator_loss: 0.4514 - generator_loss: 2.3922\n",
            "Epoch 334/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9220 - discriminator_loss: 0.4505 - generator_loss: 2.3818\n",
            "Epoch 335/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9715 - discriminator_loss: 0.4550 - generator_loss: 2.4142\n",
            "Epoch 336/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9782 - discriminator_loss: 0.4478 - generator_loss: 2.4087\n",
            "Epoch 337/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9681 - discriminator_loss: 0.4545 - generator_loss: 2.4221\n",
            "Epoch 338/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9232 - discriminator_loss: 0.4541 - generator_loss: 2.3925\n",
            "Epoch 339/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9443 - discriminator_loss: 0.4492 - generator_loss: 2.3952\n",
            "Epoch 340/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9282 - discriminator_loss: 0.4554 - generator_loss: 2.3978\n",
            "Epoch 341/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9305 - discriminator_loss: 0.4515 - generator_loss: 2.3942\n",
            "Epoch 342/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9638 - discriminator_loss: 0.4478 - generator_loss: 2.4084\n",
            "Epoch 343/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9538 - discriminator_loss: 0.4527 - generator_loss: 2.3965\n",
            "Epoch 344/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9543 - discriminator_loss: 0.4520 - generator_loss: 2.4085\n",
            "Epoch 345/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9480 - discriminator_loss: 0.4491 - generator_loss: 2.3974\n",
            "Epoch 346/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9216 - discriminator_loss: 0.4546 - generator_loss: 2.3878\n",
            "Epoch 347/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9573 - discriminator_loss: 0.4567 - generator_loss: 2.4079\n",
            "Epoch 348/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9375 - discriminator_loss: 0.4529 - generator_loss: 2.3958\n",
            "Epoch 349/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9438 - discriminator_loss: 0.4484 - generator_loss: 2.3919\n",
            "Epoch 350/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9714 - discriminator_loss: 0.4463 - generator_loss: 2.4115\n",
            "Epoch 351/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9124 - discriminator_loss: 0.4557 - generator_loss: 2.3866\n",
            "Epoch 352/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9199 - discriminator_loss: 0.4498 - generator_loss: 2.3792\n",
            "Epoch 353/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9155 - discriminator_loss: 0.4536 - generator_loss: 2.3787\n",
            "Epoch 354/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9529 - discriminator_loss: 0.4545 - generator_loss: 2.3979\n",
            "Epoch 355/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9445 - discriminator_loss: 0.4540 - generator_loss: 2.4045\n",
            "Epoch 356/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9718 - discriminator_loss: 0.4488 - generator_loss: 2.4161\n",
            "Epoch 357/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9639 - discriminator_loss: 0.4533 - generator_loss: 2.4005\n",
            "Epoch 358/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9550 - discriminator_loss: 0.4439 - generator_loss: 2.3972\n",
            "Epoch 359/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9631 - discriminator_loss: 0.4510 - generator_loss: 2.4022\n",
            "Epoch 360/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9557 - discriminator_loss: 0.4535 - generator_loss: 2.4115\n",
            "Epoch 361/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9472 - discriminator_loss: 0.4555 - generator_loss: 2.4149\n",
            "Epoch 362/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9591 - discriminator_loss: 0.4471 - generator_loss: 2.3990\n",
            "Epoch 363/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9681 - discriminator_loss: 0.4528 - generator_loss: 2.4047\n",
            "Epoch 364/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9182 - discriminator_loss: 0.4503 - generator_loss: 2.3835\n",
            "Epoch 365/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9828 - discriminator_loss: 0.4524 - generator_loss: 2.4207\n",
            "Epoch 366/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9673 - discriminator_loss: 0.4514 - generator_loss: 2.4048\n",
            "Epoch 367/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9498 - discriminator_loss: 0.4467 - generator_loss: 2.3987\n",
            "Epoch 368/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9619 - discriminator_loss: 0.4493 - generator_loss: 2.4105\n",
            "Epoch 369/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9478 - discriminator_loss: 0.4527 - generator_loss: 2.3957\n",
            "Epoch 370/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9412 - discriminator_loss: 0.4469 - generator_loss: 2.3954\n",
            "Epoch 371/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9503 - discriminator_loss: 0.4514 - generator_loss: 2.4127\n",
            "Epoch 372/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9567 - discriminator_loss: 0.4512 - generator_loss: 2.4086\n",
            "Epoch 373/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9366 - discriminator_loss: 0.4559 - generator_loss: 2.4046\n",
            "Epoch 374/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9321 - discriminator_loss: 0.4535 - generator_loss: 2.3926\n",
            "Epoch 375/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9688 - discriminator_loss: 0.4473 - generator_loss: 2.4146\n",
            "Epoch 376/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9721 - discriminator_loss: 0.4515 - generator_loss: 2.4075\n",
            "Epoch 377/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9345 - discriminator_loss: 0.4463 - generator_loss: 2.3884\n",
            "Epoch 378/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9212 - discriminator_loss: 0.4552 - generator_loss: 2.3944\n",
            "Epoch 379/500\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - delta_loss: -1.9622 - discriminator_loss: 0.4547 - generator_loss: 2.4140\n",
            "Epoch 380/500\n",
            "\u001b[1m 1/87\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 349ms/step - delta_loss: -2.0417 - discriminator_loss: 0.4111 - generator_loss: 2.4528"
          ]
        }
      ],
      "source": [
        "feature_dim = X.shape[1]\n",
        "num_classes = len(np.unique(y))  # 统一使用全尺寸的 num_classes, 即使是只对少数类训练 CGAN. 这样就不用做额外的标签映射。\n",
        "\n",
        "# 定义模型保存目录与文件名\n",
        "save_dir = balanced_folder / 'models' / scaling_method\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "generator_file = save_dir / (\n",
        "    f'{oversampling_method}('\n",
        "    f'n{noise_dim},f{feature_dim},c{num_classes},e{epochs},b{batch_size},'\n",
        "    f'gen[{gen_embed_dim},{gen_hidden_dims},{gen_learning_rate}],'\n",
        "    f'dis[{disc_embed_dim},{disc_hidden_dims},{disc_learning_rate}]'\n",
        "    ')_generator.keras'\n",
        ")\n",
        "discriminator_file = save_dir / (generator_file.stem[:-10] + '_discriminator.keras')\n",
        "cgan_file = save_dir / (generator_file.stem[:-10] + '_cgan.keras')\n",
        "\n",
        "\n",
        "if generator_file.exists() and not retrain:\n",
        "    # 如果已经存在预训练的生成器模型，则直接加载\n",
        "    print(f\"[{now()}] 📡 Loading pre-trained generator from {generator_file}\")\n",
        "    generator = tf.keras.models.load_model(generator_file)\n",
        "\n",
        "    print(f\"[{now()}] 📡 Loading pre-trained discriminator from {discriminator_file}\")\n",
        "    discriminator = tf.keras.models.load_model(discriminator_file)\n",
        "else:\n",
        "    print(f\"[{now()}] 🚀 Training cGAN [{generator_file.stem}]...\")\n",
        "\n",
        "    ## 1️⃣ 选择要用来训练的样本\n",
        "    selected_X, selected_y = select_cgan_subset(X, y, oversampling_method[-1])\n",
        "    print(f\"[{now()}] Selected X.shape: {selected_X.shape}, y.shape: {selected_y.shape}\")\n",
        "    print(f\"[{now()}] Selected labels: { {int(k): v for k, v in sorted(Counter(selected_y).items())} }\")\n",
        "\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((selected_X, selected_y))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    ## 2️⃣ 初始化 cGAN\n",
        "    generator = build_generator(num_classes, feature_dim, noise_dim=noise_dim, embed_dim=gen_embed_dim, hidden_dims=gen_hidden_dims)\n",
        "    discriminator = build_discriminator(num_classes, feature_dim, embed_dim=disc_embed_dim, hidden_dims=disc_hidden_dims)\n",
        "    cgan = ConditionalGAN(generator, discriminator, seen_labels=np.unique(selected_y))\n",
        "    cgan.compile(\n",
        "        g_optimizer=tf.keras.optimizers.Adam(learning_rate=gen_learning_rate, beta_1=0.5),\n",
        "        d_optimizer=tf.keras.optimizers.Adam(learning_rate=disc_learning_rate, beta_1=0.5),\n",
        "        loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "        )\n",
        "\n",
        "    ## 3️⃣ 训练 cGAN\n",
        "    cgan.fit(train_dataset, epochs=epochs,\n",
        "             callbacks=[\n",
        "                 MyReduceLR(delta_threshold=0.8, patience=5, factor=0.5),\n",
        "                #  BalanceCallback(delta_threshold=0.3, extra_steps=3),\n",
        "                 SaveOnInterval(interval=100, dest_gen_file=generator_file, dest_dis_file=discriminator_file),\n",
        "                 MyEarlyStopping(),\n",
        "                 ]\n",
        "             )\n",
        "\n",
        "    ## 4️⃣ 保存模型\n",
        "    generator.save(generator_file)\n",
        "    discriminator.save(discriminator_file)\n",
        "    cgan.build(input_shape=[(None, noise_dim), (None, 1)]) # cgan 要 build 后再保存，不然会有告警\n",
        "    cgan.save(cgan_file)\n",
        "    print(f\"[{now()}] ✅ Saved generator model to {generator_file}\")  # 其实只需要保存 generator 就够了\n",
        "\n",
        "    # 清理临时资源\n",
        "    del train_dataset\n",
        "    del selected_X\n",
        "    del selected_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXZWgCjzaj-"
      },
      "source": [
        "## 3️⃣ 使用 cGAN 生成新样本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld29W8B7aIdk"
      },
      "outputs": [],
      "source": [
        "def generate_samples(generator: tf.keras.Model, target_class: int, num_samples: int):\n",
        "    \"\"\"\n",
        "    Generates samples using the generator for a specific target class.\n",
        "\n",
        "    Args:\n",
        "        generator (tensorflow.keras.Model): The generator model.\n",
        "        target_class (int): The target class for which to generate samples.\n",
        "        num_samples (int): The number of samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Generated samples as a NumPy array.\n",
        "    \"\"\"\n",
        "    noise_dim = generator.input_shape[0][1]\n",
        "\n",
        "    # 随机生成一组噪声向量 shape=(num_samples, noise_dim)\n",
        "    noise = np.random.normal(0, 1, size=(num_samples, noise_dim))\n",
        "\n",
        "    # 随机生成一组类别标签 shape=(num_samples, 1), 全部为 target_class\n",
        "    labels = np.full((num_samples, 1), fill_value=target_class, dtype=np.int32)\n",
        "\n",
        "    # 使用生成器生成数据\n",
        "    generated_data = generator.predict([noise, labels], verbose=0)\n",
        "    return generated_data\n",
        "\n",
        "\n",
        "def cgan_undersample(cgan_discriminator: tf.keras.Model, sampling_strategy: dict, X: np.ndarray, y: np.ndarray):\n",
        "    \"\"\"\n",
        "    使用 CGAN 判别器对目标数据集进行欠采样，删除评分低的数据\n",
        "    \"\"\"\n",
        "    print(f'[{now()}] 📉 CGAN Undersampling ...')\n",
        "    print(f'  original X.shaep: {X.shape}')\n",
        "    print(f'  original labels_counts: {get_label_counts(y)}')\n",
        "    print(f'  undersample to: {sampling_strategy}')\n",
        "\n",
        "    keep_idxs = []\n",
        "\n",
        "    for cls, target_n in sampling_strategy.items():\n",
        "        idxs = np.where(y == cls)[0]\n",
        "\n",
        "        # nothing to drop if already <= target\n",
        "        if len(idxs) <= target_n:\n",
        "            keep_idxs.extend(idxs.tolist())\n",
        "            print(f'[{now()}] Skipping class [{cls}]: {len(idxs)} ≤ {target_n}')\n",
        "            continue\n",
        "\n",
        "        # Score all samples of this cls\n",
        "        X_cls = X[idxs]\n",
        "        y_cls = y[idxs].reshape(-1, 1)\n",
        "        scores = cgan_discriminator([X_cls, y_cls], training=False)\n",
        "        scores = tf.reshape(scores, [-1]).numpy()\n",
        "\n",
        "        # 按照判别器评分降序排列，取前 n 个保留(保留评分高的)\n",
        "        top_idxs = idxs[np.argsort(scores)[::-1][:target_n]]\n",
        "        # 按照判别器评分升序排列，取前 n 个保留(保留评分低的)\n",
        "        # top_idxs = idxs[np.argsort(scores)[:target_n]]\n",
        "\n",
        "        keep_idxs.extend(top_idxs.tolist())\n",
        "        print(f'[{now()}] Dropping {len(idxs) - target_n} samples for class [{cls}]: {len(idxs)} -> {target_n}')\n",
        "\n",
        "    # For any classes not in sampling_strategy, keep all\n",
        "    all_classes = set(np.unique(y))\n",
        "    leftover = all_classes - set(sampling_strategy.keys())\n",
        "    for cls in leftover:\n",
        "        keep_idxs.extend(np.where(y == cls)[0].tolist())\n",
        "\n",
        "    # produce final undersampled arrays\n",
        "    keep_idxs = np.sort(keep_idxs)\n",
        "    X_res = X[keep_idxs]\n",
        "    y_res = y[keep_idxs]\n",
        "\n",
        "    print(f'[{now()}] 📉 After CGAN Undersampling:')\n",
        "    print(f'  X_res.shape: {X_res.shape}')\n",
        "    print(f'  Labels: {get_label_counts(y_res)}')\n",
        "\n",
        "    return X_res, y_res\n",
        "\n",
        "def cgan_oversample(cgan_generator: tf.keras.Model, sampling_strategy: dict, X: np.ndarray, y: np.ndarray):\n",
        "    current_counts = get_label_counts(y)\n",
        "\n",
        "    print(f'[{now()}] 📈 CGAN Oversampling ...')\n",
        "    print(f'  original X.shaep: {X.shape}')\n",
        "    print(f'  original labels_counts: {current_counts}')\n",
        "    print(f'  oversample to: {sampling_strategy}')\n",
        "\n",
        "    all_X = [X]\n",
        "    all_y = [y]\n",
        "\n",
        "    for cls, desired_n in sampling_strategy.items():\n",
        "        current_n = current_counts.get(cls, 0)\n",
        "        n_to_gen = desired_n - current_n\n",
        "        if n_to_gen > 0:\n",
        "            print(f'[{now()}] Generating {n_to_gen} samples for class [{cls}]: {current_n} -> {desired_n}')\n",
        "            gen_samples = generate_samples(cgan_generator, cls, n_to_gen)\n",
        "            all_X.append(gen_samples)\n",
        "            all_y.append(np.full(n_to_gen, cls, dtype=np.int32))\n",
        "        else:\n",
        "            print(f'[{now()}] Skipping class [{cls}]: {current_n} ≥ {desired_n}')\n",
        "\n",
        "    X_res = np.concatenate(all_X)\n",
        "    y_res = np.concatenate(all_y)\n",
        "\n",
        "    print(f'[{now()}] 📈 After CGAN Oversampling:')\n",
        "    print(f'  X_res.shape: {X_res.shape}')\n",
        "    print(f'  Labels: {get_label_counts(y_res)}')\n",
        "\n",
        "    return X_res, y_res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z8xldy80_sI"
      },
      "outputs": [],
      "source": [
        "if len(resample_outputs) == 0:\n",
        "    print(f'[{now()}] 不生成过采样的数据文件')\n",
        "\n",
        "for resample_scheme in resample_outputs:\n",
        "    print(f'[{now()}] 🚀 resample_scheme: {resample_scheme}')\n",
        "\n",
        "    # CGAN 欠采样(如果需要的话)\n",
        "    if cgan_filter_strategy:\n",
        "        print(f'[{now()}] 🟡 Apply CGAN Undersampling.')\n",
        "        X_filtered, y_filtered = cgan_undersample(discriminator, cgan_filter_schemes[cgan_filter_strategy], X, y)\n",
        "    else:\n",
        "        X_filtered, y_filtered = X, y\n",
        "\n",
        "    # CGAN 过采样\n",
        "    print(f'[{now()}] 🟢 Apply CGAN Oversampling.')\n",
        "    resample_to = resample_schemes[resample_scheme]\n",
        "    X_resampled, y_resampled = cgan_oversample(generator, resample_to, X_filtered, y_filtered)\n",
        "\n",
        "    # 保存文件\n",
        "    filename = generator_file.stem[:-10] + (f'f{cgan_filter_strategy}.npy' if cgan_filter_strategy else '.npy')\n",
        "    X_resampled_file = balanced_folder / f'train_X_{scaling_method}_s{resample_scheme}_{filename}'\n",
        "    y_resampled_file = balanced_folder / f'train_y_{scaling_method}_s{resample_scheme}_{filename}'\n",
        "    np.save(X_resampled_file, X_resampled)\n",
        "    np.save(y_resampled_file, y_resampled)\n",
        "    print(f\"[{now()}] 💾 Saved resampled data to {X_resampled_file} & {y_resampled_file.name}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "print(f'[{now()}] ⛔ 运行结束. shutdown now...')\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "TGNmz5P2dIq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qR21AFUgeYXb",
        "AM7RomoyKpSt",
        "lUwtAak0tyuJ"
      ],
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}