{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dxJ73X_8msbm",
        "P2_m2DxUmnyF",
        "Z-MW8Tv7nawk",
        "Sx2N_dOzqXOg"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/preprocessing/pre_process_separated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CSE-CIC-IDS2018 数据集预处理\n",
        "\n",
        "## 数据集下载\n",
        "使用 aws 命令行工具，从云存储中下载: `aws s3 sync --no-sign-request --region us-east-2 \"s3://cse-cic-ids2018/Processed Traffic Data for ML Algorithms/\" ./`\n",
        "\n",
        "## 数据集内容\n",
        "### 特征项\n",
        "正常有 80 列特征。\n",
        "```\n",
        "['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
        "```\n",
        "只有 Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv 文件多了 `['Dst IP', 'Src Port', 'Flow ID', 'Src IP']` 四个特征。\n",
        "\n",
        "### 字符型特征\n",
        "只有 `Label` 特征是字符串，表示该行数据是某种类型的攻击。\n",
        "其余特征都是数值型。\n",
        "\n",
        "### Label 值\n",
        "['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC',\n",
        " 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye',\n",
        " 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris',\n",
        " 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        " 共 15 种。\n"
      ],
      "metadata": {
        "id": "RKUYkPpeQ7zM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab Env"
      ],
      "metadata": {
        "id": "dxJ73X_8msbm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2641f-LspVjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef97b628-d5d9-4ca1-ee76-c54d434bf742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/NYIT/870/datasets/CSE-CIC-IDS2018': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "### 挂载 Google Drive ###\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    # Colab 是一个虚拟机环境, /content 目录是默认的用户工作目录\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 打印 datasets 目录\n",
        "!ls -thl /content/drive/MyDrive/NYIT/870/datasets/CSE-CIC-IDS2018"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules import & Globals setup"
      ],
      "metadata": {
        "id": "lA7Uq7qxm-KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Modules ###\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "\n",
        "### Globals ###\n",
        "\n",
        "## 数据文件目录\n",
        "dataset = 'CSE-CIC-IDS2018'\n",
        "dataset_folder = f'/content/drive/MyDrive/NYIT/870/datasets/original/{dataset}/'\n",
        "preprocessed_folder = f'/content/drive/MyDrive/NYIT/870/datasets/preprocessed/{dataset}/'\n",
        "balanced_folder = f'/content/drive/MyDrive/NYIT/870/datasets/balanced/{dataset}/'\n",
        "\n",
        "## csv 文件匹配\n",
        "# 修改该正则表达式，可以只匹配某个单独的文件\n",
        "# csv_reg = '*01-03-2018*.csv'\n",
        "csv_reg = '*.csv'\n",
        "csv_files = list(Path(dataset_folder).rglob(csv_reg))\n",
        "for csv in csv_files:\n",
        "    print(f'csv file: {csv}')\n",
        "    pass\n",
        "\n",
        "## 指定 csv 文件\n",
        "csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "# csv_file = '/content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv'\n",
        "\n",
        "## 无用的特征列\n",
        "cols_to_drop = ['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Timestamp']\n",
        "\n",
        "## Label 列的所有可能值\n",
        "# unique_labels = []\n",
        "unique_labels = ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        "\n",
        "## 选择特征缩放的方式(标准化，归一化)\n",
        "# 支持: standard, minmax, robust, l1pstandard, l1pminmax\n",
        "# scaling_method = 'standard'\n",
        "# scaling_method = 'minmax'\n",
        "scaling_methods = ['l1pminmax', 'l1pstandard', 'robust']\n"
      ],
      "metadata": {
        "id": "vfJUPAKPu7mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c991a5c9-ab5f-4ca6-d416-76e101257299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Unique Values of the Label Column"
      ],
      "metadata": {
        "id": "P2_m2DxUmnyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 获取 Label 特征项的所有可能值 ##\n",
        "\n",
        "# unique_labels = []\n",
        "if not unique_labels:\n",
        "    all_labels_count = {}  # 统计所有 csv 文件的 labels 种类与数量\n",
        "\n",
        "    # 遍历每个 csv 文件\n",
        "    csv_files = list(Path(dataset_folder).rglob('*.csv'))\n",
        "    for csv in csv_files:\n",
        "        print(f'Reading csv file: {Path(csv).name}')\n",
        "\n",
        "        csv_labels_count = {}  # 统计当前 CSV 文件的 labels 数量\n",
        "\n",
        "        # 分块读取\n",
        "        chunk_size = 100000\n",
        "        for chunk in pd.read_csv(csv, usecols=['Label'], chunksize=chunk_size):\n",
        "            if 'Label' in chunk.columns:\n",
        "                # 统计当前 chunk 的 labels 种类与数量，返回 {'Benign': 100, 'Bot': 99} 字典\n",
        "                chunk_labels_count = chunk['Label'].value_counts().to_dict()\n",
        "\n",
        "                for label, count in chunk_labels_count.items():\n",
        "                    # 更新当前 csv 文件的 labels 统计\n",
        "                    csv_labels_count[label] = csv_labels_count.get(label, 0) + count\n",
        "\n",
        "                    # 更新所有 csv 文件的 labels 统计\n",
        "                    all_labels_count[label] = all_labels_count.get(label, 0) + count\n",
        "\n",
        "        # 打印当前 csv 的 unique labels\n",
        "        print(f'  unique labels: [{len(csv_labels_count)}], {dict(sorted(csv_labels_count.items()))}\\n')\n",
        "        pass\n",
        "\n",
        "    # 打印所有的 unique labels\n",
        "    print(f'All unique labels count: [{len(all_labels_count)}] \\n{dict(sorted(all_labels_count.items()))}\\n')\n",
        "\n",
        "    # 如果 'Label' 存在则删除\n",
        "    all_labels_count.pop('Label', None)\n",
        "\n",
        "    # 转换成列表\n",
        "    unique_labels = sorted(all_labels_count.keys())\n",
        "else:\n",
        "    print(f'unique_labels has been set')\n",
        "\n",
        "# 打印所有唯一的 Label 值\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] All unique labels list: [{len(unique_labels)}] (removed 'Lable')\\n{unique_labels}\", )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHjyLiWerf0r",
        "outputId": "d04336f6-0a12-4fec-a735-7e87d00375a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_labels has been set\n",
            "[04/20/25 03:59:05] All unique labels list: [15] (removed 'Lable')\n",
            "['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unique Labels Output:\n",
        "```\n",
        "Reading csv file: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [2], {'Benign': 762384, 'Bot': 286191}\n",
        "Reading csv file: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [4], {'Benign': 446772, 'DoS attacks-Hulk': 461912, 'DoS attacks-SlowHTTPTest': 139890, 'Label': 1}\n",
        "Reading csv file: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [4], {'Benign': 1048009, 'Brute Force -Web': 362, 'Brute Force -XSS': 151, 'SQL Injection': 53}\n",
        "Reading csv file: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [2], {'Benign': 7372557, 'DDoS attacks-LOIC-HTTP': 576191}\n",
        "Reading csv file: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [3], {'Benign': 238037, 'Infilteration': 93063, 'Label': 25}\n",
        "Reading csv file: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [3], {'Benign': 996077, 'DoS attacks-GoldenEye': 41508, 'DoS attacks-Slowloris': 10990}\n",
        "Reading csv file: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [4], {'Benign': 1048213, 'Brute Force -Web': 249, 'Brute Force -XSS': 79, 'SQL Injection': 34}\n",
        "Reading csv file: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [3], {'Benign': 667626, 'FTP-BruteForce': 193360, 'SSH-Bruteforce': 187589}\n",
        "Reading csv file: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [3], {'Benign': 360833, 'DDOS attack-HOIC': 686012, 'DDOS attack-LOIC-UDP': 1730}\n",
        "Reading csv file: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
        "  unique labels: [3], {'Benign': 544200, 'Infilteration': 68871, 'Label': 33}\n",
        "\n",
        "All unique labels count: [16]\n",
        "{'Benign': 13484708, 'Bot': 286191, 'Brute Force -Web': 611, 'Brute Force -XSS': 230, 'DDOS attack-HOIC': 686012, 'DDOS attack-LOIC-UDP': 1730, 'DDoS attacks-LOIC-HTTP': 576191, 'DoS attacks-GoldenEye': 41508, 'DoS attacks-Hulk': 461912, 'DoS attacks-SlowHTTPTest': 139890, 'DoS attacks-Slowloris': 10990, 'FTP-BruteForce': 193360, 'Infilteration': 161934, 'Label': 59, 'SQL Injection': 87, 'SSH-Bruteforce': 187589}\n",
        "\n",
        "All unique labels list: [15] (removed 'Lable')\n",
        "['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        "```\n",
        "###Questions❓\n",
        "* 很明显 Benign 的数据太多了\n",
        "* ['Brute Force -Web': 611, 'Brute Force -XSS': 230, 'DDOS attack-LOIC-UDP': 1730, 'SQL Injection': 87] 这几个又太少\n",
        "\n",
        "所以\n",
        "1. 在所 imblanced 处理的时候，是否可以针对这些少量的 Label 进行增强？\n",
        "2. 针对 3GB 的那个文件，是不是可以把非 Benign 的都提取出来，然后再补上 Benign 数据到 300MB 的平均大小即可。太大了 Colab 会崩溃。\n"
      ],
      "metadata": {
        "id": "EC3fF8hJfCe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a CSV File"
      ],
      "metadata": {
        "id": "Z-MW8Tv7nawk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 读取 csv 到 pandas.DataFrame 对象 ##\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] Loading csv file: {csv_file}\")\n",
        "\n",
        "## 一次性读取 #######\n",
        "nrows = None  # 一次性读取多少行, None 表示全部读取\n",
        "df = pd.read_csv(csv_file, nrows=nrows)\n",
        "####################\n",
        "\n",
        "## 分块读取 #########\n",
        "# chunk_size = 100000  # Adjust based on memory capacity\n",
        "# df_list = []  # List to store chunks\n",
        "\n",
        "# # Read CSV file in chunks\n",
        "# for chunk in pd.read_csv(csv_file, chunksize=chunk_size):\n",
        "#     print(f\"Processing chunk with shape: {chunk.shape}\")\n",
        "#     df_list.append(chunk)  # Store each chunk\n",
        "\n",
        "# # Combine all chunks into a single DataFrame\n",
        "# df = pd.concat(df_list, ignore_index=True)\n",
        "####################\n",
        "\n",
        "print(f'  原始数据包含[{len(df.columns)}]列特征: {sorted(df.columns.tolist())}')\n",
        "print(f\"  Label 列的值: {df['Label'].value_counts()}\")\n",
        "\n",
        "# 删除 Label 列的值等于 'Label' 的行\n",
        "# (因为有几个文件在某一行又出现了一排的列名)\n",
        "if 'Label' in df.columns and ('Label' in df['Label'].values):\n",
        "    df = df[df['Label'] != 'Label']\n",
        "    print(f'[{datetime.now().strftime(\"%x %X\")}] 删除其中 Label 列的值等于 \"Label\" 的行')\n",
        "    print(f\"  Label 列的值: {df['Label'].value_counts()}\")\n",
        "\n",
        "print('\\n===== DataFrame Info =====')\n",
        "df.info()\n",
        "print('===== DataFrame Info =====')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8dRmoXf_AKl",
        "outputId": "e7243ba4-8ed1-46e5-cef2-5fff436454b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/20/25 03:59:05] Loading csv file: /content/drive/MyDrive/NYIT/870/datasets/original/CSE-CIC-IDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
            "  原始数据包含[80]列特征: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label 列的值: Label\n",
            "Benign    762384\n",
            "Bot       286191\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== DataFrame Info =====\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 80 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   Dst Port           1048575 non-null  int64  \n",
            " 1   Protocol           1048575 non-null  int64  \n",
            " 2   Timestamp          1048575 non-null  object \n",
            " 3   Flow Duration      1048575 non-null  int64  \n",
            " 4   Tot Fwd Pkts       1048575 non-null  int64  \n",
            " 5   Tot Bwd Pkts       1048575 non-null  int64  \n",
            " 6   TotLen Fwd Pkts    1048575 non-null  int64  \n",
            " 7   TotLen Bwd Pkts    1048575 non-null  float64\n",
            " 8   Fwd Pkt Len Max    1048575 non-null  int64  \n",
            " 9   Fwd Pkt Len Min    1048575 non-null  int64  \n",
            " 10  Fwd Pkt Len Mean   1048575 non-null  float64\n",
            " 11  Fwd Pkt Len Std    1048575 non-null  float64\n",
            " 12  Bwd Pkt Len Max    1048575 non-null  int64  \n",
            " 13  Bwd Pkt Len Min    1048575 non-null  int64  \n",
            " 14  Bwd Pkt Len Mean   1048575 non-null  float64\n",
            " 15  Bwd Pkt Len Std    1048575 non-null  float64\n",
            " 16  Flow Byts/s        1046017 non-null  float64\n",
            " 17  Flow Pkts/s        1048575 non-null  float64\n",
            " 18  Flow IAT Mean      1048575 non-null  float64\n",
            " 19  Flow IAT Std       1048575 non-null  float64\n",
            " 20  Flow IAT Max       1048575 non-null  float64\n",
            " 21  Flow IAT Min       1048575 non-null  float64\n",
            " 22  Fwd IAT Tot        1048575 non-null  float64\n",
            " 23  Fwd IAT Mean       1048575 non-null  float64\n",
            " 24  Fwd IAT Std        1048575 non-null  float64\n",
            " 25  Fwd IAT Max        1048575 non-null  float64\n",
            " 26  Fwd IAT Min        1048575 non-null  float64\n",
            " 27  Bwd IAT Tot        1048575 non-null  float64\n",
            " 28  Bwd IAT Mean       1048575 non-null  float64\n",
            " 29  Bwd IAT Std        1048575 non-null  float64\n",
            " 30  Bwd IAT Max        1048575 non-null  float64\n",
            " 31  Bwd IAT Min        1048575 non-null  float64\n",
            " 32  Fwd PSH Flags      1048575 non-null  int64  \n",
            " 33  Bwd PSH Flags      1048575 non-null  int64  \n",
            " 34  Fwd URG Flags      1048575 non-null  int64  \n",
            " 35  Bwd URG Flags      1048575 non-null  int64  \n",
            " 36  Fwd Header Len     1048575 non-null  int64  \n",
            " 37  Bwd Header Len     1048575 non-null  int64  \n",
            " 38  Fwd Pkts/s         1048575 non-null  float64\n",
            " 39  Bwd Pkts/s         1048575 non-null  float64\n",
            " 40  Pkt Len Min        1048575 non-null  int64  \n",
            " 41  Pkt Len Max        1048575 non-null  int64  \n",
            " 42  Pkt Len Mean       1048575 non-null  float64\n",
            " 43  Pkt Len Std        1048575 non-null  float64\n",
            " 44  Pkt Len Var        1048575 non-null  float64\n",
            " 45  FIN Flag Cnt       1048575 non-null  int64  \n",
            " 46  SYN Flag Cnt       1048575 non-null  int64  \n",
            " 47  RST Flag Cnt       1048575 non-null  int64  \n",
            " 48  PSH Flag Cnt       1048575 non-null  int64  \n",
            " 49  ACK Flag Cnt       1048575 non-null  int64  \n",
            " 50  URG Flag Cnt       1048575 non-null  int64  \n",
            " 51  CWE Flag Count     1048575 non-null  int64  \n",
            " 52  ECE Flag Cnt       1048575 non-null  int64  \n",
            " 53  Down/Up Ratio      1048575 non-null  int64  \n",
            " 54  Pkt Size Avg       1048575 non-null  float64\n",
            " 55  Fwd Seg Size Avg   1048575 non-null  float64\n",
            " 56  Bwd Seg Size Avg   1048575 non-null  float64\n",
            " 57  Fwd Byts/b Avg     1048575 non-null  int64  \n",
            " 58  Fwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 59  Fwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 60  Bwd Byts/b Avg     1048575 non-null  int64  \n",
            " 61  Bwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 62  Bwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 63  Subflow Fwd Pkts   1048575 non-null  int64  \n",
            " 64  Subflow Fwd Byts   1048575 non-null  int64  \n",
            " 65  Subflow Bwd Pkts   1048575 non-null  int64  \n",
            " 66  Subflow Bwd Byts   1048575 non-null  int64  \n",
            " 67  Init Fwd Win Byts  1048575 non-null  int64  \n",
            " 68  Init Bwd Win Byts  1048575 non-null  int64  \n",
            " 69  Fwd Act Data Pkts  1048575 non-null  int64  \n",
            " 70  Fwd Seg Size Min   1048575 non-null  int64  \n",
            " 71  Active Mean        1048575 non-null  float64\n",
            " 72  Active Std         1048575 non-null  float64\n",
            " 73  Active Max         1048575 non-null  float64\n",
            " 74  Active Min         1048575 non-null  float64\n",
            " 75  Idle Mean          1048575 non-null  float64\n",
            " 76  Idle Std           1048575 non-null  float64\n",
            " 77  Idle Max           1048575 non-null  float64\n",
            " 78  Idle Min           1048575 non-null  float64\n",
            " 79  Label              1048575 non-null  object \n",
            "dtypes: float64(37), int64(41), object(2)\n",
            "memory usage: 640.0+ MB\n",
            "===== DataFrame Info =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop some columns"
      ],
      "metadata": {
        "id": "Sx2N_dOzqXOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 删除部分无用的特征列 ##\n",
        "cols_to_drop_exist = [col for col in cols_to_drop if col in df.columns]\n",
        "df = df.drop(cols_to_drop_exist, axis=1)  # axis=1 表示删除列\n",
        "\n",
        "print('\\n===== DataFrame Info =====')\n",
        "df.info()\n",
        "print('===== DataFrame Info =====')"
      ],
      "metadata": {
        "id": "lT7TBAcJnvdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4072da4-c977-415c-bc6c-420b3a838519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== DataFrame Info =====\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 79 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   Dst Port           1048575 non-null  int64  \n",
            " 1   Protocol           1048575 non-null  int64  \n",
            " 2   Flow Duration      1048575 non-null  int64  \n",
            " 3   Tot Fwd Pkts       1048575 non-null  int64  \n",
            " 4   Tot Bwd Pkts       1048575 non-null  int64  \n",
            " 5   TotLen Fwd Pkts    1048575 non-null  int64  \n",
            " 6   TotLen Bwd Pkts    1048575 non-null  float64\n",
            " 7   Fwd Pkt Len Max    1048575 non-null  int64  \n",
            " 8   Fwd Pkt Len Min    1048575 non-null  int64  \n",
            " 9   Fwd Pkt Len Mean   1048575 non-null  float64\n",
            " 10  Fwd Pkt Len Std    1048575 non-null  float64\n",
            " 11  Bwd Pkt Len Max    1048575 non-null  int64  \n",
            " 12  Bwd Pkt Len Min    1048575 non-null  int64  \n",
            " 13  Bwd Pkt Len Mean   1048575 non-null  float64\n",
            " 14  Bwd Pkt Len Std    1048575 non-null  float64\n",
            " 15  Flow Byts/s        1046017 non-null  float64\n",
            " 16  Flow Pkts/s        1048575 non-null  float64\n",
            " 17  Flow IAT Mean      1048575 non-null  float64\n",
            " 18  Flow IAT Std       1048575 non-null  float64\n",
            " 19  Flow IAT Max       1048575 non-null  float64\n",
            " 20  Flow IAT Min       1048575 non-null  float64\n",
            " 21  Fwd IAT Tot        1048575 non-null  float64\n",
            " 22  Fwd IAT Mean       1048575 non-null  float64\n",
            " 23  Fwd IAT Std        1048575 non-null  float64\n",
            " 24  Fwd IAT Max        1048575 non-null  float64\n",
            " 25  Fwd IAT Min        1048575 non-null  float64\n",
            " 26  Bwd IAT Tot        1048575 non-null  float64\n",
            " 27  Bwd IAT Mean       1048575 non-null  float64\n",
            " 28  Bwd IAT Std        1048575 non-null  float64\n",
            " 29  Bwd IAT Max        1048575 non-null  float64\n",
            " 30  Bwd IAT Min        1048575 non-null  float64\n",
            " 31  Fwd PSH Flags      1048575 non-null  int64  \n",
            " 32  Bwd PSH Flags      1048575 non-null  int64  \n",
            " 33  Fwd URG Flags      1048575 non-null  int64  \n",
            " 34  Bwd URG Flags      1048575 non-null  int64  \n",
            " 35  Fwd Header Len     1048575 non-null  int64  \n",
            " 36  Bwd Header Len     1048575 non-null  int64  \n",
            " 37  Fwd Pkts/s         1048575 non-null  float64\n",
            " 38  Bwd Pkts/s         1048575 non-null  float64\n",
            " 39  Pkt Len Min        1048575 non-null  int64  \n",
            " 40  Pkt Len Max        1048575 non-null  int64  \n",
            " 41  Pkt Len Mean       1048575 non-null  float64\n",
            " 42  Pkt Len Std        1048575 non-null  float64\n",
            " 43  Pkt Len Var        1048575 non-null  float64\n",
            " 44  FIN Flag Cnt       1048575 non-null  int64  \n",
            " 45  SYN Flag Cnt       1048575 non-null  int64  \n",
            " 46  RST Flag Cnt       1048575 non-null  int64  \n",
            " 47  PSH Flag Cnt       1048575 non-null  int64  \n",
            " 48  ACK Flag Cnt       1048575 non-null  int64  \n",
            " 49  URG Flag Cnt       1048575 non-null  int64  \n",
            " 50  CWE Flag Count     1048575 non-null  int64  \n",
            " 51  ECE Flag Cnt       1048575 non-null  int64  \n",
            " 52  Down/Up Ratio      1048575 non-null  int64  \n",
            " 53  Pkt Size Avg       1048575 non-null  float64\n",
            " 54  Fwd Seg Size Avg   1048575 non-null  float64\n",
            " 55  Bwd Seg Size Avg   1048575 non-null  float64\n",
            " 56  Fwd Byts/b Avg     1048575 non-null  int64  \n",
            " 57  Fwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 58  Fwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 59  Bwd Byts/b Avg     1048575 non-null  int64  \n",
            " 60  Bwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 61  Bwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 62  Subflow Fwd Pkts   1048575 non-null  int64  \n",
            " 63  Subflow Fwd Byts   1048575 non-null  int64  \n",
            " 64  Subflow Bwd Pkts   1048575 non-null  int64  \n",
            " 65  Subflow Bwd Byts   1048575 non-null  int64  \n",
            " 66  Init Fwd Win Byts  1048575 non-null  int64  \n",
            " 67  Init Bwd Win Byts  1048575 non-null  int64  \n",
            " 68  Fwd Act Data Pkts  1048575 non-null  int64  \n",
            " 69  Fwd Seg Size Min   1048575 non-null  int64  \n",
            " 70  Active Mean        1048575 non-null  float64\n",
            " 71  Active Std         1048575 non-null  float64\n",
            " 72  Active Max         1048575 non-null  float64\n",
            " 73  Active Min         1048575 non-null  float64\n",
            " 74  Idle Mean          1048575 non-null  float64\n",
            " 75  Idle Std           1048575 non-null  float64\n",
            " 76  Idle Max           1048575 non-null  float64\n",
            " 77  Idle Min           1048575 non-null  float64\n",
            " 78  Label              1048575 non-null  object \n",
            "dtypes: float64(37), int64(41), object(1)\n",
            "memory usage: 632.0+ MB\n",
            "===== DataFrame Info =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Inf & NaN"
      ],
      "metadata": {
        "id": "Ad2Ox7EqqejW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 保证数值列转换成数值类型而不是 object 类型 ##\n",
        "\n",
        "# 提数值取特征列，排除 'Label' 列\n",
        "numeric_features = df.drop(columns=['Label'])\n",
        "\n",
        "# 对数值特征列进行数值转换\n",
        "df[numeric_features.columns] = numeric_features.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C0U_qm0H9ZY",
        "outputId": "c3ce31de-b98a-4507-83e5-564fff9cbb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 79 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   Dst Port           1048575 non-null  int64  \n",
            " 1   Protocol           1048575 non-null  int64  \n",
            " 2   Flow Duration      1048575 non-null  int64  \n",
            " 3   Tot Fwd Pkts       1048575 non-null  int64  \n",
            " 4   Tot Bwd Pkts       1048575 non-null  int64  \n",
            " 5   TotLen Fwd Pkts    1048575 non-null  int64  \n",
            " 6   TotLen Bwd Pkts    1048575 non-null  float64\n",
            " 7   Fwd Pkt Len Max    1048575 non-null  int64  \n",
            " 8   Fwd Pkt Len Min    1048575 non-null  int64  \n",
            " 9   Fwd Pkt Len Mean   1048575 non-null  float64\n",
            " 10  Fwd Pkt Len Std    1048575 non-null  float64\n",
            " 11  Bwd Pkt Len Max    1048575 non-null  int64  \n",
            " 12  Bwd Pkt Len Min    1048575 non-null  int64  \n",
            " 13  Bwd Pkt Len Mean   1048575 non-null  float64\n",
            " 14  Bwd Pkt Len Std    1048575 non-null  float64\n",
            " 15  Flow Byts/s        1046017 non-null  float64\n",
            " 16  Flow Pkts/s        1048575 non-null  float64\n",
            " 17  Flow IAT Mean      1048575 non-null  float64\n",
            " 18  Flow IAT Std       1048575 non-null  float64\n",
            " 19  Flow IAT Max       1048575 non-null  float64\n",
            " 20  Flow IAT Min       1048575 non-null  float64\n",
            " 21  Fwd IAT Tot        1048575 non-null  float64\n",
            " 22  Fwd IAT Mean       1048575 non-null  float64\n",
            " 23  Fwd IAT Std        1048575 non-null  float64\n",
            " 24  Fwd IAT Max        1048575 non-null  float64\n",
            " 25  Fwd IAT Min        1048575 non-null  float64\n",
            " 26  Bwd IAT Tot        1048575 non-null  float64\n",
            " 27  Bwd IAT Mean       1048575 non-null  float64\n",
            " 28  Bwd IAT Std        1048575 non-null  float64\n",
            " 29  Bwd IAT Max        1048575 non-null  float64\n",
            " 30  Bwd IAT Min        1048575 non-null  float64\n",
            " 31  Fwd PSH Flags      1048575 non-null  int64  \n",
            " 32  Bwd PSH Flags      1048575 non-null  int64  \n",
            " 33  Fwd URG Flags      1048575 non-null  int64  \n",
            " 34  Bwd URG Flags      1048575 non-null  int64  \n",
            " 35  Fwd Header Len     1048575 non-null  int64  \n",
            " 36  Bwd Header Len     1048575 non-null  int64  \n",
            " 37  Fwd Pkts/s         1048575 non-null  float64\n",
            " 38  Bwd Pkts/s         1048575 non-null  float64\n",
            " 39  Pkt Len Min        1048575 non-null  int64  \n",
            " 40  Pkt Len Max        1048575 non-null  int64  \n",
            " 41  Pkt Len Mean       1048575 non-null  float64\n",
            " 42  Pkt Len Std        1048575 non-null  float64\n",
            " 43  Pkt Len Var        1048575 non-null  float64\n",
            " 44  FIN Flag Cnt       1048575 non-null  int64  \n",
            " 45  SYN Flag Cnt       1048575 non-null  int64  \n",
            " 46  RST Flag Cnt       1048575 non-null  int64  \n",
            " 47  PSH Flag Cnt       1048575 non-null  int64  \n",
            " 48  ACK Flag Cnt       1048575 non-null  int64  \n",
            " 49  URG Flag Cnt       1048575 non-null  int64  \n",
            " 50  CWE Flag Count     1048575 non-null  int64  \n",
            " 51  ECE Flag Cnt       1048575 non-null  int64  \n",
            " 52  Down/Up Ratio      1048575 non-null  int64  \n",
            " 53  Pkt Size Avg       1048575 non-null  float64\n",
            " 54  Fwd Seg Size Avg   1048575 non-null  float64\n",
            " 55  Bwd Seg Size Avg   1048575 non-null  float64\n",
            " 56  Fwd Byts/b Avg     1048575 non-null  int64  \n",
            " 57  Fwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 58  Fwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 59  Bwd Byts/b Avg     1048575 non-null  int64  \n",
            " 60  Bwd Pkts/b Avg     1048575 non-null  int64  \n",
            " 61  Bwd Blk Rate Avg   1048575 non-null  int64  \n",
            " 62  Subflow Fwd Pkts   1048575 non-null  int64  \n",
            " 63  Subflow Fwd Byts   1048575 non-null  int64  \n",
            " 64  Subflow Bwd Pkts   1048575 non-null  int64  \n",
            " 65  Subflow Bwd Byts   1048575 non-null  int64  \n",
            " 66  Init Fwd Win Byts  1048575 non-null  int64  \n",
            " 67  Init Bwd Win Byts  1048575 non-null  int64  \n",
            " 68  Fwd Act Data Pkts  1048575 non-null  int64  \n",
            " 69  Fwd Seg Size Min   1048575 non-null  int64  \n",
            " 70  Active Mean        1048575 non-null  float64\n",
            " 71  Active Std         1048575 non-null  float64\n",
            " 72  Active Max         1048575 non-null  float64\n",
            " 73  Active Min         1048575 non-null  float64\n",
            " 74  Idle Mean          1048575 non-null  float64\n",
            " 75  Idle Std           1048575 non-null  float64\n",
            " 76  Idle Max           1048575 non-null  float64\n",
            " 77  Idle Min           1048575 non-null  float64\n",
            " 78  Label              1048575 non-null  object \n",
            "dtypes: float64(37), int64(41), object(1)\n",
            "memory usage: 632.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 处理 Inf 值 ##\n",
        "print(\"正无穷 (+Inf) 个数:\", (df == np.inf).sum().sum())\n",
        "print(\"负无穷 (-Inf) 个数:\", (df == -np.inf).sum().sum())\n",
        "\n",
        "# 方法一: 删除该行\n",
        "df = df[~df.isin([np.inf, -np.inf]).any(axis=1)]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 方法二: 替换为对应列的最大/最小值\n",
        "# max_value = df.replace([np.inf, -np.inf], np.nan).max()\n",
        "# min_value = df.replace([np.inf, -np.inf], np.nan).min()\n",
        "# df.replace(np.inf, max_value, inplace=True)\n",
        "# df.replace(-np.inf, min_value, inplace=True)\n",
        "\n",
        "# 方法三: 替换成 NaN\n",
        "# df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "print(df.shape)\n",
        "print(\"正无穷 (+Inf) 个数:\", (df == np.inf).sum().sum())\n",
        "print(\"负无穷 (-Inf) 个数:\", (df == -np.inf).sum().sum())"
      ],
      "metadata": {
        "id": "OoFKfXJojvvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce653134-68fa-4b6b-a927-73a65e856c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正无穷 (+Inf) 个数: 5542\n",
            "负无穷 (-Inf) 个数: 0\n",
            "(1044525, 79)\n",
            "正无穷 (+Inf) 个数: 0\n",
            "负无穷 (-Inf) 个数: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 处理 NaN 值 ##\n",
        "print(f'NaN 个数: {df.isna().sum().sum()}')\n",
        "\n",
        "# 方法一: 删除该行\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 方法二: 填充值\n",
        "# df['Label'] = df['Label'].fillna('Benign')  # 填充 Label 列\n",
        "# df = df.fillna(0)  # 填充其他列\n",
        "\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "c5JePC5NOABI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12399d22-a6d9-4b07-abbf-c36415b4a447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN 个数: 0\n",
            "(1044525, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling of Numerical Features"
      ],
      "metadata": {
        "id": "rJtdRtFZ1OgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 对数值型特征进行特征缩放(标准化或者归一化) ##\n",
        "\n",
        "def scaling(X, scaling_method, output_file):\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] 📊 Scaling method: {scaling_method}\")\n",
        "\n",
        "    if scaling_method == 'standard':\n",
        "        # 标准化 (均值为0，标准差为1)\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        pass\n",
        "    elif scaling_method == 'minmax':\n",
        "        # 归一化 (缩放到 [0,1] 区间)\n",
        "        scaler = MinMaxScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        pass\n",
        "    elif scaling_method == 'l1pstandard':\n",
        "        X_log = np.log1p(X.replace(-1, -0.5))\n",
        "        X_scaled = StandardScaler().fit_transform(X_log)\n",
        "        pass\n",
        "    elif scaling_method == 'l1pminmax':\n",
        "        # 把 -1 值替换成 -0.5，然后进行 log1p 缩放极端值\n",
        "        X_log = np.log1p(X.replace(-1, -0.5))\n",
        "        # 最后再归一化\n",
        "        X_scaled = MinMaxScaler().fit_transform(X_log)\n",
        "        pass\n",
        "    elif scaling_method == 'robust':\n",
        "        X_scaled = RobustScaler().fit_transform(X)\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError(f'Unknown scaling method: {scaling_method}')\n",
        "\n",
        "    # 使用 float32 减小文件大小\n",
        "    X_scaled = X_scaled.astype(np.float32)\n",
        "\n",
        "    np.save(output_file, X_scaled)  # 保存为 .npy 文件\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {output_file}\\n\")\n",
        "    return X_scaled\n",
        "\n",
        "df_numeric = df.drop(columns=['Label'])  # 剔除 Label 列，保留数值列\n",
        "filename = Path(csv_file).stem  # 获取原文件名，不包含扩展名\n",
        "\n",
        "for scaling_method in scaling_methods:\n",
        "    output_file = Path(preprocessed_folder) / f'separated/{filename}_X_{scaling_method}.npy'\n",
        "    X_scaled = scaling(df_numeric, scaling_method, output_file)\n"
      ],
      "metadata": {
        "id": "Gwp9_Bce1U8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da90bb0-9b73-4114-834b-f26d879fc295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/20/25 03:59:31] 📊 Scaling method: l1pminmax\n",
            "[04/20/25 03:59:35] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/preprocessed/CSE-CIC-IDS2018/separated/Friday-02-03-2018_TrafficForML_CICFlowMeter_X_l1pminmax.npy\n",
            "\n",
            "[04/20/25 03:59:35] 📊 Scaling method: l1pstandard\n",
            "[04/20/25 03:59:40] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/preprocessed/CSE-CIC-IDS2018/separated/Friday-02-03-2018_TrafficForML_CICFlowMeter_X_l1pstandard.npy\n",
            "\n",
            "[04/20/25 03:59:40] 📊 Scaling method: robust\n",
            "[04/20/25 03:59:46] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/preprocessed/CSE-CIC-IDS2018/separated/Friday-02-03-2018_TrafficForML_CICFlowMeter_X_robust.npy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Enconding (Numericalization & One-hot)"
      ],
      "metadata": {
        "id": "Bs3SQTxZ8oA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'unique labels: {unique_labels}\\n')\n",
        "\n",
        "\n",
        "## 对 Label 特征列进行数值化编码 ##\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] Numericalization Encoding...\")\n",
        "\n",
        "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "for key, value in label_mapping.items():\n",
        "    print(f'{value:2}: {key}')\n",
        "\n",
        "def encode_label(label):\n",
        "    if label in label_mapping:\n",
        "        return label_mapping[label]\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown label '{label}' encountered during encoding.\")\n",
        "\n",
        "df['Label_encoded'] = df['Label'].apply(encode_label)\n",
        "print(df['Label_encoded'].shape)\n",
        "\n",
        "output_file = Path(preprocessed_folder) / f'separated/{filename}_label.npy'\n",
        "np.save(output_file, df['Label_encoded'].to_numpy())\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ✅ Saved to {output_file}\")"
      ],
      "metadata": {
        "id": "IWzRk7Lv9I6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1489d2fb-bdcd-4e97-9244-67f717e7242d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique labels: ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
            "\n",
            "[04/20/25 03:59:46] Numericalization Encoding...\n",
            " 0: Benign\n",
            " 1: Bot\n",
            " 2: Brute Force -Web\n",
            " 3: Brute Force -XSS\n",
            " 4: DDOS attack-HOIC\n",
            " 5: DDOS attack-LOIC-UDP\n",
            " 6: DDoS attacks-LOIC-HTTP\n",
            " 7: DoS attacks-GoldenEye\n",
            " 8: DoS attacks-Hulk\n",
            " 9: DoS attacks-SlowHTTPTest\n",
            "10: DoS attacks-Slowloris\n",
            "11: FTP-BruteForce\n",
            "12: Infilteration\n",
            "13: SQL Injection\n",
            "14: SSH-Bruteforce\n",
            "(1044525,)\n",
            "[04/20/25 03:59:47] ✅ Saved to /content/drive/MyDrive/NYIT/870/datasets/preprocessed/CSE-CIC-IDS2018/separated/Friday-02-03-2018_TrafficForML_CICFlowMeter_label.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 对 Label 特征列进行 onehot 编码 ##\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] One-hot Encoding...\")\n",
        "\n",
        "do_onehot = False\n",
        "if do_onehot:\n",
        "    # 映射字典\n",
        "    label_mapping = {lbl: [1 if lbl == label else 0 for label in unique_labels] for lbl in unique_labels}\n",
        "    for key, value in label_mapping.items():\n",
        "        print(f'{value}: {key}')\n",
        "\n",
        "    # onehot 编码\n",
        "    df_onehot = pd.DataFrame(df['Label'].map(label_mapping).to_list(), columns=unique_labels)\n",
        "    print(df_onehot.shape)\n",
        "\n",
        "    # 保存为 .npy 文件\n",
        "    # output_file = Path(preprocessed_folder) / f'separated/{filename}_label_onehot.npy'\n",
        "    # np.save(output_file, df_onehot.to_numpy())\n",
        "\n",
        "    # 转换成 稀疏矩阵 保存为 .npz 文件\n",
        "    import scipy.sparse\n",
        "    onehot_sparse = scipy.sparse.csr_matrix(df_onehot.to_numpy())\n",
        "    output_file = Path(preprocessed_folder) / f'separated/{filename}_label_onehot_sparse.npz'\n",
        "    scipy.sparse.save_npz(output_file, onehot_sparse)\n",
        "\n",
        "    # 加载稀疏矩阵\n",
        "    # labels_sparse = scipy.sparse.load_npz(output_file)\n",
        "    # labels_onehot = labels_sparse.toarray()\n",
        "    # print(labels_onehot.shape)\n",
        "\n",
        "    print(f'\\nSaved to {output_file}')\n",
        "\n",
        "else:\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] 跳过！对 Label 的 onehot 编码可以直接从数值化编码转换过来，没必要提前做。\")"
      ],
      "metadata": {
        "id": "uYhP8vxkG3Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df5aa36-71f0-4eef-bac7-12710207e7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[04/20/25 03:59:47] One-hot Encoding...\n",
            "[04/20/25 03:59:47] 跳过！对 Label 的 onehot 编码可以直接从数值化编码转换过来，没必要提前做。\n"
          ]
        }
      ]
    }
  ]
}