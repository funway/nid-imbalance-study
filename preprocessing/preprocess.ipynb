{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jz6jQFupNcIr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funway/nid-imbalance-study/blob/main/preprocessing/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSE-CIC-IDS2018 æ•°æ®é›†ä»‹ç»\n",
        "\n",
        "ğŸš€ NYIT 880 | ğŸ§‘ğŸ»â€ğŸ’» funway"
      ],
      "metadata": {
        "id": "jz6jQFupNcIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. æ•°æ®é›†ä¸‹è½½\n",
        "ä½¿ç”¨ aws å‘½ä»¤è¡Œå·¥å…·ï¼Œä»äº‘å­˜å‚¨ä¸­ä¸‹è½½ CSV æ–‡ä»¶:\n",
        "```\n",
        "aws s3 sync --no-sign-request --region us-east-2 \"s3://cse-cic-ids2018/Processed Traffic Data for ML Algorithms/\" ./\n",
        "```\n",
        "\n",
        "\n",
        "## 2. æ•°æ®é›†å†…å®¹\n",
        "æ­£å¸¸æƒ…å†µæ¯ä¸ª csv æ–‡ä»¶åŒ…å« 80 åˆ—æ•°æ®:\n",
        "- 79 åˆ—ç‰¹å¾ (`features`)\n",
        "- 1 åˆ—ç»“æœæ ‡ç­¾ (`label`)\n",
        "\n",
        "### 2.1 ç‰¹å¾é¡¹\n",
        "```\n",
        "['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
        "```\n",
        "\n",
        "**ä¾‹å¤–**:\n",
        "- åªæœ‰ Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv æ–‡ä»¶å¤šäº† `['Dst IP', 'Src Port', 'Flow ID', 'Src IP']` å››ä¸ªç‰¹å¾é¡¹, éœ€è¦åˆ é™¤ã€‚\n",
        "\n",
        "### 2.2 å­—ç¬¦å‹ç‰¹å¾\n",
        "åªæœ‰ `Label` ç‰¹å¾æ˜¯å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè¯¥è¡Œæ•°æ®æ˜¯æŸç§ç±»å‹çš„æ”»å‡»ã€‚\n",
        "å…¶ä½™ç‰¹å¾éƒ½æ˜¯æ•°å€¼å‹ã€‚\n",
        "\n",
        "### 2.3 æ ‡ç­¾å€¼\n",
        " Label åˆ—å…± 15 ç§å€¼:\n",
        " ```\n",
        " ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC',\n",
        " 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye',\n",
        " 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris',\n",
        " 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        " ```"
      ],
      "metadata": {
        "id": "CcAzY9TCNgSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSE-CIC-IDS2018 æ•°æ®é›†é¢„å¤„ç†\n",
        "\n",
        "ğŸš€ NYIT 880 | ğŸ§‘ğŸ»â€ğŸ’» funway\n"
      ],
      "metadata": {
        "id": "kHpVRWX6NpUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### æŒ‚è½½ Google Drive ###\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# æ‰“å°ç›®å½•\n",
        "!ls -thl /content/drive/MyDrive/NYIT/880/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1puthpauNo9J",
        "outputId": "742d8a9a-e309-4080-dac5-1e549ca3e995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16K\n",
            "drwx------ 2 root root 4.0K Jun  4 16:53 data\n",
            "drwx------ 2 root root 4.0K Jun  4 16:53 data_bak\n",
            "drwx------ 2 root root 4.0K May 28 05:33 code\n",
            "drwx------ 2 root root 4.0K May 28 05:31 dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Modules ###\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "\n",
        "### Globals ###\n",
        "## æ•°æ®æ–‡ä»¶ç›®å½•\n",
        "dataset = 'cse-cic-ids2018'\n",
        "project_folder = Path('/content/drive/MyDrive/NYIT/880')\n",
        "dataset_folder = project_folder / 'dataset' / dataset\n",
        "preprocessed_folder = project_folder / 'data/preprocessed'\n",
        "balanced_folder = project_folder / 'data/balanced'\n",
        "splits_folder = preprocessed_folder / 'splits'\n",
        "\n",
        "\n",
        "## csv æ–‡ä»¶åŒ¹é…\n",
        "csv_reg = '*.csv'\n",
        "csv_files = list(dataset_folder.rglob(csv_reg))\n",
        "for csv in csv_files:\n",
        "    print(f'csv file: {csv}, {type(csv)}')\n",
        "    pass\n",
        "\n",
        "## æ— ç”¨çš„ç‰¹å¾åˆ—\n",
        "cols_to_drop = ['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Timestamp']\n",
        "\n",
        "## Label åˆ—çš„æ‰€æœ‰å¯èƒ½å€¼(æœ‰åº)\n",
        "unique_labels = ['Benign', 'Bot', 'Brute Force -Web', 'Brute Force -XSS', 'DDOS attack-HOIC', 'DDOS attack-LOIC-UDP', 'DDoS attacks-LOIC-HTTP', 'DoS attacks-GoldenEye', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'Infilteration', 'SQL Injection', 'SSH-Bruteforce']\n",
        "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ğŸ·ï¸ Label mapping: {label_mapping}\")\n",
        "\n",
        "\n",
        "### Utilities ###\n",
        "def get_label_counts(y: np.ndarray) -> dict[int, int]:\n",
        "  return {int(k): v for k, v in sorted(Counter(y).items())}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmIBEJYcOcXV",
        "outputId": "d35c9982-94dc-42aa-8b59-d4de7fa3ebf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "csv file: /content/drive/MyDrive/NYIT/880/dataset/cse-cic-ids2018/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv, <class 'pathlib.PosixPath'>\n",
            "[06/04/25 17:44:44] ğŸ·ï¸ Label mapping: {'Benign': 0, 'Bot': 1, 'Brute Force -Web': 2, 'Brute Force -XSS': 3, 'DDOS attack-HOIC': 4, 'DDOS attack-LOIC-UDP': 5, 'DDoS attacks-LOIC-HTTP': 6, 'DoS attacks-GoldenEye': 7, 'DoS attacks-Hulk': 8, 'DoS attacks-SlowHTTPTest': 9, 'DoS attacks-Slowloris': 10, 'FTP-BruteForce': 11, 'Infilteration': 12, 'SQL Injection': 13, 'SSH-Bruteforce': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get all unique labels"
      ],
      "metadata": {
        "id": "4h5F0oeEZmti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## è·å– Label çš„æ‰€æœ‰å¯èƒ½å€¼ ##\n",
        "\n",
        "# unique_labels = []\n",
        "\n",
        "if not unique_labels:\n",
        "    all_labels_count = {}  # ç»Ÿè®¡æ‰€æœ‰ csv æ–‡ä»¶çš„ labels ç§ç±»ä¸æ•°é‡\n",
        "\n",
        "    # éå†æ¯ä¸ª csv æ–‡ä»¶\n",
        "    for csv in csv_files:\n",
        "        print(f'Reading csv file: {Path(csv).name}')\n",
        "\n",
        "        csv_labels_count = {}  # ç»Ÿè®¡å½“å‰ CSV æ–‡ä»¶çš„ labels æ•°é‡\n",
        "\n",
        "        # åˆ†å—è¯»å–\n",
        "        chunk_size = 100000\n",
        "        for chunk in pd.read_csv(csv, usecols=['Label'], chunksize=chunk_size):\n",
        "            if 'Label' in chunk.columns:\n",
        "                # ç»Ÿè®¡å½“å‰ chunk çš„ labels ç§ç±»ä¸æ•°é‡ï¼Œè¿”å› {'Benign': 100, 'Bot': 99} å­—å…¸\n",
        "                chunk_labels_count = chunk['Label'].value_counts().to_dict()\n",
        "\n",
        "                for label, count in chunk_labels_count.items():\n",
        "                    # æ›´æ–°å½“å‰ csv æ–‡ä»¶çš„ labels ç»Ÿè®¡\n",
        "                    csv_labels_count[label] = csv_labels_count.get(label, 0) + count\n",
        "\n",
        "                    # æ›´æ–°æ‰€æœ‰ csv æ–‡ä»¶çš„ labels ç»Ÿè®¡\n",
        "                    all_labels_count[label] = all_labels_count.get(label, 0) + count\n",
        "\n",
        "        # æ‰“å°å½“å‰ csv çš„ unique labels\n",
        "        print(f'  unique labels: [{len(csv_labels_count)}], {dict(sorted(csv_labels_count.items()))}\\n')\n",
        "        pass\n",
        "\n",
        "    # æ‰“å°æ‰€æœ‰çš„ unique labels\n",
        "    print(f'All unique labels count: [{len(all_labels_count)}] \\n{dict(sorted(all_labels_count.items()))}\\n')\n",
        "\n",
        "    # å¦‚æœ 'Label' å­˜åœ¨åˆ™åˆ é™¤\n",
        "    all_labels_count.pop('Label', None)\n",
        "\n",
        "    # è½¬æ¢æˆæœ‰åºåˆ—è¡¨\n",
        "    unique_labels = sorted(all_labels_count.keys())\n",
        "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] All unique labels: [{len(label_mapping)}] (removed 'Label')\\n{label_mapping}\", )\n",
        "else:\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] unique_labels has been set: [{len(label_mapping)}]\\n{label_mapping}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR9wRXmdSFO_",
        "outputId": "dab47544-31d0-4181-e34e-310b6d145e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/04/25 17:31:08] unique_labels has been set: [15]\n",
            "{'Benign': 0, 'Bot': 1, 'Brute Force -Web': 2, 'Brute Force -XSS': 3, 'DDOS attack-HOIC': 4, 'DDOS attack-LOIC-UDP': 5, 'DDoS attacks-LOIC-HTTP': 6, 'DoS attacks-GoldenEye': 7, 'DoS attacks-Hulk': 8, 'DoS attacks-SlowHTTPTest': 9, 'DoS attacks-Slowloris': 10, 'FTP-BruteForce': 11, 'Infilteration': 12, 'SQL Injection': 13, 'SSH-Bruteforce': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning æ•°æ®æ¸…æ´—\n",
        "1. åˆ é™¤æ— ç”¨ç‰¹å¾åˆ—\n",
        "2. åˆ é™¤å¼‚å¸¸è¡Œ(è¡Œæ•°æ®ä¸ºåˆ—å)\n",
        "3. æ•°å€¼å‹ç‰¹å¾åˆ— ç±»å‹è½¬æ¢ä¸º float32 (å¼‚å¸¸å€¼è½¬æ¢ä¸º NaN)\n",
        "4. å¤„ç† Inf å€¼ (åˆ é™¤è¡Œ)\n",
        "5. å¤„ç† NaN å€¼ (åˆ é™¤è¡Œ)\n",
        "6. æ ‡ç­¾åˆ—è¿›è¡Œæ•°å€¼åŒ–ç¼–ç \n",
        "\n"
      ],
      "metadata": {
        "id": "G_ezQnmoplCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_folder = preprocessed_folder / 'cleaned.parquet'\n",
        "reclean = False\n",
        "\n",
        "if not cleaned_folder.exists() or reclean:\n",
        "    # ç¡®ä¿ç›®å½•å­˜åœ¨\n",
        "    cleaned_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for i, csv in enumerate(csv_files):\n",
        "        # åŠ è½½æ–‡ä»¶\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}] Loading csv file [{i+1}]: {csv.name}\")\n",
        "        df = pd.read_csv(csv, nrows=None, low_memory=False)\n",
        "        print(f'  åŒ…å«[{len(df.columns)}]åˆ—ç‰¹å¾: {sorted(df.columns.tolist())}')\n",
        "        print(f\"  Label åˆ—çš„å€¼: {df['Label'].value_counts().to_dict()}\")\n",
        "\n",
        "\n",
        "        ## åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ— ##\n",
        "        cols_to_drop_exist = [col for col in cols_to_drop if col in df.columns]\n",
        "        df = df.drop(cols_to_drop_exist, axis=1)  # axis=1 è¡¨ç¤ºåˆ é™¤åˆ—\n",
        "        print(f'  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: {cols_to_drop_exist}')\n",
        "        print(f'    åˆ é™¤åå‰©ä½™[{len(df.columns)}]åˆ—ç‰¹å¾')\n",
        "\n",
        "\n",
        "        ## åˆ é™¤ Label åˆ—çš„å€¼ç­‰äº 'Label' çš„è¡Œ ##\n",
        "        # å› ä¸ºæœ‰å‡ ä¸ªæ–‡ä»¶åœ¨æŸäº›è¡Œå‡ºç°äº†ä¸€æ•´è¡Œçš„ç‰¹å¾å\n",
        "        if 'Label' in df.columns and ('Label' in df['Label'].values):\n",
        "            df = df[df['Label'] != 'Label']\n",
        "            print(f'  â åˆ é™¤å…¶ä¸­ Label åˆ—çš„å€¼ç­‰äº \"Label\" çš„è¡Œ')\n",
        "            print(f\"    åˆ é™¤å Label åˆ—çš„å€¼: {df['Label'].value_counts().to_dict()}\")\n",
        "\n",
        "\n",
        "        ## æ•°å€¼åˆ—ç‰¹å¾è½¬æ¢æˆ æ•°å€¼ç±»å‹ è€Œä¸æ˜¯ object ç±»å‹ ##\n",
        "        print(f'  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32')\n",
        "        # æå–æ•°å€¼ç‰¹å¾åˆ—ï¼Œæ’é™¤ 'Label' åˆ—\n",
        "        features = df.columns.difference(['Label'])\n",
        "        # å¯¹æ•°å€¼ç‰¹å¾åˆ—è¿›è¡Œæ•°å€¼è½¬æ¢(æ— æ³•è½¬æ¢æˆæ•°å€¼çš„ï¼Œå¼ºåˆ¶è®¾ä¸º NaN)\n",
        "        df[features] = df[features].apply(pd.to_numeric, errors='coerce').astype('float32')\n",
        "\n",
        "\n",
        "        ## å¤„ç† Inf å€¼ ##\n",
        "        print(f'  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape={df.shape}')\n",
        "        print(f'    æ­£æ— ç©· (+Inf) æ•°é‡: {(df == np.inf).sum().sum()}, è´Ÿæ— ç©· (-Inf) æ•°é‡: {(df == -np.inf).sum().sum()}')\n",
        "        # æ–¹æ³•ä¸€: åˆ é™¤è¯¥è¡Œ\n",
        "        df = df[~df.isin([np.inf, -np.inf]).any(axis=1)]\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # æ–¹æ³•äºŒ: æ›¿æ¢ä¸ºå¯¹åº”åˆ—çš„æœ€å¤§/æœ€å°å€¼\n",
        "        # max_value = df.replace([np.inf, -np.inf], np.nan).max()\n",
        "        # min_value = df.replace([np.inf, -np.inf], np.nan).min()\n",
        "        # df.replace(np.inf, max_value, inplace=True)\n",
        "        # df.replace(-np.inf, min_value, inplace=True)\n",
        "        # æ–¹æ³•ä¸‰: æ›¿æ¢æˆ NaN\n",
        "        # df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        print(f'    å¤„ç†å shape={df.shape}')\n",
        "\n",
        "\n",
        "        ## å¤„ç† NaN å€¼ ##\n",
        "        print(f'  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: {df.isna().sum().sum()}')\n",
        "        # æ–¹æ³•ä¸€: åˆ é™¤è¯¥è¡Œ\n",
        "        df.dropna(inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        # æ–¹æ³•äºŒ: å¡«å……å€¼\n",
        "        # df['Label'] = df['Label'].fillna('Benign')  # å¡«å…… Label åˆ—\n",
        "        # df = df.fillna(0)  # å¡«å……å…¶ä»–åˆ—\n",
        "        print(f'    å¤„ç†å shape={df.shape}')\n",
        "\n",
        "\n",
        "        ## å¯¹ Label æ ‡ç­¾åˆ—è¿›è¡Œæ•°å€¼åŒ–ç¼–ç  ##\n",
        "        print(f\"  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\")\n",
        "        def encode_label(label):\n",
        "            if label in label_mapping:\n",
        "                return label_mapping[label]\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown label '{label}' encountered during encoding.\")\n",
        "\n",
        "        print(f\"    è½¬æ¢å‰ Label åˆ—çš„å€¼: {df['Label'].value_counts().to_dict()}\")\n",
        "        df['Label'] = df['Label'].apply(encode_label).astype('int32')\n",
        "        print(f\"    è½¬æ¢å Label åˆ—çš„å€¼: {df['Label'].value_counts().to_dict()}\")\n",
        "\n",
        "\n",
        "        ## ä¿å­˜æ–‡ä»¶ ##\n",
        "        # df.to_csv('combined.csv', mode='a', header=(i==0), index=False)\n",
        "        output_file = cleaned_folder / f'part-{i+1:03d}.parquet'\n",
        "        df.to_parquet(output_file, index=False)\n",
        "        print(f\"[{datetime.now().strftime('%x %X')}] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [{i+1}]: {csv.name} >> {output_file}\")\n",
        "\n",
        "        print(\"-------------------------\")\n",
        "else:\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] â­ï¸ {cleaned_folder} å·²å­˜åœ¨, è·³è¿‡è¯¥æ­¥éª¤\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "749tdpJTZ3we",
        "outputId": "fe013bee-6d38-4716-d031-293f9acd690f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/04/25 17:31:15] Loading csv file [1]: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 762384, 'Bot': 286191}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 5542, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1044525, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1044525, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 758334, 'Bot': 286191}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 758334, 1: 286191}\n",
            "[06/04/25 17:32:04] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [1]: Friday-02-03-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-001.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:32:04] Loading csv file [2]: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'DoS attacks-Hulk': 461912, 'Benign': 446772, 'DoS attacks-SlowHTTPTest': 139890, 'Label': 1}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  â åˆ é™¤å…¶ä¸­ Label åˆ—çš„å€¼ç­‰äº \"Label\" çš„è¡Œ\n",
            "    åˆ é™¤å Label åˆ—çš„å€¼: {'DoS attacks-Hulk': 461912, 'Benign': 446772, 'DoS attacks-SlowHTTPTest': 139890}\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048574, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 0, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1048574, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1048574, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'DoS attacks-Hulk': 461912, 'Benign': 446772, 'DoS attacks-SlowHTTPTest': 139890}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {8: 461912, 0: 446772, 9: 139890}\n",
            "[06/04/25 17:33:56] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [2]: Friday-16-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-002.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:33:56] Loading csv file [3]: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 1048009, 'Brute Force -Web': 362, 'Brute Force -XSS': 151, 'SQL Injection': 53}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 7662, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1042867, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1042867, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 1042301, 'Brute Force -Web': 362, 'Brute Force -XSS': 151, 'SQL Injection': 53}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 1042301, 2: 362, 3: 151, 13: 53}\n",
            "[06/04/25 17:34:38] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [3]: Friday-23-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-003.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:34:38] Loading csv file [4]: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 238037, 'Infilteration': 93063, 'Label': 25}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  â åˆ é™¤å…¶ä¸­ Label åˆ—çš„å€¼ç­‰äº \"Label\" çš„è¡Œ\n",
            "    åˆ é™¤å Label åˆ—çš„å€¼: {'Benign': 238037, 'Infilteration': 93063}\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(331100, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 4004, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(328181, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(328181, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 235778, 'Infilteration': 92403}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 235778, 12: 92403}\n",
            "[06/04/25 17:35:10] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [4]: Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-004.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:35:10] Loading csv file [5]: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 996077, 'DoS attacks-GoldenEye': 41508, 'DoS attacks-Slowloris': 10990}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 11133, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1040548, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1040548, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 988050, 'DoS attacks-GoldenEye': 41508, 'DoS attacks-Slowloris': 10990}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 988050, 7: 41508, 10: 10990}\n",
            "[06/04/25 17:35:47] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [5]: Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-005.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:35:47] Loading csv file [6]: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 1048213, 'Brute Force -Web': 249, 'Brute Force -XSS': 79, 'SQL Injection': 34}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 7651, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1042965, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1042965, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 1042603, 'Brute Force -Web': 249, 'Brute Force -XSS': 79, 'SQL Injection': 34}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 1042603, 2: 249, 3: 79, 13: 34}\n",
            "[06/04/25 17:36:25] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [6]: Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-006.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:36:25] Loading csv file [7]: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 667626, 'FTP-BruteForce': 193360, 'SSH-Bruteforce': 187589}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 5371, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1044751, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1044751, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 663808, 'FTP-BruteForce': 193354, 'SSH-Bruteforce': 187589}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 663808, 11: 193354, 14: 187589}\n",
            "[06/04/25 17:37:07] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [7]: Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-007.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:37:07] Loading csv file [8]: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'DDOS attack-HOIC': 686012, 'Benign': 360833, 'DDOS attack-LOIC-UDP': 1730}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1048575, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 0, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1048575, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1048575, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'DDOS attack-HOIC': 686012, 'Benign': 360833, 'DDOS attack-LOIC-UDP': 1730}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {4: 686012, 0: 360833, 5: 1730}\n",
            "[06/04/25 17:37:43] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [8]: Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-008.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:37:43] Loading csv file [9]: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[80]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'Benign': 544200, 'Infilteration': 68871, 'Label': 33}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  â åˆ é™¤å…¶ä¸­ Label åˆ—çš„å€¼ç­‰äº \"Label\" çš„è¡Œ\n",
            "    åˆ é™¤å Label åˆ—çš„å€¼: {'Benign': 544200, 'Infilteration': 68871}\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(613071, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 8297, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(606902, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(606902, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'Benign': 538666, 'Infilteration': 68236}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {0: 538666, 12: 68236}\n",
            "[06/04/25 17:38:42] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [9]: Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-009.parquet\n",
            "-------------------------\n",
            "[06/04/25 17:38:42] Loading csv file [10]: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
            "  åŒ…å«[84]åˆ—ç‰¹å¾: ['ACK Flag Cnt', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Bwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Header Len', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Tot', 'Bwd PSH Flags', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Min', 'Bwd Pkt Len Std', 'Bwd Pkts/b Avg', 'Bwd Pkts/s', 'Bwd Seg Size Avg', 'Bwd URG Flags', 'CWE Flag Count', 'Down/Up Ratio', 'Dst IP', 'Dst Port', 'ECE Flag Cnt', 'FIN Flag Cnt', 'Flow Byts/s', 'Flow Duration', 'Flow IAT Max', 'Flow IAT Mean', 'Flow IAT Min', 'Flow IAT Std', 'Flow ID', 'Flow Pkts/s', 'Fwd Act Data Pkts', 'Fwd Blk Rate Avg', 'Fwd Byts/b Avg', 'Fwd Header Len', 'Fwd IAT Max', 'Fwd IAT Mean', 'Fwd IAT Min', 'Fwd IAT Std', 'Fwd IAT Tot', 'Fwd PSH Flags', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Min', 'Fwd Pkt Len Std', 'Fwd Pkts/b Avg', 'Fwd Pkts/s', 'Fwd Seg Size Avg', 'Fwd Seg Size Min', 'Fwd URG Flags', 'Idle Max', 'Idle Mean', 'Idle Min', 'Idle Std', 'Init Bwd Win Byts', 'Init Fwd Win Byts', 'Label', 'PSH Flag Cnt', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Min', 'Pkt Len Std', 'Pkt Len Var', 'Pkt Size Avg', 'Protocol', 'RST Flag Cnt', 'SYN Flag Cnt', 'Src IP', 'Src Port', 'Subflow Bwd Byts', 'Subflow Bwd Pkts', 'Subflow Fwd Byts', 'Subflow Fwd Pkts', 'Timestamp', 'Tot Bwd Pkts', 'Tot Fwd Pkts', 'TotLen Bwd Pkts', 'TotLen Fwd Pkts', 'URG Flag Cnt']\n",
            "  Label åˆ—çš„å€¼: {'DDoS attacks-LOIC-HTTP': 576191, 'Benign': 499999}\n",
            "  â åˆ é™¤éƒ¨åˆ†æ— ç”¨çš„ç‰¹å¾åˆ—: ['Flow ID', 'Src IP', 'Dst IP', 'Src Port', 'Timestamp']\n",
            "    åˆ é™¤åå‰©ä½™[79]åˆ—ç‰¹å¾\n",
            "  ğŸ” æ•°å€¼ç‰¹å¾ç±»å‹è½¬æ¢ â‡¨ float32\n",
            "  âš ï¸ å¤„ç† Inf å€¼. å½“å‰ shape=(1076190, 79)\n",
            "    æ­£æ— ç©· (+Inf) æ•°é‡: 5617, è´Ÿæ— ç©· (-Inf) æ•°é‡: 0\n",
            "    å¤„ç†å shape=(1072147, 79)\n",
            "  âš ï¸ å¤„ç† NaN å€¼. åŒ…å« NaN ä¸ªæ•°: 0\n",
            "    å¤„ç†å shape=(1072147, 79)\n",
            "  ğŸ” æ ‡ç­¾åˆ—æ•°å€¼åŒ–ç¼–ç  Numericalization Encoding...\n",
            "    è½¬æ¢å‰ Label åˆ—çš„å€¼: {'DDoS attacks-LOIC-HTTP': 576191, 'Benign': 495956}\n",
            "    è½¬æ¢å Label åˆ—çš„å€¼: {6: 576191, 0: 495956}\n",
            "[06/04/25 17:39:32] ğŸ’¾ ä¿å­˜æ–‡ä»¶ [10]: Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv >> /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet/part-010.parquet\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Trimming\n",
        "- åˆ é™¤å…¨é›¶å€¼çš„ç‰¹å¾åˆ—\n",
        "- åˆ é™¤å­˜åœ¨ å°äº -1 çš„å€¼çš„è¡Œ\n",
        "- åˆ é™¤è¿‡å¤šçš„æ ‡ç­¾æ ·æœ¬ (å°¤å…¶æ˜¯ `Benign` æ ·æœ¬, åªä¿ç•™ 2000000 è¡Œ)"
      ],
      "metadata": {
        "id": "HtFtyuulcWdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trimed_file = preprocessed_folder / 'trimed_data.parquet'\n",
        "re_trim = False\n",
        "\n",
        "# trim_to å­—å…¸æŒ‡å®šè¦è£å‰ªçš„ ç›®æ ‡æ ‡ç­¾ ä¸ ç›®æ ‡æ•°é‡ â‡¨ df[label] <= trim_to[label]\n",
        "trim_to = {0:2000000, 1:300000, 3:300000} # å› ä¸ºæ ‡ç­¾ 1,3 æœ¬æ¥å°±æ²¡æœ‰30ä¸‡æ¡æ•°æ®, æ‰€ä»¥è¿™é‡Œå¹¶ä¸ä¼šå¯¹æ ‡ç­¾ 1,3 è¿›è¡Œè£å‰ª\n",
        "\n",
        "if not trimed_file.exists() or re_trim:\n",
        "    ## ä¸€æ¬¡æ€§è¯»å–å…¨éƒ¨æ•°æ® ##\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ğŸš€ Loading cleaned data from {cleaned_folder}\")\n",
        "\n",
        "    df = pd.read_parquet(cleaned_folder)\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] shape={df.shape}\")\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] Label åˆ—çš„å€¼: {dict(sorted(df['Label'].value_counts().items()))}\")\n",
        "\n",
        "\n",
        "    ## åˆ¤æ–­ df ä¸­æ˜¯å¦æœ‰å…¨é›¶çš„åˆ—ï¼Œæœ‰çš„è¯åˆ é™¤ ##\n",
        "    zero_columns = df.columns[(df==0).all()]\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ğŸ§¹ æ£€æµ‹åˆ°å…¨é›¶å€¼çš„åˆ—å…± {len(zero_columns)} ä¸ª: {[df.columns.get_loc(col) for col in zero_columns]}\")\n",
        "\n",
        "    df = df.drop(zero_columns, axis=1)\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ğŸ§¹ åˆ é™¤å shape={df.shape}\")\n",
        "\n",
        "    ## å¤„ç†å°äº -1 çš„å€¼ ##\n",
        "    rows_with_negatives = df[df.lt(-1).any(axis=1)]\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âš ï¸ å¤„ç†å°äº -1 çš„å€¼. å…±æ‰¾åˆ° {len(rows_with_negatives)} è¡ŒåŒ…å«å°äº -1 çš„å€¼\")\n",
        "    df.drop(index=rows_with_negatives.index, inplace=True)\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âš ï¸ å¤„ç†å shape={df.shape}\")\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âš ï¸ Label åˆ—çš„å€¼: {dict(sorted(df['Label'].value_counts().items()))}\")\n",
        "\n",
        "    ## å¼€å§‹è£å‰ª ##\n",
        "    # è®¡ç®—æ¯è¡Œæ˜¯å¦åº”è¯¥ä¿ç•™\n",
        "    df['__keep__'] = False\n",
        "    for label, max_count in trim_to.items():\n",
        "        mask = (df['Label'] == label)\n",
        "        if len(df[mask]) <= max_count:\n",
        "            keep_indices = df[mask].index\n",
        "        else:\n",
        "            keep_indices = df[mask].sample(n=max_count, random_state=42).index\n",
        "        df.loc[keep_indices, '__keep__'] = True\n",
        "\n",
        "    # æœªå‡ºç°åœ¨ trim_to ä¸­çš„ç±»åˆ«ï¼Œé»˜è®¤ä¿ç•™å…¨éƒ¨\n",
        "    df.loc[~df['Label'].isin(trim_to.keys()), '__keep__'] = True\n",
        "\n",
        "    # è¿‡æ»¤å¹¶ä¸¢å¼ƒæ ‡è®°åˆ—\n",
        "    df = df[df['__keep__']].drop(columns='__keep__').reset_index(drop=True)\n",
        "\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âœ‚ï¸ è£å‰ªå shape={df.shape}\")\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âœ‚ï¸ Label åˆ—çš„å€¼: {dict(sorted(df['Label'].value_counts().items()))}\")\n",
        "\n",
        "\n",
        "    ## ä¿å­˜è£å‰ªåçš„æ•°æ® ##\n",
        "    df.to_parquet(trimed_file, index=False)\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ğŸ’¾ ä¿å­˜è£å‰ªåçš„æ•°æ®: {trimed_file}\")\n",
        "    pass\n",
        "else:\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] â­ï¸ {trimed_file} å·²å­˜åœ¨, ç›´æ¥åŠ è½½\")\n",
        "    df = pd.read_parquet(trimed_file)\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] shape={df.shape}\")\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] Label åˆ—çš„å€¼: {dict(sorted(df['Label'].value_counts().items()))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkeF9WkjzPdW",
        "outputId": "36263e14-1771-47a6-8818-36878280c9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/04/25 17:39:32] ğŸš€ Loading cleaned data from /content/drive/MyDrive/NYIT/880/data/preprocessed/cleaned.parquet\n",
            "[06/04/25 17:39:44] shape=(9320035, 79)\n",
            "[06/04/25 17:39:44] Label åˆ—çš„å€¼: {0: 6573101, 1: 286191, 2: 611, 3: 230, 4: 686012, 5: 1730, 6: 576191, 7: 41508, 8: 461912, 9: 139890, 10: 10990, 11: 193354, 12: 160639, 13: 87, 14: 187589}\n",
            "[06/04/25 17:39:47] ğŸ§¹ æ£€æµ‹åˆ°å…¨é›¶å€¼çš„åˆ—å…± 8 ä¸ª: [32, 34, 56, 57, 58, 59, 60, 61]\n",
            "[06/04/25 17:39:50] ğŸ§¹ åˆ é™¤å shape=(9320035, 71)\n",
            "[06/04/25 17:39:53] âš ï¸ å¤„ç†å°äº -1 çš„å€¼. å…±æ‰¾åˆ° 15 è¡ŒåŒ…å«å°äº -1 çš„å€¼\n",
            "[06/04/25 17:39:56] âš ï¸ å¤„ç†å shape=(9320020, 71)\n",
            "[06/04/25 17:39:56] âš ï¸ Label åˆ—çš„å€¼: {0: 6573086, 1: 286191, 2: 611, 3: 230, 4: 686012, 5: 1730, 6: 576191, 7: 41508, 8: 461912, 9: 139890, 10: 10990, 11: 193354, 12: 160639, 13: 87, 14: 187589}\n",
            "[06/04/25 17:40:08] âœ‚ï¸ è£å‰ªå shape=(4746934, 71)\n",
            "[06/04/25 17:40:08] âœ‚ï¸ Label åˆ—çš„å€¼: {0: 2000000, 1: 286191, 2: 611, 3: 230, 4: 686012, 5: 1730, 6: 576191, 7: 41508, 8: 461912, 9: 139890, 10: 10990, 11: 193354, 12: 160639, 13: 87, 14: 187589}\n",
            "[06/04/25 17:40:29] ğŸ’¾ ä¿å­˜è£å‰ªåçš„æ•°æ®: /content/drive/MyDrive/NYIT/880/data/preprocessed/trimed_data.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ•°æ®ç»Ÿè®¡\n",
        "- shape\n",
        "- æ¯ç§æ ‡ç­¾çš„æ ·æœ¬æ•°\n",
        "- ç‰¹å¾åˆ—çš„æ•°å€¼åˆ†å¸ƒ\n",
        "- è´Ÿå€¼ç»Ÿè®¡"
      ],
      "metadata": {
        "id": "lTjOPpDNj8OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = f\"[{datetime.now().strftime('%x %X')}] === Data Summary ===\"\n",
        "\n",
        "report_file = preprocessed_folder / 'trimed_report.txt'\n",
        "\n",
        "pd.set_option('display.max_rows', None)     # æ˜¾ç¤ºæ‰€æœ‰è¡Œï¼ˆæ¯ä¸€åˆ—å¯¹åº”ä¸€è¡Œï¼‰\n",
        "pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼ˆæ¯ä¸€ä¸ªç»Ÿè®¡æŒ‡æ ‡ï¼‰\n",
        "\n",
        "report += \"\\n\" + f\"[{datetime.now().strftime('%x %X')}] æ•°æ®é›†å½¢çŠ¶: {df.shape}\"\n",
        "report += \"\\n\" + f\"[{datetime.now().strftime('%x %X')}] å„æ ‡ç­¾æ ·æœ¬ç»Ÿè®¡:\\n{dict(sorted(df['Label'].value_counts().items()))}\"\n",
        "report += \"\\n\" + f\"[{datetime.now().strftime('%x %X')}] æ•°æ®åˆ†å¸ƒç»Ÿè®¡: \\n{df.describe()}\"\n",
        "\n",
        "negative_counts = (df < 0).sum()\n",
        "negative_counts_filtered = {\n",
        "    k: int(v) for k, v in negative_counts.items() if v > 0\n",
        "}\n",
        "report += \"\\n\"*2 + f\"[{datetime.now().strftime('%x %X')}] è´Ÿå€¼ç»Ÿè®¡, å…± [{len(negative_counts_filtered)}] åˆ—å­˜åœ¨è´Ÿå€¼:\"\n",
        "report += \"\\n\" + f\"{negative_counts_filtered}\"\n",
        "\n",
        "print(f\"[{datetime.now().strftime('%x %X')}] ç»Ÿè®¡æ•°æ®è¾“å‡ºåˆ°æ–‡ä»¶: {report_file}\")\n",
        "with open(report_file, 'w') as f:\n",
        "    f.write(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10vVr_6ckAgR",
        "outputId": "ac3aa9af-0a88-4e56-9e94-b1c8e1f6825c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/04/25 17:40:48] ç»Ÿè®¡æ•°æ®è¾“å‡ºåˆ°æ–‡ä»¶: /content/drive/MyDrive/NYIT/880/data/preprocessed/trimed_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset split\n",
        "- train set: 80%\n",
        "- valid set: 10%\n",
        "- test set: 10%"
      ],
      "metadata": {
        "id": "N5X7-pOK4pV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if splits_folder.exists():\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] âš ï¸ {splits_folder} ç›®å½•å·²å­˜åœ¨, å°†è¦†ç›–é‡Œé¢çš„æ•°æ®\")\n",
        "else:\n",
        "    print(f\"[{datetime.now().strftime('%x %X')}] ğŸ“ åˆ›å»ºç›®å½•: {splits_folder}\")\n",
        "    splits_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# åˆ†ç¦» ç‰¹å¾çŸ©é˜µ ä¸ æ ‡ç­¾\n",
        "features = df.columns.difference(['Label'])\n",
        "X = df[features].to_numpy(dtype=np.float32)\n",
        "y = df['Label'].to_numpy(dtype=np.int32)\n",
        "\n",
        "print(f'Original features: {X.shape}')\n",
        "print(f'Original labels: {get_label_counts(y)}\\n')\n",
        "\n",
        "# Split whole => 0.8 : 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "del X, y\n",
        "\n",
        "# Split 0.2 => 0.1 : 0.1\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train labels: {get_label_counts(y_train)}\\n')\n",
        "np.save(splits_folder / f'train_X.npy', X_train)\n",
        "np.save(splits_folder / f'train_y.npy', y_train)\n",
        "\n",
        "print(f'X_valid shape: {X_valid.shape}')\n",
        "print(f'y_valid labels: {get_label_counts(y_valid)}\\n')\n",
        "np.save(splits_folder / f'valid_X.npy', X_valid)\n",
        "np.save(splits_folder / f'valid_y.npy', y_valid)\n",
        "\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_test labels: {get_label_counts(y_test)}\\n')\n",
        "np.save(splits_folder / f'test_X.npy', X_test)\n",
        "np.save(splits_folder / f'test_y.npy', y_test)\n",
        "\n",
        "print(f'[{datetime.now().strftime(\"%x %X\")}] âœ… Saved splited datasets to {splits_folder}/ (train, valid, test)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2gnTJP5448I",
        "outputId": "186fca0c-8c3e-4575-9717-0be64d80ccc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06/04/25 18:00:36] âš ï¸ /content/drive/MyDrive/NYIT/880/data/preprocessed/splits ç›®å½•å·²å­˜åœ¨, å°†è¦†ç›–é‡Œé¢çš„æ•°æ®\n",
            "Original features: (4746934, 70)\n",
            "Original labels: {0: 2000000, 1: 286191, 2: 611, 3: 230, 4: 686012, 5: 1730, 6: 576191, 7: 41508, 8: 461912, 9: 139890, 10: 10990, 11: 193354, 12: 160639, 13: 87, 14: 187589}\n",
            "\n",
            "X_train shape: (3797547, 70)\n",
            "y_train labels: {0: 1600000, 1: 228953, 2: 489, 3: 184, 4: 548809, 5: 1384, 6: 460953, 7: 33206, 8: 369530, 9: 111912, 10: 8792, 11: 154683, 12: 128511, 13: 70, 14: 150071}\n",
            "\n",
            "X_valid shape: (474693, 70)\n",
            "y_valid labels: {0: 200000, 1: 28619, 2: 61, 3: 23, 4: 68601, 5: 173, 6: 57619, 7: 4151, 8: 46191, 9: 13989, 10: 1099, 11: 19335, 12: 16064, 13: 9, 14: 18759}\n",
            "\n",
            "X_test shape: (474694, 70)\n",
            "y_test labels: {0: 200000, 1: 28619, 2: 61, 3: 23, 4: 68602, 5: 173, 6: 57619, 7: 4151, 8: 46191, 9: 13989, 10: 1099, 11: 19336, 12: 16064, 13: 8, 14: 18759}\n",
            "\n",
            "[06/04/25 18:01:29] âœ… Saved splited datasets to /content/drive/MyDrive/NYIT/880/data/preprocessed/splits/ (train, valid, test)\n"
          ]
        }
      ]
    }
  ]
}